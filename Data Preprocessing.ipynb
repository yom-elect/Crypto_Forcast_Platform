{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#%matplotlib inline \n",
    "from datetime import date\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"seaborn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading the data of all three Crypto pairs in between 17th September 2014 to 30th June 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 34s 784ms/step - loss: 0.0013 - val_loss: 0.0127\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 17s 529ms/step - loss: 2.0195e-04 - val_loss: 0.0075\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 17s 529ms/step - loss: 1.6338e-04 - val_loss: 0.0150\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 17s 527ms/step - loss: 1.4052e-04 - val_loss: 0.0150\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 17s 529ms/step - loss: 1.3196e-04 - val_loss: 0.0247\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 18s 534ms/step - loss: 1.1590e-04 - val_loss: 0.0278\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 18s 559ms/step - loss: 1.0702e-04 - val_loss: 0.0413\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 17s 522ms/step - loss: 1.1280e-04 - val_loss: 0.0341\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 17s 521ms/step - loss: 1.0738e-04 - val_loss: 0.0400\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 17s 528ms/step - loss: 9.6484e-05 - val_loss: 0.0421\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 17s 520ms/step - loss: 9.3902e-05 - val_loss: 0.0290\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 17s 511ms/step - loss: 1.0101e-04 - val_loss: 0.0269\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 17s 519ms/step - loss: 1.2277e-04 - val_loss: 0.0321\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 17s 519ms/step - loss: 8.5756e-05 - val_loss: 0.0377\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 17s 509ms/step - loss: 7.7279e-05 - val_loss: 0.0317\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 17s 520ms/step - loss: 8.3915e-05 - val_loss: 0.0259\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 17s 517ms/step - loss: 7.0568e-05 - val_loss: 0.0293\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 17s 524ms/step - loss: 8.9962e-05 - val_loss: 0.0236\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 17s 526ms/step - loss: 6.8556e-05 - val_loss: 0.0168\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 17s 522ms/step - loss: 7.1776e-05 - val_loss: 0.0186\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 18s 552ms/step - loss: 6.5726e-05 - val_loss: 0.0165\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 18s 547ms/step - loss: 6.4479e-05 - val_loss: 0.0146\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 18s 556ms/step - loss: 6.2420e-05 - val_loss: 0.0214\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 17s 506ms/step - loss: 6.3983e-05 - val_loss: 0.0166\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 17s 513ms/step - loss: 5.8155e-05 - val_loss: 0.0226\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 17s 510ms/step - loss: 5.7705e-05 - val_loss: 0.0150\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 17s 508ms/step - loss: 5.4320e-05 - val_loss: 0.0197\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 16s 501ms/step - loss: 5.5482e-05 - val_loss: 0.0151\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 17s 513ms/step - loss: 5.3333e-05 - val_loss: 0.0127\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 17s 512ms/step - loss: 6.0996e-05 - val_loss: 0.0161\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 17s 509ms/step - loss: 5.2547e-05 - val_loss: 0.0146\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 17s 503ms/step - loss: 5.4370e-05 - val_loss: 0.0160\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 17s 508ms/step - loss: 5.8661e-05 - val_loss: 0.0162\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 17s 510ms/step - loss: 5.0255e-05 - val_loss: 0.0126\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 17s 505ms/step - loss: 4.6003e-05 - val_loss: 0.0128\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 18s 536ms/step - loss: 5.1459e-05 - val_loss: 0.0232\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 17s 509ms/step - loss: 4.9828e-05 - val_loss: 0.0130\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 17s 503ms/step - loss: 4.6933e-05 - val_loss: 0.0171\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 17s 518ms/step - loss: 4.4673e-05 - val_loss: 0.0110\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 18s 561ms/step - loss: 4.3164e-05 - val_loss: 0.0086\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 18s 559ms/step - loss: 4.4023e-05 - val_loss: 0.0094\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 18s 558ms/step - loss: 4.3035e-05 - val_loss: 0.0115\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 18s 547ms/step - loss: 4.4201e-05 - val_loss: 0.0157\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 18s 538ms/step - loss: 5.0952e-05 - val_loss: 0.0145\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 18s 540ms/step - loss: 4.1177e-05 - val_loss: 0.0064\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 18s 548ms/step - loss: 4.5742e-05 - val_loss: 0.0078\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 18s 535ms/step - loss: 3.5849e-05 - val_loss: 0.0087\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 18s 550ms/step - loss: 3.5874e-05 - val_loss: 0.0080\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 17s 525ms/step - loss: 3.5446e-05 - val_loss: 0.0129\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 18s 531ms/step - loss: 3.9410e-05 - val_loss: 0.0088\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 17s 524ms/step - loss: 3.1639e-05 - val_loss: 0.0106\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 17s 529ms/step - loss: 3.5997e-05 - val_loss: 0.0083\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 17s 528ms/step - loss: 3.7263e-05 - val_loss: 0.0077\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 17s 527ms/step - loss: 3.0802e-05 - val_loss: 0.0084\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 17s 529ms/step - loss: 3.0929e-05 - val_loss: 0.0075\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 18s 531ms/step - loss: 2.9817e-05 - val_loss: 0.0109\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 17s 528ms/step - loss: 3.2682e-05 - val_loss: 0.0093\n",
      "Epoch 58/100\n",
      "33/33 [==============================] - 17s 524ms/step - loss: 2.8571e-05 - val_loss: 0.0086\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 17s 529ms/step - loss: 2.8916e-05 - val_loss: 0.0082\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 17s 528ms/step - loss: 2.7225e-05 - val_loss: 0.0091\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 17s 528ms/step - loss: 2.7255e-05 - val_loss: 0.0076\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 18s 536ms/step - loss: 2.7011e-05 - val_loss: 0.0073\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 17s 526ms/step - loss: 2.7779e-05 - val_loss: 0.0050\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 17s 528ms/step - loss: 2.6702e-05 - val_loss: 0.0056\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 17s 530ms/step - loss: 2.8859e-05 - val_loss: 0.0032\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 18s 531ms/step - loss: 2.6714e-05 - val_loss: 0.0064\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 17s 527ms/step - loss: 2.4452e-05 - val_loss: 0.0064\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 17s 526ms/step - loss: 2.4436e-05 - val_loss: 0.0068\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 18s 531ms/step - loss: 2.4884e-05 - val_loss: 0.0049\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 17s 528ms/step - loss: 2.5191e-05 - val_loss: 0.0086\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 17s 526ms/step - loss: 3.1797e-05 - val_loss: 0.0034\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 18s 530ms/step - loss: 2.6145e-05 - val_loss: 0.0064\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 17s 531ms/step - loss: 2.2936e-05 - val_loss: 0.0033\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 17s 528ms/step - loss: 2.2826e-05 - val_loss: 0.0045\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 17s 524ms/step - loss: 2.4807e-05 - val_loss: 0.0043\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 17s 531ms/step - loss: 2.2166e-05 - val_loss: 0.0029\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 18s 532ms/step - loss: 2.4171e-05 - val_loss: 0.0071\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 18s 533ms/step - loss: 2.2725e-05 - val_loss: 0.0044\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 17s 528ms/step - loss: 2.2722e-05 - val_loss: 0.0057\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 17s 527ms/step - loss: 2.4039e-05 - val_loss: 0.0057\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 17s 526ms/step - loss: 2.4663e-05 - val_loss: 0.0087\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 17s 530ms/step - loss: 2.4401e-05 - val_loss: 0.0051\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 17s 528ms/step - loss: 2.2133e-05 - val_loss: 0.0054\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 18s 533ms/step - loss: 2.5787e-05 - val_loss: 0.0046\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 17s 523ms/step - loss: 2.0855e-05 - val_loss: 0.0058\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 18s 532ms/step - loss: 2.2484e-05 - val_loss: 0.0044\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 17s 528ms/step - loss: 2.2350e-05 - val_loss: 0.0056\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 17s 530ms/step - loss: 2.1949e-05 - val_loss: 0.0046\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 17s 524ms/step - loss: 2.4545e-05 - val_loss: 0.0044\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 17s 530ms/step - loss: 2.2220e-05 - val_loss: 0.0051\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 17s 527ms/step - loss: 2.9631e-05 - val_loss: 0.0021\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 17s 525ms/step - loss: 3.5833e-05 - val_loss: 0.0045\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 17s 531ms/step - loss: 2.5708e-05 - val_loss: 0.0042\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 17s 525ms/step - loss: 2.2001e-05 - val_loss: 0.0036\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 18s 538ms/step - loss: 2.1343e-05 - val_loss: 0.0041\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 17s 529ms/step - loss: 2.0727e-05 - val_loss: 0.0045\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 17s 530ms/step - loss: 2.0504e-05 - val_loss: 0.0044\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 18s 542ms/step - loss: 2.1077e-05 - val_loss: 0.0072\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 18s 534ms/step - loss: 2.3660e-05 - val_loss: 0.0028\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 18s 533ms/step - loss: 2.3494e-05 - val_loss: 0.0050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_90_layer_call_fn, lstm_cell_90_layer_call_and_return_conditional_losses, lstm_cell_91_layer_call_fn, lstm_cell_91_layer_call_and_return_conditional_losses, lstm_cell_92_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/BTC\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/BTC\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 7s 79ms/step\n",
      "20/20 [==============================] - 2s 78ms/step\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Epoch 1/100\n",
      "19/19 [==============================] - 19s 681ms/step - loss: 0.0080 - val_loss: 0.0249\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 11s 594ms/step - loss: 0.0016 - val_loss: 0.0079\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - 11s 593ms/step - loss: 0.0013 - val_loss: 0.0131\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 11s 588ms/step - loss: 0.0016 - val_loss: 0.0060\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 11s 593ms/step - loss: 0.0013 - val_loss: 0.0065\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 11s 596ms/step - loss: 0.0010 - val_loss: 0.0086\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 11s 603ms/step - loss: 0.0010 - val_loss: 0.0054\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 12s 621ms/step - loss: 0.0010 - val_loss: 0.0066\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 11s 598ms/step - loss: 8.3803e-04 - val_loss: 0.0068\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 12s 608ms/step - loss: 8.5072e-04 - val_loss: 0.0054\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 11s 596ms/step - loss: 7.5242e-04 - val_loss: 0.0047\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 11s 592ms/step - loss: 6.6442e-04 - val_loss: 0.0048\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 11s 602ms/step - loss: 6.0010e-04 - val_loss: 0.0058\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 12s 611ms/step - loss: 4.0684e-04 - val_loss: 0.0087\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 11s 594ms/step - loss: 3.1314e-04 - val_loss: 0.0128\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 12s 605ms/step - loss: 3.3487e-04 - val_loss: 0.0077\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 12s 609ms/step - loss: 3.4771e-04 - val_loss: 0.0192\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 12s 613ms/step - loss: 2.8726e-04 - val_loss: 0.0119\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 11s 593ms/step - loss: 3.2928e-04 - val_loss: 0.0176\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 11s 589ms/step - loss: 3.4036e-04 - val_loss: 0.0167\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 12s 604ms/step - loss: 2.9525e-04 - val_loss: 0.0095\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - 12s 607ms/step - loss: 2.7481e-04 - val_loss: 0.0114\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 12s 614ms/step - loss: 2.7479e-04 - val_loss: 0.0097\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 11s 598ms/step - loss: 2.5461e-04 - val_loss: 0.0126\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 11s 594ms/step - loss: 2.7608e-04 - val_loss: 0.0153\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 11s 596ms/step - loss: 2.7926e-04 - val_loss: 0.0159\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 11s 585ms/step - loss: 2.6083e-04 - val_loss: 0.0127\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 11s 601ms/step - loss: 2.4962e-04 - val_loss: 0.0122\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - 11s 594ms/step - loss: 2.5763e-04 - val_loss: 0.0141\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 11s 592ms/step - loss: 2.8322e-04 - val_loss: 0.0073\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 11s 599ms/step - loss: 2.8151e-04 - val_loss: 0.0099\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 11s 587ms/step - loss: 2.6528e-04 - val_loss: 0.0149\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 11s 598ms/step - loss: 2.6522e-04 - val_loss: 0.0089\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 11s 600ms/step - loss: 2.3847e-04 - val_loss: 0.0075\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 11s 591ms/step - loss: 2.8377e-04 - val_loss: 0.0063\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 11s 598ms/step - loss: 2.8900e-04 - val_loss: 0.0078\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 11s 593ms/step - loss: 2.4935e-04 - val_loss: 0.0081\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 11s 603ms/step - loss: 2.8496e-04 - val_loss: 0.0084\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 11s 592ms/step - loss: 2.6080e-04 - val_loss: 0.0066\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 11s 594ms/step - loss: 2.9229e-04 - val_loss: 0.0077\n",
      "Epoch 41/100\n",
      "19/19 [==============================] - 11s 595ms/step - loss: 3.0156e-04 - val_loss: 0.0063\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 12s 613ms/step - loss: 2.5064e-04 - val_loss: 0.0070\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 11s 592ms/step - loss: 2.2957e-04 - val_loss: 0.0106\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 11s 591ms/step - loss: 2.1406e-04 - val_loss: 0.0135\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 11s 595ms/step - loss: 3.0400e-04 - val_loss: 0.0068\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 11s 593ms/step - loss: 2.6938e-04 - val_loss: 0.0077\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 11s 597ms/step - loss: 2.4985e-04 - val_loss: 0.0059\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - 11s 595ms/step - loss: 2.2471e-04 - val_loss: 0.0068\n",
      "Epoch 49/100\n",
      "19/19 [==============================] - 11s 600ms/step - loss: 2.4552e-04 - val_loss: 0.0068\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 11s 590ms/step - loss: 2.3590e-04 - val_loss: 0.0089\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - 11s 599ms/step - loss: 2.2424e-04 - val_loss: 0.0093\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 11s 593ms/step - loss: 2.5459e-04 - val_loss: 0.0048\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 12s 656ms/step - loss: 2.5626e-04 - val_loss: 0.0077\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 12s 635ms/step - loss: 2.4034e-04 - val_loss: 0.0105\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 12s 630ms/step - loss: 2.4307e-04 - val_loss: 0.0117\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 11s 589ms/step - loss: 2.8029e-04 - val_loss: 0.0076\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 11s 605ms/step - loss: 2.3513e-04 - val_loss: 0.0150\n",
      "Epoch 58/100\n",
      "19/19 [==============================] - 11s 588ms/step - loss: 2.8955e-04 - val_loss: 0.0069\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 11s 591ms/step - loss: 2.5289e-04 - val_loss: 0.0054\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 11s 593ms/step - loss: 2.4256e-04 - val_loss: 0.0074\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 12s 618ms/step - loss: 2.1383e-04 - val_loss: 0.0137\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 11s 585ms/step - loss: 2.5102e-04 - val_loss: 0.0072\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 11s 594ms/step - loss: 2.5144e-04 - val_loss: 0.0084\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - 11s 587ms/step - loss: 2.0375e-04 - val_loss: 0.0075\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - 11s 599ms/step - loss: 2.1902e-04 - val_loss: 0.0055\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - 11s 590ms/step - loss: 1.9910e-04 - val_loss: 0.0092\n",
      "Epoch 67/100\n",
      "19/19 [==============================] - 11s 594ms/step - loss: 2.1555e-04 - val_loss: 0.0080\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - 11s 596ms/step - loss: 1.9601e-04 - val_loss: 0.0095\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - 11s 588ms/step - loss: 2.0115e-04 - val_loss: 0.0054\n",
      "Epoch 70/100\n",
      "19/19 [==============================] - 11s 594ms/step - loss: 2.0588e-04 - val_loss: 0.0060\n",
      "Epoch 71/100\n",
      "19/19 [==============================] - 11s 596ms/step - loss: 2.0299e-04 - val_loss: 0.0083\n",
      "Epoch 72/100\n",
      "19/19 [==============================] - 11s 605ms/step - loss: 1.9001e-04 - val_loss: 0.0065\n",
      "Epoch 73/100\n",
      "19/19 [==============================] - 13s 670ms/step - loss: 1.9363e-04 - val_loss: 0.0046\n",
      "Epoch 74/100\n",
      "19/19 [==============================] - 12s 642ms/step - loss: 1.8989e-04 - val_loss: 0.0061\n",
      "Epoch 75/100\n",
      "19/19 [==============================] - 11s 598ms/step - loss: 1.8760e-04 - val_loss: 0.0056\n",
      "Epoch 76/100\n",
      "19/19 [==============================] - 12s 608ms/step - loss: 2.4695e-04 - val_loss: 0.0043\n",
      "Epoch 77/100\n",
      "19/19 [==============================] - 11s 588ms/step - loss: 2.1585e-04 - val_loss: 0.0052\n",
      "Epoch 78/100\n",
      "19/19 [==============================] - 11s 593ms/step - loss: 1.8404e-04 - val_loss: 0.0061\n",
      "Epoch 79/100\n",
      "19/19 [==============================] - 11s 598ms/step - loss: 1.9222e-04 - val_loss: 0.0058\n",
      "Epoch 80/100\n",
      "19/19 [==============================] - 11s 591ms/step - loss: 2.2279e-04 - val_loss: 0.0045\n",
      "Epoch 81/100\n",
      "19/19 [==============================] - 12s 608ms/step - loss: 2.2923e-04 - val_loss: 0.0046\n",
      "Epoch 82/100\n",
      "19/19 [==============================] - 11s 592ms/step - loss: 2.2556e-04 - val_loss: 0.0060\n",
      "Epoch 83/100\n",
      "19/19 [==============================] - 11s 597ms/step - loss: 1.9846e-04 - val_loss: 0.0043\n",
      "Epoch 84/100\n",
      "19/19 [==============================] - 11s 595ms/step - loss: 2.1630e-04 - val_loss: 0.0058\n",
      "Epoch 85/100\n",
      "19/19 [==============================] - 11s 594ms/step - loss: 2.2695e-04 - val_loss: 0.0053\n",
      "Epoch 86/100\n",
      "19/19 [==============================] - 12s 616ms/step - loss: 2.2723e-04 - val_loss: 0.0065\n",
      "Epoch 87/100\n",
      "19/19 [==============================] - 11s 593ms/step - loss: 2.2814e-04 - val_loss: 0.0061\n",
      "Epoch 88/100\n",
      "19/19 [==============================] - 11s 591ms/step - loss: 1.8161e-04 - val_loss: 0.0056\n",
      "Epoch 89/100\n",
      "19/19 [==============================] - 11s 599ms/step - loss: 1.7923e-04 - val_loss: 0.0058\n",
      "Epoch 90/100\n",
      "19/19 [==============================] - 12s 620ms/step - loss: 2.0676e-04 - val_loss: 0.0041\n",
      "Epoch 91/100\n",
      "19/19 [==============================] - 11s 594ms/step - loss: 2.0901e-04 - val_loss: 0.0038\n",
      "Epoch 92/100\n",
      "19/19 [==============================] - 11s 598ms/step - loss: 2.0165e-04 - val_loss: 0.0041\n",
      "Epoch 93/100\n",
      "19/19 [==============================] - 11s 588ms/step - loss: 1.7566e-04 - val_loss: 0.0050\n",
      "Epoch 94/100\n",
      "19/19 [==============================] - 11s 588ms/step - loss: 1.8856e-04 - val_loss: 0.0047\n",
      "Epoch 95/100\n",
      "19/19 [==============================] - 11s 595ms/step - loss: 1.7033e-04 - val_loss: 0.0043\n",
      "Epoch 96/100\n",
      "19/19 [==============================] - 11s 591ms/step - loss: 1.8488e-04 - val_loss: 0.0039\n",
      "Epoch 97/100\n",
      "19/19 [==============================] - 12s 606ms/step - loss: 1.7885e-04 - val_loss: 0.0047\n",
      "Epoch 98/100\n",
      "19/19 [==============================] - 11s 590ms/step - loss: 1.8043e-04 - val_loss: 0.0065\n",
      "Epoch 99/100\n",
      "19/19 [==============================] - 11s 589ms/step - loss: 1.5918e-04 - val_loss: 0.0062\n",
      "Epoch 100/100\n",
      "19/19 [==============================] - 11s 601ms/step - loss: 2.3391e-04 - val_loss: 0.0040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_93_layer_call_fn, lstm_cell_93_layer_call_and_return_conditional_losses, lstm_cell_94_layer_call_fn, lstm_cell_94_layer_call_and_return_conditional_losses, lstm_cell_95_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/ETH\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/ETH\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 5s 78ms/step\n",
      "11/11 [==============================] - 1s 80ms/step\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Epoch 1/100\n",
      "19/19 [==============================] - 18s 651ms/step - loss: 0.0180 - val_loss: 6.0507e-05\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 11s 576ms/step - loss: 0.0023 - val_loss: 3.7127e-05\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - 11s 573ms/step - loss: 0.0019 - val_loss: 6.9301e-05\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 11s 569ms/step - loss: 0.0019 - val_loss: 1.6418e-04\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 11s 570ms/step - loss: 0.0019 - val_loss: 1.0222e-04\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 11s 567ms/step - loss: 0.0018 - val_loss: 4.1931e-05\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 11s 570ms/step - loss: 0.0018 - val_loss: 2.2215e-05\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 11s 569ms/step - loss: 0.0018 - val_loss: 1.3107e-04\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 11s 572ms/step - loss: 0.0017 - val_loss: 4.8917e-05\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 11s 567ms/step - loss: 0.0017 - val_loss: 2.3968e-05\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 11s 564ms/step - loss: 0.0017 - val_loss: 3.6813e-05\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 11s 584ms/step - loss: 0.0017 - val_loss: 5.3562e-05\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 11s 568ms/step - loss: 0.0017 - val_loss: 1.0888e-04\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 11s 572ms/step - loss: 0.0017 - val_loss: 3.2939e-04\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 11s 564ms/step - loss: 0.0017 - val_loss: 4.1924e-05\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 11s 567ms/step - loss: 0.0016 - val_loss: 5.6816e-05\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 11s 573ms/step - loss: 0.0017 - val_loss: 1.8171e-05\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 11s 561ms/step - loss: 0.0017 - val_loss: 3.8458e-05\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 11s 567ms/step - loss: 0.0016 - val_loss: 1.4033e-04\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 11s 575ms/step - loss: 0.0016 - val_loss: 1.1069e-04\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 11s 572ms/step - loss: 0.0017 - val_loss: 3.4033e-05\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - 11s 570ms/step - loss: 0.0016 - val_loss: 8.1604e-05\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 11s 565ms/step - loss: 0.0016 - val_loss: 1.5102e-04\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 11s 562ms/step - loss: 0.0016 - val_loss: 5.0808e-04\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 11s 572ms/step - loss: 0.0016 - val_loss: 4.0628e-05\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 11s 574ms/step - loss: 0.0015 - val_loss: 1.2197e-04\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 11s 590ms/step - loss: 0.0016 - val_loss: 2.0473e-04\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 11s 561ms/step - loss: 0.0015 - val_loss: 4.2170e-05\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - 11s 557ms/step - loss: 0.0016 - val_loss: 5.0092e-05\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 11s 560ms/step - loss: 0.0016 - val_loss: 3.2847e-05\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 11s 562ms/step - loss: 0.0015 - val_loss: 2.0759e-05\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 11s 553ms/step - loss: 0.0015 - val_loss: 1.6024e-04\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 11s 563ms/step - loss: 0.0016 - val_loss: 4.6521e-05\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 11s 561ms/step - loss: 0.0015 - val_loss: 1.6595e-05\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 10s 547ms/step - loss: 0.0015 - val_loss: 2.5811e-04\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 10s 551ms/step - loss: 0.0015 - val_loss: 1.7624e-04\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 10s 550ms/step - loss: 0.0016 - val_loss: 1.1967e-04\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 11s 567ms/step - loss: 0.0015 - val_loss: 2.2533e-05\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 10s 550ms/step - loss: 0.0015 - val_loss: 1.4992e-04\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 10s 543ms/step - loss: 0.0015 - val_loss: 2.1057e-04\n",
      "Epoch 41/100\n",
      "19/19 [==============================] - 11s 568ms/step - loss: 0.0015 - val_loss: 2.8527e-04\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 11s 569ms/step - loss: 0.0015 - val_loss: 1.6382e-05\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 11s 564ms/step - loss: 0.0015 - val_loss: 4.0813e-05\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 11s 567ms/step - loss: 0.0014 - val_loss: 3.8737e-05\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 10s 549ms/step - loss: 0.0015 - val_loss: 6.1803e-05\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 11s 553ms/step - loss: 0.0015 - val_loss: 1.0362e-04\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 11s 560ms/step - loss: 0.0014 - val_loss: 2.2880e-05\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - 11s 559ms/step - loss: 0.0015 - val_loss: 7.8453e-05\n",
      "Epoch 49/100\n",
      "19/19 [==============================] - 11s 565ms/step - loss: 0.0014 - val_loss: 2.0617e-05\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 11s 552ms/step - loss: 0.0014 - val_loss: 3.8149e-04\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - 11s 573ms/step - loss: 0.0016 - val_loss: 2.4818e-04\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 11s 572ms/step - loss: 0.0015 - val_loss: 1.4392e-04\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 11s 563ms/step - loss: 0.0014 - val_loss: 5.4605e-05\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 11s 578ms/step - loss: 0.0014 - val_loss: 1.4268e-05\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 11s 563ms/step - loss: 0.0014 - val_loss: 3.4431e-05\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 10s 549ms/step - loss: 0.0014 - val_loss: 1.7776e-05\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 10s 547ms/step - loss: 0.0014 - val_loss: 1.4898e-05\n",
      "Epoch 58/100\n",
      "19/19 [==============================] - 11s 564ms/step - loss: 0.0014 - val_loss: 3.3971e-05\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 11s 555ms/step - loss: 0.0014 - val_loss: 9.4681e-05\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 11s 570ms/step - loss: 0.0015 - val_loss: 6.5156e-05\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 11s 563ms/step - loss: 0.0014 - val_loss: 1.7607e-05\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 11s 557ms/step - loss: 0.0014 - val_loss: 1.0700e-04\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 10s 549ms/step - loss: 0.0013 - val_loss: 2.6525e-05\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - 10s 547ms/step - loss: 0.0014 - val_loss: 6.1286e-05\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - 10s 547ms/step - loss: 0.0013 - val_loss: 1.6002e-05\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - 11s 554ms/step - loss: 0.0013 - val_loss: 4.0033e-05\n",
      "Epoch 67/100\n",
      "19/19 [==============================] - 11s 567ms/step - loss: 0.0013 - val_loss: 1.0968e-04\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - 11s 560ms/step - loss: 0.0014 - val_loss: 1.1733e-04\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - 11s 564ms/step - loss: 0.0013 - val_loss: 5.9387e-05\n",
      "Epoch 70/100\n",
      "19/19 [==============================] - 11s 564ms/step - loss: 0.0013 - val_loss: 3.2043e-05\n",
      "Epoch 71/100\n",
      "19/19 [==============================] - 12s 638ms/step - loss: 0.0013 - val_loss: 1.4060e-05\n",
      "Epoch 72/100\n",
      "19/19 [==============================] - 12s 610ms/step - loss: 0.0013 - val_loss: 2.7969e-04\n",
      "Epoch 73/100\n",
      "19/19 [==============================] - 11s 573ms/step - loss: 0.0014 - val_loss: 9.1649e-05\n",
      "Epoch 74/100\n",
      "19/19 [==============================] - 11s 565ms/step - loss: 0.0013 - val_loss: 2.5558e-05\n",
      "Epoch 75/100\n",
      "19/19 [==============================] - 11s 564ms/step - loss: 0.0013 - val_loss: 3.2660e-05\n",
      "Epoch 76/100\n",
      "19/19 [==============================] - 11s 571ms/step - loss: 0.0013 - val_loss: 2.0728e-05\n",
      "Epoch 77/100\n",
      "19/19 [==============================] - 11s 575ms/step - loss: 0.0013 - val_loss: 1.3341e-05\n",
      "Epoch 78/100\n",
      "19/19 [==============================] - 11s 573ms/step - loss: 0.0013 - val_loss: 2.0012e-05\n",
      "Epoch 79/100\n",
      "19/19 [==============================] - 11s 568ms/step - loss: 0.0013 - val_loss: 1.4012e-04\n",
      "Epoch 80/100\n",
      "19/19 [==============================] - 11s 562ms/step - loss: 0.0013 - val_loss: 2.5670e-05\n",
      "Epoch 81/100\n",
      "19/19 [==============================] - 11s 570ms/step - loss: 0.0014 - val_loss: 1.8811e-05\n",
      "Epoch 82/100\n",
      "19/19 [==============================] - 11s 568ms/step - loss: 0.0013 - val_loss: 1.5474e-05\n",
      "Epoch 83/100\n",
      "19/19 [==============================] - 11s 579ms/step - loss: 0.0013 - val_loss: 1.6574e-05\n",
      "Epoch 84/100\n",
      "19/19 [==============================] - 11s 573ms/step - loss: 0.0013 - val_loss: 8.3598e-05\n",
      "Epoch 85/100\n",
      "19/19 [==============================] - 11s 567ms/step - loss: 0.0013 - val_loss: 1.4674e-05\n",
      "Epoch 86/100\n",
      "19/19 [==============================] - 11s 572ms/step - loss: 0.0012 - val_loss: 2.0582e-05\n",
      "Epoch 87/100\n",
      "19/19 [==============================] - 11s 571ms/step - loss: 0.0012 - val_loss: 1.4553e-04\n",
      "Epoch 88/100\n",
      "19/19 [==============================] - 11s 580ms/step - loss: 0.0013 - val_loss: 2.5646e-04\n",
      "Epoch 89/100\n",
      "19/19 [==============================] - 11s 569ms/step - loss: 0.0013 - val_loss: 4.0042e-05\n",
      "Epoch 90/100\n",
      "19/19 [==============================] - 11s 568ms/step - loss: 0.0013 - val_loss: 1.2638e-05\n",
      "Epoch 91/100\n",
      "19/19 [==============================] - 11s 568ms/step - loss: 0.0013 - val_loss: 8.0919e-05\n",
      "Epoch 92/100\n",
      "19/19 [==============================] - 11s 571ms/step - loss: 0.0013 - val_loss: 1.1351e-04\n",
      "Epoch 93/100\n",
      "19/19 [==============================] - 11s 571ms/step - loss: 0.0013 - val_loss: 2.7207e-05\n",
      "Epoch 94/100\n",
      "19/19 [==============================] - 11s 574ms/step - loss: 0.0012 - val_loss: 2.3545e-05\n",
      "Epoch 95/100\n",
      "19/19 [==============================] - 11s 583ms/step - loss: 0.0012 - val_loss: 5.0425e-05\n",
      "Epoch 96/100\n",
      "19/19 [==============================] - 11s 571ms/step - loss: 0.0013 - val_loss: 3.8311e-04\n",
      "Epoch 97/100\n",
      "19/19 [==============================] - 11s 565ms/step - loss: 0.0014 - val_loss: 9.2212e-05\n",
      "Epoch 98/100\n",
      "19/19 [==============================] - 11s 598ms/step - loss: 0.0013 - val_loss: 2.4036e-05\n",
      "Epoch 99/100\n",
      "19/19 [==============================] - 11s 568ms/step - loss: 0.0012 - val_loss: 1.1172e-04\n",
      "Epoch 100/100\n",
      "19/19 [==============================] - 11s 572ms/step - loss: 0.0013 - val_loss: 3.3859e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_96_layer_call_fn, lstm_cell_96_layer_call_and_return_conditional_losses, lstm_cell_97_layer_call_fn, lstm_cell_97_layer_call_and_return_conditional_losses, lstm_cell_98_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/USDT\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/USDT\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 5s 77ms/step\n",
      "11/11 [==============================] - 1s 80ms/step\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Epoch 1/100\n",
      "15/15 [==============================] - 16s 593ms/step - loss: 0.0582 - val_loss: 0.0056\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 7s 480ms/step - loss: 0.0083 - val_loss: 0.0028\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 7s 487ms/step - loss: 0.0046 - val_loss: 5.5709e-04\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 7s 483ms/step - loss: 0.0042 - val_loss: 4.2828e-05\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 7s 483ms/step - loss: 0.0041 - val_loss: 5.3882e-05\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 7s 476ms/step - loss: 0.0040 - val_loss: 1.4276e-04\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 7s 479ms/step - loss: 0.0039 - val_loss: 2.6989e-05\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 7s 478ms/step - loss: 0.0039 - val_loss: 1.1961e-04\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 7s 482ms/step - loss: 0.0039 - val_loss: 2.8591e-04\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 7s 484ms/step - loss: 0.0038 - val_loss: 2.1251e-04\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 7s 474ms/step - loss: 0.0038 - val_loss: 7.6788e-05\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 7s 489ms/step - loss: 0.0037 - val_loss: 8.2619e-05\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 7s 480ms/step - loss: 0.0037 - val_loss: 7.2713e-05\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 7s 480ms/step - loss: 0.0036 - val_loss: 2.8443e-04\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 7s 480ms/step - loss: 0.0036 - val_loss: 2.8466e-05\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 7s 482ms/step - loss: 0.0035 - val_loss: 1.9576e-04\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 7s 478ms/step - loss: 0.0036 - val_loss: 3.2474e-05\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 7s 486ms/step - loss: 0.0034 - val_loss: 3.4077e-05\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 7s 484ms/step - loss: 0.0033 - val_loss: 1.3124e-04\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 7s 482ms/step - loss: 0.0033 - val_loss: 2.2116e-04\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 7s 487ms/step - loss: 0.0032 - val_loss: 3.2034e-05\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 7s 480ms/step - loss: 0.0033 - val_loss: 9.4998e-04\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 7s 490ms/step - loss: 0.0033 - val_loss: 2.4878e-05\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 7s 480ms/step - loss: 0.0033 - val_loss: 4.0581e-04\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 7s 490ms/step - loss: 0.0032 - val_loss: 7.6288e-05\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 7s 489ms/step - loss: 0.0032 - val_loss: 2.7957e-05\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 7s 489ms/step - loss: 0.0033 - val_loss: 6.3398e-04\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 7s 487ms/step - loss: 0.0032 - val_loss: 4.0662e-05\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 7s 485ms/step - loss: 0.0031 - val_loss: 7.7381e-05\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 7s 485ms/step - loss: 0.0030 - val_loss: 5.7511e-05\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 7s 487ms/step - loss: 0.0030 - val_loss: 4.1206e-05\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 7s 491ms/step - loss: 0.0030 - val_loss: 9.5169e-05\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 7s 484ms/step - loss: 0.0030 - val_loss: 6.1688e-05\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 7s 491ms/step - loss: 0.0030 - val_loss: 1.2022e-04\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 7s 488ms/step - loss: 0.0030 - val_loss: 1.2806e-04\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 7s 487ms/step - loss: 0.0030 - val_loss: 8.8084e-05\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 7s 488ms/step - loss: 0.0030 - val_loss: 1.3630e-04\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 7s 477ms/step - loss: 0.0030 - val_loss: 1.3522e-04\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 7s 448ms/step - loss: 0.0030 - val_loss: 5.6596e-05\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 7s 448ms/step - loss: 0.0030 - val_loss: 2.9836e-04\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 7s 456ms/step - loss: 0.0029 - val_loss: 2.6516e-05\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 7s 450ms/step - loss: 0.0030 - val_loss: 2.7077e-05\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 7s 456ms/step - loss: 0.0029 - val_loss: 3.3438e-04\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 7s 453ms/step - loss: 0.0031 - val_loss: 1.9794e-04\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 7s 449ms/step - loss: 0.0030 - val_loss: 5.5668e-05\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 7s 457ms/step - loss: 0.0032 - val_loss: 3.0761e-05\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 7s 444ms/step - loss: 0.0033 - val_loss: 1.3246e-04\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 7s 443ms/step - loss: 0.0029 - val_loss: 2.7195e-05\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 7s 440ms/step - loss: 0.0028 - val_loss: 7.4425e-05\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 7s 444ms/step - loss: 0.0028 - val_loss: 6.5776e-05\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 7s 455ms/step - loss: 0.0028 - val_loss: 5.4047e-05\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 7s 455ms/step - loss: 0.0028 - val_loss: 8.2172e-05\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 7s 479ms/step - loss: 0.0028 - val_loss: 8.4071e-05\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 7s 465ms/step - loss: 0.0028 - val_loss: 1.1007e-04\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 7s 452ms/step - loss: 0.0028 - val_loss: 7.3992e-05\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 7s 450ms/step - loss: 0.0028 - val_loss: 7.6206e-05\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 7s 449ms/step - loss: 0.0028 - val_loss: 7.9280e-05\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 7s 447ms/step - loss: 0.0027 - val_loss: 1.4515e-04\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 7s 449ms/step - loss: 0.0027 - val_loss: 4.8240e-05\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 7s 446ms/step - loss: 0.0027 - val_loss: 7.0056e-05\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 7s 448ms/step - loss: 0.0027 - val_loss: 2.5315e-05\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 7s 446ms/step - loss: 0.0027 - val_loss: 2.4768e-05\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 7s 449ms/step - loss: 0.0026 - val_loss: 2.8198e-05\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 7s 447ms/step - loss: 0.0027 - val_loss: 5.8306e-05\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 7s 448ms/step - loss: 0.0027 - val_loss: 1.0764e-04\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 7s 447ms/step - loss: 0.0026 - val_loss: 5.0910e-05\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 7s 452ms/step - loss: 0.0027 - val_loss: 4.6669e-05\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 7s 448ms/step - loss: 0.0026 - val_loss: 2.9860e-04\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 7s 447ms/step - loss: 0.0029 - val_loss: 7.8124e-04\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 7s 449ms/step - loss: 0.0028 - val_loss: 3.7365e-05\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 7s 450ms/step - loss: 0.0027 - val_loss: 2.2785e-04\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 7s 454ms/step - loss: 0.0026 - val_loss: 2.5601e-04\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 7s 443ms/step - loss: 0.0027 - val_loss: 7.6016e-05\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 7s 457ms/step - loss: 0.0026 - val_loss: 1.6337e-04\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 7s 445ms/step - loss: 0.0027 - val_loss: 1.1727e-04\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 7s 452ms/step - loss: 0.0026 - val_loss: 7.8131e-05\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 7s 443ms/step - loss: 0.0026 - val_loss: 3.0288e-04\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 7s 458ms/step - loss: 0.0028 - val_loss: 7.3397e-05\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 7s 449ms/step - loss: 0.0026 - val_loss: 2.7209e-04\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 7s 463ms/step - loss: 0.0026 - val_loss: 2.4647e-05\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 7s 454ms/step - loss: 0.0025 - val_loss: 3.4246e-04\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 7s 447ms/step - loss: 0.0025 - val_loss: 6.9381e-05\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 7s 452ms/step - loss: 0.0026 - val_loss: 2.6127e-05\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 7s 451ms/step - loss: 0.0025 - val_loss: 2.4968e-05\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 7s 444ms/step - loss: 0.0025 - val_loss: 5.7238e-05\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 7s 452ms/step - loss: 0.0025 - val_loss: 2.1782e-04\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 7s 454ms/step - loss: 0.0025 - val_loss: 4.8894e-04\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 7s 451ms/step - loss: 0.0026 - val_loss: 2.7279e-04\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 7s 444ms/step - loss: 0.0025 - val_loss: 2.5360e-05\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 7s 448ms/step - loss: 0.0026 - val_loss: 8.7826e-05\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 7s 442ms/step - loss: 0.0026 - val_loss: 3.1014e-04\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 7s 454ms/step - loss: 0.0027 - val_loss: 1.8936e-04\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 7s 445ms/step - loss: 0.0025 - val_loss: 1.0196e-04\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 7s 452ms/step - loss: 0.0027 - val_loss: 3.0269e-04\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 7s 454ms/step - loss: 0.0025 - val_loss: 3.5320e-05\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 7s 450ms/step - loss: 0.0025 - val_loss: 2.9792e-04\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 7s 448ms/step - loss: 0.0026 - val_loss: 8.0809e-05\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 7s 446ms/step - loss: 0.0025 - val_loss: 2.5769e-04\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 7s 457ms/step - loss: 0.0025 - val_loss: 2.4806e-05\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 7s 463ms/step - loss: 0.0025 - val_loss: 7.6671e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_99_layer_call_fn, lstm_cell_99_layer_call_and_return_conditional_losses, lstm_cell_100_layer_call_fn, lstm_cell_100_layer_call_and_return_conditional_losses, lstm_cell_101_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/USDC\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/USDC\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 4s 82ms/step\n",
      "8/8 [==============================] - 1s 84ms/step\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Epoch 1/100\n",
      "19/19 [==============================] - 18s 654ms/step - loss: 0.0109 - val_loss: 0.0080\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 11s 599ms/step - loss: 0.0033 - val_loss: 0.0062\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - 11s 588ms/step - loss: 0.0026 - val_loss: 0.0068\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 11s 596ms/step - loss: 0.0017 - val_loss: 0.0061\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 11s 577ms/step - loss: 0.0016 - val_loss: 0.0120\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 11s 588ms/step - loss: 0.0015 - val_loss: 0.0102\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 11s 568ms/step - loss: 0.0018 - val_loss: 0.0123\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 11s 598ms/step - loss: 0.0014 - val_loss: 0.0109\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 11s 577ms/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 11s 585ms/step - loss: 0.0012 - val_loss: 0.0048\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 11s 589ms/step - loss: 0.0011 - val_loss: 0.0051\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 11s 604ms/step - loss: 0.0011 - val_loss: 0.0046\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 11s 604ms/step - loss: 9.1447e-04 - val_loss: 0.0039\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 11s 583ms/step - loss: 7.7167e-04 - val_loss: 0.0085\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 11s 568ms/step - loss: 0.0011 - val_loss: 0.0057\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 11s 592ms/step - loss: 9.3872e-04 - val_loss: 0.0041\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 11s 582ms/step - loss: 7.5498e-04 - val_loss: 0.0049\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 11s 591ms/step - loss: 6.4489e-04 - val_loss: 0.0038\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 11s 578ms/step - loss: 6.3530e-04 - val_loss: 0.0039\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 11s 588ms/step - loss: 5.7422e-04 - val_loss: 0.0036\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 11s 579ms/step - loss: 6.2999e-04 - val_loss: 0.0030\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - 11s 586ms/step - loss: 6.5569e-04 - val_loss: 0.0041\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 11s 587ms/step - loss: 7.1861e-04 - val_loss: 0.0041\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 11s 586ms/step - loss: 5.9180e-04 - val_loss: 0.0030\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 11s 582ms/step - loss: 5.7929e-04 - val_loss: 0.0030\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 11s 575ms/step - loss: 5.5839e-04 - val_loss: 0.0041\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 11s 585ms/step - loss: 5.3171e-04 - val_loss: 0.0027\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 11s 592ms/step - loss: 5.2248e-04 - val_loss: 0.0069\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - 11s 575ms/step - loss: 5.6416e-04 - val_loss: 0.0107\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 11s 583ms/step - loss: 6.5097e-04 - val_loss: 0.0067\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 11s 586ms/step - loss: 5.7847e-04 - val_loss: 0.0039\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 11s 595ms/step - loss: 5.4038e-04 - val_loss: 0.0059\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 11s 588ms/step - loss: 5.1989e-04 - val_loss: 0.0025\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 11s 586ms/step - loss: 4.8267e-04 - val_loss: 0.0038\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 11s 587ms/step - loss: 4.8702e-04 - val_loss: 0.0023\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 11s 565ms/step - loss: 4.9915e-04 - val_loss: 0.0025\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 11s 586ms/step - loss: 4.7251e-04 - val_loss: 0.0029\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 11s 586ms/step - loss: 5.3980e-04 - val_loss: 0.0054\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 11s 574ms/step - loss: 6.8617e-04 - val_loss: 0.0030\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 11s 571ms/step - loss: 5.4466e-04 - val_loss: 0.0024\n",
      "Epoch 41/100\n",
      "19/19 [==============================] - 11s 587ms/step - loss: 5.3033e-04 - val_loss: 0.0021\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 11s 584ms/step - loss: 4.7124e-04 - val_loss: 0.0022\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 11s 592ms/step - loss: 4.6998e-04 - val_loss: 0.0021\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 11s 575ms/step - loss: 4.7818e-04 - val_loss: 0.0025\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 11s 591ms/step - loss: 4.7145e-04 - val_loss: 0.0049\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 11s 573ms/step - loss: 4.4334e-04 - val_loss: 0.0049\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 11s 586ms/step - loss: 4.3994e-04 - val_loss: 0.0030\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - 11s 585ms/step - loss: 4.5286e-04 - val_loss: 0.0018\n",
      "Epoch 49/100\n",
      "19/19 [==============================] - 11s 582ms/step - loss: 4.6847e-04 - val_loss: 0.0021\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 11s 591ms/step - loss: 3.9214e-04 - val_loss: 0.0016\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - 12s 607ms/step - loss: 4.3897e-04 - val_loss: 0.0049\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 11s 571ms/step - loss: 4.2945e-04 - val_loss: 0.0034\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 11s 583ms/step - loss: 4.8275e-04 - val_loss: 0.0023\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 11s 589ms/step - loss: 4.8360e-04 - val_loss: 0.0013\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 11s 575ms/step - loss: 4.8797e-04 - val_loss: 0.0020\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 11s 586ms/step - loss: 4.3651e-04 - val_loss: 0.0020\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 11s 583ms/step - loss: 4.9651e-04 - val_loss: 0.0036\n",
      "Epoch 58/100\n",
      "19/19 [==============================] - 11s 584ms/step - loss: 3.7721e-04 - val_loss: 0.0023\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 11s 586ms/step - loss: 3.9238e-04 - val_loss: 0.0015\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 11s 588ms/step - loss: 3.7232e-04 - val_loss: 0.0021\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 11s 599ms/step - loss: 4.1826e-04 - val_loss: 0.0018\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 11s 583ms/step - loss: 4.3065e-04 - val_loss: 0.0019\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 11s 595ms/step - loss: 4.5302e-04 - val_loss: 0.0015\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - 11s 592ms/step - loss: 3.6488e-04 - val_loss: 0.0036\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - 11s 576ms/step - loss: 4.0930e-04 - val_loss: 0.0015\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - 11s 598ms/step - loss: 3.6344e-04 - val_loss: 0.0019\n",
      "Epoch 67/100\n",
      "19/19 [==============================] - 11s 580ms/step - loss: 3.5959e-04 - val_loss: 0.0014\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - 11s 597ms/step - loss: 3.4084e-04 - val_loss: 0.0014\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - 1120s 62s/step - loss: 4.1222e-04 - val_loss: 0.0014\n",
      "Epoch 70/100\n",
      "19/19 [==============================] - 18s 949ms/step - loss: 3.7034e-04 - val_loss: 0.0013\n",
      "Epoch 71/100\n",
      "19/19 [==============================] - 12s 618ms/step - loss: 3.3432e-04 - val_loss: 0.0020\n",
      "Epoch 72/100\n",
      "19/19 [==============================] - 12s 609ms/step - loss: 3.4082e-04 - val_loss: 0.0014\n",
      "Epoch 73/100\n",
      "19/19 [==============================] - 12s 617ms/step - loss: 3.6374e-04 - val_loss: 0.0011\n",
      "Epoch 74/100\n",
      "19/19 [==============================] - 12s 637ms/step - loss: 3.3875e-04 - val_loss: 0.0011\n",
      "Epoch 75/100\n",
      "19/19 [==============================] - 12s 622ms/step - loss: 3.9913e-04 - val_loss: 0.0011\n",
      "Epoch 76/100\n",
      "19/19 [==============================] - 11s 590ms/step - loss: 3.3233e-04 - val_loss: 0.0016\n",
      "Epoch 77/100\n",
      "19/19 [==============================] - 11s 588ms/step - loss: 3.0161e-04 - val_loss: 0.0014\n",
      "Epoch 78/100\n",
      "19/19 [==============================] - 11s 583ms/step - loss: 3.0256e-04 - val_loss: 0.0028\n",
      "Epoch 79/100\n",
      "19/19 [==============================] - 12s 653ms/step - loss: 3.3783e-04 - val_loss: 0.0013\n",
      "Epoch 80/100\n",
      "19/19 [==============================] - 12s 644ms/step - loss: 3.0250e-04 - val_loss: 0.0026\n",
      "Epoch 81/100\n",
      "19/19 [==============================] - 11s 602ms/step - loss: 3.3936e-04 - val_loss: 0.0012\n",
      "Epoch 82/100\n",
      "19/19 [==============================] - 11s 583ms/step - loss: 3.5063e-04 - val_loss: 0.0032\n",
      "Epoch 83/100\n",
      "19/19 [==============================] - 11s 588ms/step - loss: 4.0592e-04 - val_loss: 0.0019\n",
      "Epoch 84/100\n",
      "19/19 [==============================] - 11s 585ms/step - loss: 3.5259e-04 - val_loss: 0.0017\n",
      "Epoch 85/100\n",
      "19/19 [==============================] - 11s 600ms/step - loss: 3.1751e-04 - val_loss: 0.0014\n",
      "Epoch 86/100\n",
      "19/19 [==============================] - 14s 739ms/step - loss: 2.9584e-04 - val_loss: 0.0027\n",
      "Epoch 87/100\n",
      "19/19 [==============================] - 12s 622ms/step - loss: 3.2071e-04 - val_loss: 0.0011\n",
      "Epoch 88/100\n",
      "19/19 [==============================] - 11s 596ms/step - loss: 3.0230e-04 - val_loss: 9.6415e-04\n",
      "Epoch 89/100\n",
      "19/19 [==============================] - 11s 601ms/step - loss: 3.7781e-04 - val_loss: 0.0016\n",
      "Epoch 90/100\n",
      "19/19 [==============================] - 11s 606ms/step - loss: 3.3763e-04 - val_loss: 0.0012\n",
      "Epoch 91/100\n",
      "19/19 [==============================] - 12s 631ms/step - loss: 2.8610e-04 - val_loss: 9.2329e-04\n",
      "Epoch 92/100\n",
      "19/19 [==============================] - 11s 595ms/step - loss: 2.9176e-04 - val_loss: 0.0013\n",
      "Epoch 93/100\n",
      "19/19 [==============================] - 11s 604ms/step - loss: 2.8878e-04 - val_loss: 0.0016\n",
      "Epoch 94/100\n",
      "19/19 [==============================] - 11s 586ms/step - loss: 2.8638e-04 - val_loss: 0.0011\n",
      "Epoch 95/100\n",
      "19/19 [==============================] - 12s 616ms/step - loss: 2.9053e-04 - val_loss: 0.0013\n",
      "Epoch 96/100\n",
      "19/19 [==============================] - 11s 603ms/step - loss: 2.8407e-04 - val_loss: 0.0010\n",
      "Epoch 97/100\n",
      "19/19 [==============================] - 11s 586ms/step - loss: 3.0742e-04 - val_loss: 0.0022\n",
      "Epoch 98/100\n",
      "19/19 [==============================] - 11s 585ms/step - loss: 3.1152e-04 - val_loss: 8.1116e-04\n",
      "Epoch 99/100\n",
      "19/19 [==============================] - 11s 588ms/step - loss: 2.9085e-04 - val_loss: 0.0013\n",
      "Epoch 100/100\n",
      "19/19 [==============================] - 12s 610ms/step - loss: 2.7300e-04 - val_loss: 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_102_layer_call_fn, lstm_cell_102_layer_call_and_return_conditional_losses, lstm_cell_103_layer_call_fn, lstm_cell_103_layer_call_and_return_conditional_losses, lstm_cell_104_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/BNB\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/BNB\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 7s 120ms/step\n",
      "11/11 [==============================] - 1s 104ms/step\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Epoch 1/100\n",
      "11/11 [==============================] - 17s 704ms/step - loss: 0.0415 - val_loss: 7.4865e-04\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 6s 528ms/step - loss: 0.0049 - val_loss: 8.3444e-04\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 6s 540ms/step - loss: 0.0026 - val_loss: 7.7598e-04\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 6s 547ms/step - loss: 0.0019 - val_loss: 3.5690e-04\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 6s 528ms/step - loss: 0.0017 - val_loss: 2.1495e-04\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 6s 525ms/step - loss: 0.0016 - val_loss: 1.2392e-04\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 6s 512ms/step - loss: 0.0016 - val_loss: 1.6705e-04\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 6s 508ms/step - loss: 0.0016 - val_loss: 1.3889e-04\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 6s 559ms/step - loss: 0.0016 - val_loss: 1.2368e-04\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 6s 516ms/step - loss: 0.0016 - val_loss: 1.6877e-04\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 6s 513ms/step - loss: 0.0016 - val_loss: 1.4714e-04\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 6s 502ms/step - loss: 0.0016 - val_loss: 1.4393e-04\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 6s 510ms/step - loss: 0.0016 - val_loss: 1.8595e-04\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 6s 504ms/step - loss: 0.0017 - val_loss: 2.5432e-04\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 6s 507ms/step - loss: 0.0016 - val_loss: 1.2515e-04\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 6s 511ms/step - loss: 0.0016 - val_loss: 1.3910e-04\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 6s 512ms/step - loss: 0.0016 - val_loss: 1.6526e-04\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 6s 512ms/step - loss: 0.0016 - val_loss: 1.4053e-04\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 6s 498ms/step - loss: 0.0016 - val_loss: 1.6230e-04\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 6s 510ms/step - loss: 0.0016 - val_loss: 4.0863e-04\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 6s 509ms/step - loss: 0.0016 - val_loss: 1.3512e-04\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 6s 507ms/step - loss: 0.0016 - val_loss: 1.2392e-04\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 6s 510ms/step - loss: 0.0016 - val_loss: 1.3427e-04\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 6s 533ms/step - loss: 0.0016 - val_loss: 1.2366e-04\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 6s 514ms/step - loss: 0.0016 - val_loss: 1.7382e-04\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 6s 509ms/step - loss: 0.0016 - val_loss: 1.2376e-04\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 6s 519ms/step - loss: 0.0016 - val_loss: 1.2427e-04\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 6s 505ms/step - loss: 0.0016 - val_loss: 1.4955e-04\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 6s 508ms/step - loss: 0.0016 - val_loss: 2.6359e-04\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 6s 505ms/step - loss: 0.0016 - val_loss: 2.8600e-04\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 6s 510ms/step - loss: 0.0016 - val_loss: 2.6266e-04\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 6s 511ms/step - loss: 0.0016 - val_loss: 1.4910e-04\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 6s 504ms/step - loss: 0.0016 - val_loss: 1.6854e-04\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 6s 505ms/step - loss: 0.0017 - val_loss: 1.2552e-04\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 6s 507ms/step - loss: 0.0016 - val_loss: 1.2511e-04\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 6s 525ms/step - loss: 0.0016 - val_loss: 1.2385e-04\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 6s 521ms/step - loss: 0.0017 - val_loss: 2.0911e-04\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 6s 503ms/step - loss: 0.0016 - val_loss: 2.1468e-04\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 6s 503ms/step - loss: 0.0016 - val_loss: 1.2855e-04\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 6s 512ms/step - loss: 0.0016 - val_loss: 2.2618e-04\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 6s 507ms/step - loss: 0.0016 - val_loss: 1.2760e-04\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 6s 500ms/step - loss: 0.0016 - val_loss: 1.3259e-04\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 6s 505ms/step - loss: 0.0016 - val_loss: 1.4254e-04\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 6s 508ms/step - loss: 0.0016 - val_loss: 1.3721e-04\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 6s 505ms/step - loss: 0.0016 - val_loss: 1.4179e-04\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 6s 507ms/step - loss: 0.0016 - val_loss: 1.7973e-04\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 6s 527ms/step - loss: 0.0016 - val_loss: 1.9308e-04\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 6s 518ms/step - loss: 0.0016 - val_loss: 1.7186e-04\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 6s 516ms/step - loss: 0.0016 - val_loss: 1.8726e-04\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 6s 506ms/step - loss: 0.0016 - val_loss: 1.3535e-04\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 6s 508ms/step - loss: 0.0016 - val_loss: 1.2368e-04\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 6s 508ms/step - loss: 0.0016 - val_loss: 1.9269e-04\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 5s 498ms/step - loss: 0.0016 - val_loss: 1.4575e-04\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 6s 526ms/step - loss: 0.0016 - val_loss: 2.4138e-04\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 6s 509ms/step - loss: 0.0017 - val_loss: 3.5240e-04\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 6s 503ms/step - loss: 0.0016 - val_loss: 2.8827e-04\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 6s 513ms/step - loss: 0.0016 - val_loss: 2.8611e-04\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 6s 515ms/step - loss: 0.0016 - val_loss: 1.4911e-04\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 6s 515ms/step - loss: 0.0016 - val_loss: 2.0234e-04\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 6s 512ms/step - loss: 0.0017 - val_loss: 1.5605e-04\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 6s 511ms/step - loss: 0.0017 - val_loss: 1.6293e-04\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 6s 498ms/step - loss: 0.0016 - val_loss: 1.9121e-04\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 6s 542ms/step - loss: 0.0016 - val_loss: 2.2871e-04\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 6s 510ms/step - loss: 0.0016 - val_loss: 2.1378e-04\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 6s 509ms/step - loss: 0.0016 - val_loss: 1.8273e-04\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 6s 509ms/step - loss: 0.0016 - val_loss: 1.3885e-04\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 6s 500ms/step - loss: 0.0016 - val_loss: 1.2374e-04\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 6s 513ms/step - loss: 0.0016 - val_loss: 1.6304e-04\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 6s 510ms/step - loss: 0.0016 - val_loss: 1.6471e-04\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 6s 506ms/step - loss: 0.0016 - val_loss: 1.4672e-04\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 6s 512ms/step - loss: 0.0016 - val_loss: 2.4357e-04\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 6s 507ms/step - loss: 0.0017 - val_loss: 3.5644e-04\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 6s 509ms/step - loss: 0.0016 - val_loss: 1.3894e-04\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 6s 507ms/step - loss: 0.0016 - val_loss: 1.2360e-04\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 6s 504ms/step - loss: 0.0016 - val_loss: 1.2440e-04\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 6s 501ms/step - loss: 0.0016 - val_loss: 1.7167e-04\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 6s 500ms/step - loss: 0.0016 - val_loss: 1.3403e-04\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 6s 532ms/step - loss: 0.0016 - val_loss: 1.3400e-04\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 6s 505ms/step - loss: 0.0016 - val_loss: 1.7595e-04\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 6s 518ms/step - loss: 0.0016 - val_loss: 1.9514e-04\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 6s 512ms/step - loss: 0.0016 - val_loss: 1.9125e-04\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 6s 506ms/step - loss: 0.0016 - val_loss: 1.6023e-04\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 6s 509ms/step - loss: 0.0016 - val_loss: 1.8123e-04\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 6s 515ms/step - loss: 0.0016 - val_loss: 1.3020e-04\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 6s 505ms/step - loss: 0.0016 - val_loss: 1.4537e-04\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 6s 503ms/step - loss: 0.0016 - val_loss: 4.7788e-04\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 6s 503ms/step - loss: 0.0017 - val_loss: 4.2928e-04\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 6s 517ms/step - loss: 0.0017 - val_loss: 1.2366e-04\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 6s 525ms/step - loss: 0.0016 - val_loss: 2.0562e-04\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 6s 520ms/step - loss: 0.0016 - val_loss: 3.0717e-04\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 6s 526ms/step - loss: 0.0016 - val_loss: 1.2495e-04\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 6s 505ms/step - loss: 0.0016 - val_loss: 1.5679e-04\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 6s 506ms/step - loss: 0.0016 - val_loss: 1.4680e-04\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 6s 500ms/step - loss: 0.0016 - val_loss: 1.2361e-04\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 6s 507ms/step - loss: 0.0016 - val_loss: 1.2429e-04\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 6s 504ms/step - loss: 0.0016 - val_loss: 2.2813e-04\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 6s 505ms/step - loss: 0.0016 - val_loss: 2.2842e-04\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 6s 505ms/step - loss: 0.0017 - val_loss: 1.3111e-04\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 6s 508ms/step - loss: 0.0017 - val_loss: 2.1807e-04\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 6s 511ms/step - loss: 0.0016 - val_loss: 1.4324e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_105_layer_call_fn, lstm_cell_105_layer_call_and_return_conditional_losses, lstm_cell_106_layer_call_fn, lstm_cell_106_layer_call_and_return_conditional_losses, lstm_cell_107_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/BUSD\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/BUSD\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 3s 83ms/step\n",
      "6/6 [==============================] - 0s 76ms/step\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Epoch 1/100\n",
      "19/19 [==============================] - 19s 701ms/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 12s 654ms/step - loss: 0.0013 - val_loss: 7.4814e-04\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - 13s 677ms/step - loss: 0.0011 - val_loss: 5.6457e-04\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 12s 653ms/step - loss: 9.8608e-04 - val_loss: 7.8773e-04\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 12s 642ms/step - loss: 8.5931e-04 - val_loss: 4.4664e-04\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 12s 632ms/step - loss: 8.1484e-04 - val_loss: 4.5677e-04\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 12s 629ms/step - loss: 8.5206e-04 - val_loss: 4.2413e-04\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 12s 647ms/step - loss: 7.2092e-04 - val_loss: 3.9251e-04\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 13s 675ms/step - loss: 6.7692e-04 - val_loss: 6.4332e-04\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 12s 663ms/step - loss: 6.3987e-04 - val_loss: 5.0230e-04\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 12s 623ms/step - loss: 6.0724e-04 - val_loss: 3.1524e-04\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 12s 618ms/step - loss: 5.3607e-04 - val_loss: 3.9638e-04\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 12s 617ms/step - loss: 5.2853e-04 - val_loss: 3.9353e-04\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 12s 622ms/step - loss: 4.9595e-04 - val_loss: 4.4139e-04\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 12s 611ms/step - loss: 4.5943e-04 - val_loss: 2.8756e-04\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 12s 611ms/step - loss: 4.2477e-04 - val_loss: 4.2105e-04\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 12s 618ms/step - loss: 4.1996e-04 - val_loss: 3.3562e-04\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 12s 644ms/step - loss: 3.9158e-04 - val_loss: 4.1622e-04\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 12s 621ms/step - loss: 3.5996e-04 - val_loss: 2.8141e-04\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 12s 616ms/step - loss: 3.5964e-04 - val_loss: 3.0868e-04\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 12s 615ms/step - loss: 3.3514e-04 - val_loss: 2.3858e-04\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - 12s 621ms/step - loss: 3.2139e-04 - val_loss: 2.3794e-04\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 12s 639ms/step - loss: 2.9726e-04 - val_loss: 4.0296e-04\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 12s 632ms/step - loss: 2.8353e-04 - val_loss: 2.2967e-04\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 13s 677ms/step - loss: 2.8634e-04 - val_loss: 2.8097e-04\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 12s 622ms/step - loss: 2.7315e-04 - val_loss: 2.2717e-04\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 12s 624ms/step - loss: 2.8155e-04 - val_loss: 2.2604e-04\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 12s 627ms/step - loss: 2.8950e-04 - val_loss: 2.3300e-04\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - 12s 631ms/step - loss: 2.6444e-04 - val_loss: 2.9760e-04\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 12s 623ms/step - loss: 2.9576e-04 - val_loss: 4.1025e-04\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 12s 621ms/step - loss: 2.8773e-04 - val_loss: 4.3102e-04\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 12s 629ms/step - loss: 2.8662e-04 - val_loss: 2.2972e-04\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 12s 626ms/step - loss: 2.7039e-04 - val_loss: 1.9766e-04\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 12s 625ms/step - loss: 2.4258e-04 - val_loss: 2.0853e-04\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 12s 617ms/step - loss: 2.4701e-04 - val_loss: 1.8800e-04\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 12s 620ms/step - loss: 2.6453e-04 - val_loss: 1.8816e-04\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 12s 618ms/step - loss: 2.4219e-04 - val_loss: 3.8419e-04\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 12s 649ms/step - loss: 2.6457e-04 - val_loss: 4.2911e-04\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 12s 630ms/step - loss: 2.3661e-04 - val_loss: 1.7709e-04\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 12s 625ms/step - loss: 2.1567e-04 - val_loss: 2.1146e-04\n",
      "Epoch 41/100\n",
      "19/19 [==============================] - 12s 621ms/step - loss: 2.3011e-04 - val_loss: 1.7758e-04\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 12s 623ms/step - loss: 2.2399e-04 - val_loss: 3.6361e-04\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 12s 633ms/step - loss: 2.2282e-04 - val_loss: 1.6501e-04\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 12s 638ms/step - loss: 2.0876e-04 - val_loss: 1.6411e-04\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 12s 629ms/step - loss: 2.2215e-04 - val_loss: 1.6229e-04\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 12s 629ms/step - loss: 2.0543e-04 - val_loss: 1.9628e-04\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 12s 620ms/step - loss: 2.1928e-04 - val_loss: 4.7947e-04\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - 12s 632ms/step - loss: 2.0700e-04 - val_loss: 1.8057e-04\n",
      "Epoch 49/100\n",
      "19/19 [==============================] - 12s 625ms/step - loss: 2.0657e-04 - val_loss: 1.8257e-04\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 12s 614ms/step - loss: 2.0876e-04 - val_loss: 1.6416e-04\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - 12s 622ms/step - loss: 2.2445e-04 - val_loss: 2.5549e-04\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 12s 627ms/step - loss: 2.0913e-04 - val_loss: 1.5089e-04\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 12s 619ms/step - loss: 1.8763e-04 - val_loss: 1.6133e-04\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 12s 637ms/step - loss: 1.9718e-04 - val_loss: 1.5701e-04\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 12s 621ms/step - loss: 1.8587e-04 - val_loss: 1.5297e-04\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 12s 643ms/step - loss: 1.9455e-04 - val_loss: 1.7121e-04\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 12s 627ms/step - loss: 1.8529e-04 - val_loss: 1.4788e-04\n",
      "Epoch 58/100\n",
      "19/19 [==============================] - 12s 620ms/step - loss: 1.9302e-04 - val_loss: 1.7500e-04\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 12s 633ms/step - loss: 1.8805e-04 - val_loss: 5.0114e-04\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 12s 614ms/step - loss: 2.1750e-04 - val_loss: 1.5651e-04\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 12s 623ms/step - loss: 1.8188e-04 - val_loss: 1.4750e-04\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 12s 630ms/step - loss: 1.7914e-04 - val_loss: 3.5051e-04\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 12s 634ms/step - loss: 2.2437e-04 - val_loss: 2.6082e-04\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - 12s 634ms/step - loss: 2.0319e-04 - val_loss: 2.5374e-04\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - 12s 625ms/step - loss: 1.9941e-04 - val_loss: 1.4877e-04\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - 12s 620ms/step - loss: 1.8170e-04 - val_loss: 1.5677e-04\n",
      "Epoch 67/100\n",
      "19/19 [==============================] - 12s 634ms/step - loss: 1.9276e-04 - val_loss: 2.0035e-04\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - 12s 640ms/step - loss: 1.9282e-04 - val_loss: 2.1161e-04\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - 12s 647ms/step - loss: 2.0977e-04 - val_loss: 3.0878e-04\n",
      "Epoch 70/100\n",
      "19/19 [==============================] - 13s 665ms/step - loss: 2.2314e-04 - val_loss: 1.6888e-04\n",
      "Epoch 71/100\n",
      "19/19 [==============================] - 12s 625ms/step - loss: 2.0323e-04 - val_loss: 1.6623e-04\n",
      "Epoch 72/100\n",
      "19/19 [==============================] - 12s 628ms/step - loss: 2.0504e-04 - val_loss: 1.3626e-04\n",
      "Epoch 73/100\n",
      "19/19 [==============================] - 12s 615ms/step - loss: 1.7485e-04 - val_loss: 1.4056e-04\n",
      "Epoch 74/100\n",
      "19/19 [==============================] - 14s 722ms/step - loss: 1.7246e-04 - val_loss: 2.6126e-04\n",
      "Epoch 75/100\n",
      "19/19 [==============================] - 12s 646ms/step - loss: 1.8920e-04 - val_loss: 1.3577e-04\n",
      "Epoch 76/100\n",
      "19/19 [==============================] - 12s 644ms/step - loss: 1.8037e-04 - val_loss: 1.3445e-04\n",
      "Epoch 77/100\n",
      "19/19 [==============================] - 13s 678ms/step - loss: 1.7800e-04 - val_loss: 1.9042e-04\n",
      "Epoch 78/100\n",
      "19/19 [==============================] - 12s 642ms/step - loss: 1.9891e-04 - val_loss: 3.2014e-04\n",
      "Epoch 79/100\n",
      "19/19 [==============================] - 12s 630ms/step - loss: 1.9155e-04 - val_loss: 1.5745e-04\n",
      "Epoch 80/100\n",
      "19/19 [==============================] - 12s 624ms/step - loss: 1.7408e-04 - val_loss: 1.3530e-04\n",
      "Epoch 81/100\n",
      "19/19 [==============================] - 12s 626ms/step - loss: 1.6518e-04 - val_loss: 2.3747e-04\n",
      "Epoch 82/100\n",
      "19/19 [==============================] - 12s 650ms/step - loss: 1.9768e-04 - val_loss: 1.6367e-04\n",
      "Epoch 83/100\n",
      "19/19 [==============================] - 13s 676ms/step - loss: 1.7669e-04 - val_loss: 1.4767e-04\n",
      "Epoch 84/100\n",
      "19/19 [==============================] - 12s 649ms/step - loss: 1.9309e-04 - val_loss: 2.0937e-04\n",
      "Epoch 85/100\n",
      "19/19 [==============================] - 12s 624ms/step - loss: 1.6308e-04 - val_loss: 1.3389e-04\n",
      "Epoch 86/100\n",
      "19/19 [==============================] - 12s 630ms/step - loss: 1.8258e-04 - val_loss: 1.4009e-04\n",
      "Epoch 87/100\n",
      "19/19 [==============================] - 12s 645ms/step - loss: 1.8416e-04 - val_loss: 1.6132e-04\n",
      "Epoch 88/100\n",
      "19/19 [==============================] - 12s 624ms/step - loss: 1.7191e-04 - val_loss: 1.4594e-04\n",
      "Epoch 89/100\n",
      "19/19 [==============================] - 12s 612ms/step - loss: 1.8476e-04 - val_loss: 1.5703e-04\n",
      "Epoch 90/100\n",
      "19/19 [==============================] - 12s 641ms/step - loss: 1.9499e-04 - val_loss: 1.2914e-04\n",
      "Epoch 91/100\n",
      "19/19 [==============================] - 12s 624ms/step - loss: 1.7132e-04 - val_loss: 1.2990e-04\n",
      "Epoch 92/100\n",
      "19/19 [==============================] - 12s 635ms/step - loss: 1.6704e-04 - val_loss: 1.4172e-04\n",
      "Epoch 93/100\n",
      "19/19 [==============================] - 12s 638ms/step - loss: 1.7877e-04 - val_loss: 1.4157e-04\n",
      "Epoch 94/100\n",
      "19/19 [==============================] - 13s 656ms/step - loss: 1.7000e-04 - val_loss: 1.5523e-04\n",
      "Epoch 95/100\n",
      "19/19 [==============================] - 12s 636ms/step - loss: 1.6881e-04 - val_loss: 1.6921e-04\n",
      "Epoch 96/100\n",
      "19/19 [==============================] - 12s 605ms/step - loss: 1.7255e-04 - val_loss: 1.3759e-04\n",
      "Epoch 97/100\n",
      "19/19 [==============================] - 11s 600ms/step - loss: 1.8237e-04 - val_loss: 1.9376e-04\n",
      "Epoch 98/100\n",
      "19/19 [==============================] - 12s 612ms/step - loss: 1.8440e-04 - val_loss: 1.3681e-04\n",
      "Epoch 99/100\n",
      "19/19 [==============================] - 12s 617ms/step - loss: 1.6526e-04 - val_loss: 1.3995e-04\n",
      "Epoch 100/100\n",
      "19/19 [==============================] - 11s 605ms/step - loss: 1.7178e-04 - val_loss: 1.6999e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_108_layer_call_fn, lstm_cell_108_layer_call_and_return_conditional_losses, lstm_cell_109_layer_call_fn, lstm_cell_109_layer_call_and_return_conditional_losses, lstm_cell_110_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/XRP\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/XRP\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 4s 81ms/step\n",
      "11/11 [==============================] - 1s 79ms/step\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Epoch 1/100\n",
      "19/19 [==============================] - 19s 714ms/step - loss: 0.0051 - val_loss: 0.0023\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 10s 518ms/step - loss: 0.0011 - val_loss: 0.0192\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - 10s 517ms/step - loss: 8.5205e-04 - val_loss: 0.0036\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 10s 530ms/step - loss: 6.6023e-04 - val_loss: 0.0023\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 10s 518ms/step - loss: 7.4646e-04 - val_loss: 0.0026\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 10s 517ms/step - loss: 6.1860e-04 - val_loss: 0.0043\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 10s 539ms/step - loss: 5.9690e-04 - val_loss: 0.0020\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 10s 520ms/step - loss: 6.4030e-04 - val_loss: 0.0051\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 10s 515ms/step - loss: 7.9349e-04 - val_loss: 0.0020\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 10s 530ms/step - loss: 6.0272e-04 - val_loss: 0.0023\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 10s 520ms/step - loss: 5.2829e-04 - val_loss: 0.0026\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 10s 553ms/step - loss: 6.1716e-04 - val_loss: 0.0023\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 11s 576ms/step - loss: 5.4530e-04 - val_loss: 0.0020\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 10s 540ms/step - loss: 5.2123e-04 - val_loss: 0.0021\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 10s 540ms/step - loss: 4.4953e-04 - val_loss: 0.0025\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 10s 530ms/step - loss: 4.5082e-04 - val_loss: 0.0042\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 10s 529ms/step - loss: 4.7693e-04 - val_loss: 0.0024\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 10s 543ms/step - loss: 5.8963e-04 - val_loss: 0.0039\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 11s 559ms/step - loss: 5.2521e-04 - val_loss: 0.0025\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 10s 531ms/step - loss: 4.6354e-04 - val_loss: 0.0017\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 10s 523ms/step - loss: 3.8352e-04 - val_loss: 0.0026\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - 10s 535ms/step - loss: 4.3328e-04 - val_loss: 0.0042\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 10s 540ms/step - loss: 5.1647e-04 - val_loss: 0.0016\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 10s 530ms/step - loss: 3.6879e-04 - val_loss: 0.0040\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 10s 548ms/step - loss: 4.3826e-04 - val_loss: 0.0016\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 10s 539ms/step - loss: 3.8810e-04 - val_loss: 0.0017\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 10s 536ms/step - loss: 3.6566e-04 - val_loss: 0.0028\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 10s 549ms/step - loss: 3.8172e-04 - val_loss: 0.0021\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - 10s 530ms/step - loss: 3.4406e-04 - val_loss: 0.0015\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 10s 541ms/step - loss: 3.2361e-04 - val_loss: 0.0014\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 11s 568ms/step - loss: 3.3879e-04 - val_loss: 0.0015\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 11s 580ms/step - loss: 3.3087e-04 - val_loss: 0.0015\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 11s 561ms/step - loss: 3.1117e-04 - val_loss: 0.0013\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 11s 578ms/step - loss: 2.9992e-04 - val_loss: 0.0015\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 11s 567ms/step - loss: 3.0178e-04 - val_loss: 0.0013\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 11s 560ms/step - loss: 3.0336e-04 - val_loss: 0.0015\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 10s 551ms/step - loss: 2.9126e-04 - val_loss: 0.0015\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 11s 555ms/step - loss: 3.0180e-04 - val_loss: 0.0012\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 11s 560ms/step - loss: 2.8867e-04 - val_loss: 0.0014\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 11s 565ms/step - loss: 2.9805e-04 - val_loss: 0.0013\n",
      "Epoch 41/100\n",
      "19/19 [==============================] - 11s 576ms/step - loss: 2.7824e-04 - val_loss: 9.6843e-04\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 11s 579ms/step - loss: 2.8996e-04 - val_loss: 0.0038\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 11s 566ms/step - loss: 3.1357e-04 - val_loss: 0.0014\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 10s 553ms/step - loss: 2.4393e-04 - val_loss: 0.0016\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 10s 544ms/step - loss: 2.2964e-04 - val_loss: 0.0012\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 10s 543ms/step - loss: 3.6527e-04 - val_loss: 0.0013\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 10s 544ms/step - loss: 4.3485e-04 - val_loss: 0.0011\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - 11s 565ms/step - loss: 2.6038e-04 - val_loss: 8.9374e-04\n",
      "Epoch 49/100\n",
      "19/19 [==============================] - 11s 592ms/step - loss: 2.4339e-04 - val_loss: 9.4307e-04\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 11s 567ms/step - loss: 2.1078e-04 - val_loss: 0.0011\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - 11s 579ms/step - loss: 2.3182e-04 - val_loss: 9.5575e-04\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 11s 573ms/step - loss: 2.3030e-04 - val_loss: 9.4893e-04\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 11s 573ms/step - loss: 1.9847e-04 - val_loss: 0.0013\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 11s 560ms/step - loss: 2.1688e-04 - val_loss: 0.0010\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 10s 542ms/step - loss: 1.9182e-04 - val_loss: 8.4104e-04\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 11s 556ms/step - loss: 2.1594e-04 - val_loss: 8.6940e-04\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 10s 552ms/step - loss: 2.3783e-04 - val_loss: 8.7951e-04\n",
      "Epoch 58/100\n",
      "19/19 [==============================] - 10s 554ms/step - loss: 2.0767e-04 - val_loss: 9.0569e-04\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 10s 547ms/step - loss: 1.8578e-04 - val_loss: 8.7332e-04\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 11s 572ms/step - loss: 1.7911e-04 - val_loss: 0.0014\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 11s 558ms/step - loss: 2.0408e-04 - val_loss: 9.8427e-04\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 11s 579ms/step - loss: 1.5777e-04 - val_loss: 0.0014\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 11s 570ms/step - loss: 2.1014e-04 - val_loss: 9.4542e-04\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - 11s 575ms/step - loss: 2.1827e-04 - val_loss: 0.0014\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - 11s 570ms/step - loss: 2.2001e-04 - val_loss: 9.8735e-04\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - 11s 582ms/step - loss: 1.7716e-04 - val_loss: 9.0462e-04\n",
      "Epoch 67/100\n",
      "19/19 [==============================] - 11s 572ms/step - loss: 1.8125e-04 - val_loss: 0.0011\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - 11s 580ms/step - loss: 1.6903e-04 - val_loss: 9.5341e-04\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - 11s 573ms/step - loss: 1.8289e-04 - val_loss: 9.7648e-04\n",
      "Epoch 70/100\n",
      "19/19 [==============================] - 11s 563ms/step - loss: 1.6212e-04 - val_loss: 0.0011\n",
      "Epoch 71/100\n",
      "19/19 [==============================] - 10s 545ms/step - loss: 1.6523e-04 - val_loss: 8.5233e-04\n",
      "Epoch 72/100\n",
      "19/19 [==============================] - 11s 563ms/step - loss: 1.7008e-04 - val_loss: 0.0014\n",
      "Epoch 73/100\n",
      "19/19 [==============================] - 10s 542ms/step - loss: 1.6576e-04 - val_loss: 0.0012\n",
      "Epoch 74/100\n",
      "19/19 [==============================] - 10s 538ms/step - loss: 1.8766e-04 - val_loss: 7.8592e-04\n",
      "Epoch 75/100\n",
      "19/19 [==============================] - 10s 540ms/step - loss: 1.7824e-04 - val_loss: 0.0011\n",
      "Epoch 76/100\n",
      "19/19 [==============================] - 10s 545ms/step - loss: 1.9245e-04 - val_loss: 9.6916e-04\n",
      "Epoch 77/100\n",
      "19/19 [==============================] - 10s 540ms/step - loss: 1.6149e-04 - val_loss: 8.2873e-04\n",
      "Epoch 78/100\n",
      "19/19 [==============================] - 10s 534ms/step - loss: 1.6015e-04 - val_loss: 9.6732e-04\n",
      "Epoch 79/100\n",
      "19/19 [==============================] - 10s 537ms/step - loss: 1.4405e-04 - val_loss: 0.0011\n",
      "Epoch 80/100\n",
      "19/19 [==============================] - 10s 537ms/step - loss: 1.6104e-04 - val_loss: 0.0010\n",
      "Epoch 81/100\n",
      "19/19 [==============================] - 10s 546ms/step - loss: 1.6389e-04 - val_loss: 0.0012\n",
      "Epoch 82/100\n",
      "19/19 [==============================] - 11s 554ms/step - loss: 1.6183e-04 - val_loss: 9.6426e-04\n",
      "Epoch 83/100\n",
      "19/19 [==============================] - 10s 550ms/step - loss: 1.5455e-04 - val_loss: 9.1810e-04\n",
      "Epoch 84/100\n",
      "19/19 [==============================] - 10s 544ms/step - loss: 1.5298e-04 - val_loss: 9.7234e-04\n",
      "Epoch 85/100\n",
      "19/19 [==============================] - 11s 562ms/step - loss: 1.7440e-04 - val_loss: 0.0011\n",
      "Epoch 86/100\n",
      "19/19 [==============================] - 11s 572ms/step - loss: 2.2855e-04 - val_loss: 0.0010\n",
      "Epoch 87/100\n",
      "19/19 [==============================] - 10s 541ms/step - loss: 1.8645e-04 - val_loss: 9.5338e-04\n",
      "Epoch 88/100\n",
      "19/19 [==============================] - 10s 543ms/step - loss: 1.4525e-04 - val_loss: 9.6618e-04\n",
      "Epoch 89/100\n",
      "19/19 [==============================] - 10s 538ms/step - loss: 1.6907e-04 - val_loss: 9.2475e-04\n",
      "Epoch 90/100\n",
      "19/19 [==============================] - 10s 534ms/step - loss: 1.5671e-04 - val_loss: 0.0013\n",
      "Epoch 91/100\n",
      "19/19 [==============================] - 10s 534ms/step - loss: 1.4452e-04 - val_loss: 0.0011\n",
      "Epoch 92/100\n",
      "19/19 [==============================] - 10s 527ms/step - loss: 1.6452e-04 - val_loss: 9.9889e-04\n",
      "Epoch 93/100\n",
      "19/19 [==============================] - 10s 546ms/step - loss: 1.5141e-04 - val_loss: 9.2387e-04\n",
      "Epoch 94/100\n",
      "19/19 [==============================] - 11s 557ms/step - loss: 1.6396e-04 - val_loss: 0.0010\n",
      "Epoch 95/100\n",
      "19/19 [==============================] - 11s 573ms/step - loss: 1.6504e-04 - val_loss: 0.0017\n",
      "Epoch 96/100\n",
      "19/19 [==============================] - 11s 558ms/step - loss: 1.9464e-04 - val_loss: 0.0010\n",
      "Epoch 97/100\n",
      "19/19 [==============================] - 10s 545ms/step - loss: 1.9386e-04 - val_loss: 8.7847e-04\n",
      "Epoch 98/100\n",
      "19/19 [==============================] - 10s 538ms/step - loss: 1.5416e-04 - val_loss: 8.3977e-04\n",
      "Epoch 99/100\n",
      "19/19 [==============================] - 11s 582ms/step - loss: 1.4836e-04 - val_loss: 9.2265e-04\n",
      "Epoch 100/100\n",
      "19/19 [==============================] - 11s 584ms/step - loss: 1.4770e-04 - val_loss: 9.3193e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_111_layer_call_fn, lstm_cell_111_layer_call_and_return_conditional_losses, lstm_cell_112_layer_call_fn, lstm_cell_112_layer_call_and_return_conditional_losses, lstm_cell_113_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/ADA\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/ADA\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 5s 82ms/step\n",
      "11/11 [==============================] - 1s 80ms/step\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Epoch 1/100\n",
      "9/9 [==============================] - 13s 793ms/step - loss: 0.0605 - val_loss: 0.0416\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 6s 637ms/step - loss: 0.0126 - val_loss: 0.0011\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 6s 634ms/step - loss: 0.0057 - val_loss: 0.0117\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 5s 589ms/step - loss: 0.0048 - val_loss: 0.0023\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 6s 603ms/step - loss: 0.0041 - val_loss: 0.0102\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 6s 645ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 6s 642ms/step - loss: 0.0032 - val_loss: 0.0096\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 6s 622ms/step - loss: 0.0032 - val_loss: 0.0053\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 5s 580ms/step - loss: 0.0030 - val_loss: 0.0097\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 5s 607ms/step - loss: 0.0030 - val_loss: 0.0062\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 5s 581ms/step - loss: 0.0027 - val_loss: 0.0081\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 5s 585ms/step - loss: 0.0027 - val_loss: 0.0081\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 5s 603ms/step - loss: 0.0026 - val_loss: 0.0056\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 5s 594ms/step - loss: 0.0025 - val_loss: 0.0050\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 6s 635ms/step - loss: 0.0026 - val_loss: 0.0047\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 5s 601ms/step - loss: 0.0025 - val_loss: 0.0083\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 6s 638ms/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 6s 617ms/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 6s 647ms/step - loss: 0.0022 - val_loss: 0.0049\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 5s 595ms/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 6s 638ms/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 6s 625ms/step - loss: 0.0024 - val_loss: 0.0047\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - 6s 626ms/step - loss: 0.0024 - val_loss: 0.0047\n",
      "Epoch 24/100\n",
      "9/9 [==============================] - 6s 607ms/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 25/100\n",
      "9/9 [==============================] - 6s 640ms/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 26/100\n",
      "9/9 [==============================] - 6s 613ms/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 27/100\n",
      "9/9 [==============================] - 6s 618ms/step - loss: 0.0023 - val_loss: 0.0062\n",
      "Epoch 28/100\n",
      "9/9 [==============================] - 5s 592ms/step - loss: 0.0025 - val_loss: 0.0059\n",
      "Epoch 29/100\n",
      "9/9 [==============================] - 5s 596ms/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 30/100\n",
      "9/9 [==============================] - 5s 590ms/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 31/100\n",
      "9/9 [==============================] - 5s 589ms/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 32/100\n",
      "9/9 [==============================] - 6s 622ms/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 33/100\n",
      "9/9 [==============================] - 6s 621ms/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 34/100\n",
      "9/9 [==============================] - 6s 644ms/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 35/100\n",
      "9/9 [==============================] - 5s 593ms/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 36/100\n",
      "9/9 [==============================] - 5s 595ms/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 37/100\n",
      "9/9 [==============================] - 6s 615ms/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 38/100\n",
      "9/9 [==============================] - 6s 614ms/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 39/100\n",
      "9/9 [==============================] - 5s 591ms/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 40/100\n",
      "9/9 [==============================] - 5s 590ms/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 41/100\n",
      "9/9 [==============================] - 5s 586ms/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 42/100\n",
      "9/9 [==============================] - 5s 602ms/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 43/100\n",
      "9/9 [==============================] - 6s 647ms/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 44/100\n",
      "9/9 [==============================] - 6s 665ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 45/100\n",
      "9/9 [==============================] - 6s 727ms/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 46/100\n",
      "9/9 [==============================] - 6s 672ms/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 47/100\n",
      "9/9 [==============================] - 6s 685ms/step - loss: 0.0016 - val_loss: 0.0032\n",
      "Epoch 48/100\n",
      "9/9 [==============================] - 6s 700ms/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 49/100\n",
      "9/9 [==============================] - 6s 706ms/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 50/100\n",
      "9/9 [==============================] - 7s 735ms/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 51/100\n",
      "9/9 [==============================] - 7s 720ms/step - loss: 0.0015 - val_loss: 0.0029\n",
      "Epoch 52/100\n",
      "9/9 [==============================] - 6s 669ms/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 53/100\n",
      "9/9 [==============================] - 6s 673ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 54/100\n",
      "9/9 [==============================] - 6s 636ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 55/100\n",
      "9/9 [==============================] - 6s 634ms/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 56/100\n",
      "9/9 [==============================] - 6s 662ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 57/100\n",
      "9/9 [==============================] - 6s 636ms/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 58/100\n",
      "9/9 [==============================] - 7s 744ms/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 59/100\n",
      "9/9 [==============================] - 7s 751ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 60/100\n",
      "9/9 [==============================] - 6s 714ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 61/100\n",
      "9/9 [==============================] - 6s 674ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 62/100\n",
      "9/9 [==============================] - 6s 624ms/step - loss: 0.0012 - val_loss: 9.9322e-04\n",
      "Epoch 63/100\n",
      "9/9 [==============================] - 6s 610ms/step - loss: 0.0013 - val_loss: 9.0145e-04\n",
      "Epoch 64/100\n",
      "9/9 [==============================] - 6s 606ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 65/100\n",
      "9/9 [==============================] - 6s 632ms/step - loss: 0.0011 - val_loss: 8.3939e-04\n",
      "Epoch 66/100\n",
      "9/9 [==============================] - 6s 625ms/step - loss: 0.0012 - val_loss: 9.4041e-04\n",
      "Epoch 67/100\n",
      "9/9 [==============================] - 6s 699ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 68/100\n",
      "9/9 [==============================] - 6s 634ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 69/100\n",
      "9/9 [==============================] - 6s 647ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 70/100\n",
      "9/9 [==============================] - 6s 671ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 71/100\n",
      "9/9 [==============================] - 7s 768ms/step - loss: 0.0013 - val_loss: 7.0258e-04\n",
      "Epoch 72/100\n",
      "9/9 [==============================] - 6s 695ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 73/100\n",
      "9/9 [==============================] - 6s 603ms/step - loss: 0.0015 - val_loss: 6.4005e-04\n",
      "Epoch 74/100\n",
      "9/9 [==============================] - 5s 586ms/step - loss: 0.0014 - val_loss: 7.5122e-04\n",
      "Epoch 75/100\n",
      "9/9 [==============================] - 5s 587ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 76/100\n",
      "9/9 [==============================] - 5s 580ms/step - loss: 0.0011 - val_loss: 7.0344e-04\n",
      "Epoch 77/100\n",
      "9/9 [==============================] - 5s 577ms/step - loss: 0.0011 - val_loss: 9.7455e-04\n",
      "Epoch 78/100\n",
      "9/9 [==============================] - 5s 603ms/step - loss: 0.0011 - val_loss: 9.3329e-04\n",
      "Epoch 79/100\n",
      "9/9 [==============================] - 6s 642ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 80/100\n",
      "9/9 [==============================] - 5s 574ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 81/100\n",
      "9/9 [==============================] - 5s 591ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 82/100\n",
      "9/9 [==============================] - 5s 574ms/step - loss: 0.0012 - val_loss: 9.6893e-04\n",
      "Epoch 83/100\n",
      "9/9 [==============================] - 5s 585ms/step - loss: 0.0012 - val_loss: 8.3824e-04\n",
      "Epoch 84/100\n",
      "9/9 [==============================] - 6s 647ms/step - loss: 0.0010 - val_loss: 6.3085e-04\n",
      "Epoch 85/100\n",
      "9/9 [==============================] - 6s 661ms/step - loss: 0.0010 - val_loss: 7.2257e-04\n",
      "Epoch 86/100\n",
      "9/9 [==============================] - 6s 685ms/step - loss: 9.5273e-04 - val_loss: 6.9110e-04\n",
      "Epoch 87/100\n",
      "9/9 [==============================] - 6s 672ms/step - loss: 9.5529e-04 - val_loss: 5.3139e-04\n",
      "Epoch 88/100\n",
      "9/9 [==============================] - 6s 675ms/step - loss: 0.0011 - val_loss: 9.7005e-04\n",
      "Epoch 89/100\n",
      "9/9 [==============================] - 6s 626ms/step - loss: 9.9150e-04 - val_loss: 6.7800e-04\n",
      "Epoch 90/100\n",
      "9/9 [==============================] - 6s 614ms/step - loss: 0.0010 - val_loss: 5.3316e-04\n",
      "Epoch 91/100\n",
      "9/9 [==============================] - 6s 614ms/step - loss: 0.0011 - val_loss: 4.7281e-04\n",
      "Epoch 92/100\n",
      "9/9 [==============================] - 5s 580ms/step - loss: 0.0012 - val_loss: 4.8232e-04\n",
      "Epoch 93/100\n",
      "9/9 [==============================] - 5s 584ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 94/100\n",
      "9/9 [==============================] - 5s 588ms/step - loss: 0.0010 - val_loss: 9.4473e-04\n",
      "Epoch 95/100\n",
      "9/9 [==============================] - 5s 573ms/step - loss: 8.5421e-04 - val_loss: 8.4427e-04\n",
      "Epoch 96/100\n",
      "9/9 [==============================] - 5s 583ms/step - loss: 8.3659e-04 - val_loss: 9.1208e-04\n",
      "Epoch 97/100\n",
      "9/9 [==============================] - 5s 600ms/step - loss: 8.5185e-04 - val_loss: 7.1513e-04\n",
      "Epoch 98/100\n",
      "9/9 [==============================] - 6s 618ms/step - loss: 8.1500e-04 - val_loss: 7.2505e-04\n",
      "Epoch 99/100\n",
      "9/9 [==============================] - 5s 585ms/step - loss: 8.9837e-04 - val_loss: 7.7603e-04\n",
      "Epoch 100/100\n",
      "9/9 [==============================] - 5s 587ms/step - loss: 0.0010 - val_loss: 8.0295e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_114_layer_call_fn, lstm_cell_114_layer_call_and_return_conditional_losses, lstm_cell_115_layer_call_fn, lstm_cell_115_layer_call_and_return_conditional_losses, lstm_cell_116_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/SOL\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/SOL\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 3s 94ms/step\n",
      "4/4 [==============================] - 0s 84ms/step\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Epoch 1/100\n",
      "19/19 [==============================] - 20s 745ms/step - loss: 0.0066 - val_loss: 0.0015\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 13s 668ms/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - 13s 693ms/step - loss: 0.0025 - val_loss: 0.0065\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 13s 697ms/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 12s 637ms/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 13s 662ms/step - loss: 0.0017 - val_loss: 7.9288e-04\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 12s 651ms/step - loss: 0.0014 - val_loss: 0.0064\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 12s 646ms/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 12s 646ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 12s 649ms/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 12s 643ms/step - loss: 0.0013 - val_loss: 9.5833e-04\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 12s 641ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 12s 648ms/step - loss: 0.0013 - val_loss: 0.0085\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 12s 649ms/step - loss: 0.0014 - val_loss: 0.0028\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 12s 648ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 13s 665ms/step - loss: 0.0011 - val_loss: 0.0106\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 12s 652ms/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 12s 640ms/step - loss: 0.0011 - val_loss: 0.0051\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 13s 671ms/step - loss: 0.0012 - val_loss: 0.0136\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 14s 723ms/step - loss: 0.0011 - val_loss: 0.0112\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 13s 703ms/step - loss: 0.0011 - val_loss: 0.0116\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - 13s 698ms/step - loss: 9.9965e-04 - val_loss: 0.0065\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 13s 668ms/step - loss: 9.8919e-04 - val_loss: 0.0064\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 13s 684ms/step - loss: 9.9612e-04 - val_loss: 0.0139\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 13s 701ms/step - loss: 0.0010 - val_loss: 0.0119\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 14s 724ms/step - loss: 9.6727e-04 - val_loss: 0.0121\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 13s 676ms/step - loss: 8.8860e-04 - val_loss: 0.0083\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 13s 694ms/step - loss: 8.6778e-04 - val_loss: 0.0070\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - 13s 685ms/step - loss: 9.2077e-04 - val_loss: 0.0195\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 13s 691ms/step - loss: 8.8908e-04 - val_loss: 0.0127\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 13s 681ms/step - loss: 8.6633e-04 - val_loss: 0.0134\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 13s 669ms/step - loss: 8.0825e-04 - val_loss: 0.0080\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 13s 678ms/step - loss: 8.1232e-04 - val_loss: 0.0084\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 13s 691ms/step - loss: 7.5921e-04 - val_loss: 0.0077\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 13s 693ms/step - loss: 7.9670e-04 - val_loss: 0.0126\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 13s 684ms/step - loss: 6.5728e-04 - val_loss: 0.0179\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 13s 682ms/step - loss: 6.4522e-04 - val_loss: 0.0174\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 13s 695ms/step - loss: 5.3792e-04 - val_loss: 0.0108\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 13s 701ms/step - loss: 5.3712e-04 - val_loss: 0.0109\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 13s 698ms/step - loss: 6.0317e-04 - val_loss: 0.0247\n",
      "Epoch 41/100\n",
      "19/19 [==============================] - 13s 682ms/step - loss: 5.4549e-04 - val_loss: 0.0099\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 13s 702ms/step - loss: 5.0866e-04 - val_loss: 0.0109\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 13s 676ms/step - loss: 4.6713e-04 - val_loss: 0.0064\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 13s 673ms/step - loss: 4.2467e-04 - val_loss: 0.0131\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 13s 690ms/step - loss: 3.9575e-04 - val_loss: 0.0129\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 13s 666ms/step - loss: 3.9868e-04 - val_loss: 0.0063\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 13s 675ms/step - loss: 4.3548e-04 - val_loss: 0.0065\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - 13s 698ms/step - loss: 4.4404e-04 - val_loss: 0.0026\n",
      "Epoch 49/100\n",
      "19/19 [==============================] - 13s 683ms/step - loss: 5.7439e-04 - val_loss: 0.0099\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 13s 700ms/step - loss: 4.3630e-04 - val_loss: 0.0026\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - 13s 665ms/step - loss: 4.3116e-04 - val_loss: 0.0060\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 14s 729ms/step - loss: 4.9626e-04 - val_loss: 0.0080\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 13s 708ms/step - loss: 4.0175e-04 - val_loss: 0.0089\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 13s 716ms/step - loss: 3.3831e-04 - val_loss: 0.0111\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 13s 691ms/step - loss: 3.8891e-04 - val_loss: 0.0094\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 13s 671ms/step - loss: 3.7714e-04 - val_loss: 0.0082\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 13s 679ms/step - loss: 3.4101e-04 - val_loss: 0.0088\n",
      "Epoch 58/100\n",
      "19/19 [==============================] - 13s 678ms/step - loss: 3.6871e-04 - val_loss: 0.0044\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 13s 688ms/step - loss: 3.3293e-04 - val_loss: 0.0103\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 13s 669ms/step - loss: 3.6632e-04 - val_loss: 0.0060\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 13s 678ms/step - loss: 3.6737e-04 - val_loss: 0.0062\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 13s 675ms/step - loss: 3.1390e-04 - val_loss: 0.0127\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 13s 676ms/step - loss: 3.5999e-04 - val_loss: 0.0121\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - 13s 672ms/step - loss: 3.6390e-04 - val_loss: 0.0075\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - 13s 683ms/step - loss: 3.6371e-04 - val_loss: 0.0081\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - 13s 668ms/step - loss: 3.0908e-04 - val_loss: 0.0068\n",
      "Epoch 67/100\n",
      "19/19 [==============================] - 13s 678ms/step - loss: 3.5483e-04 - val_loss: 0.0059\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - 13s 670ms/step - loss: 5.2474e-04 - val_loss: 0.0096\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - 13s 675ms/step - loss: 3.1523e-04 - val_loss: 0.0062\n",
      "Epoch 70/100\n",
      "19/19 [==============================] - 13s 673ms/step - loss: 3.1294e-04 - val_loss: 0.0052\n",
      "Epoch 71/100\n",
      "19/19 [==============================] - 13s 667ms/step - loss: 3.3328e-04 - val_loss: 0.0079\n",
      "Epoch 72/100\n",
      "19/19 [==============================] - 13s 684ms/step - loss: 4.8353e-04 - val_loss: 0.0161\n",
      "Epoch 73/100\n",
      "19/19 [==============================] - 13s 674ms/step - loss: 4.0142e-04 - val_loss: 0.0121\n",
      "Epoch 74/100\n",
      "19/19 [==============================] - 13s 675ms/step - loss: 3.4354e-04 - val_loss: 0.0089\n",
      "Epoch 75/100\n",
      "19/19 [==============================] - 13s 684ms/step - loss: 2.9593e-04 - val_loss: 0.0065\n",
      "Epoch 76/100\n",
      "19/19 [==============================] - 13s 686ms/step - loss: 2.7385e-04 - val_loss: 0.0070\n",
      "Epoch 77/100\n",
      "19/19 [==============================] - 13s 675ms/step - loss: 2.7235e-04 - val_loss: 0.0060\n",
      "Epoch 78/100\n",
      "19/19 [==============================] - 13s 682ms/step - loss: 2.7970e-04 - val_loss: 0.0074\n",
      "Epoch 79/100\n",
      "19/19 [==============================] - 13s 674ms/step - loss: 2.9337e-04 - val_loss: 0.0103\n",
      "Epoch 80/100\n",
      "19/19 [==============================] - 13s 672ms/step - loss: 3.0383e-04 - val_loss: 0.0068\n",
      "Epoch 81/100\n",
      "19/19 [==============================] - 13s 675ms/step - loss: 2.5397e-04 - val_loss: 0.0082\n",
      "Epoch 82/100\n",
      "19/19 [==============================] - 13s 683ms/step - loss: 3.0866e-04 - val_loss: 0.0099\n",
      "Epoch 83/100\n",
      "19/19 [==============================] - 13s 707ms/step - loss: 2.5480e-04 - val_loss: 0.0060\n",
      "Epoch 84/100\n",
      "19/19 [==============================] - 13s 669ms/step - loss: 2.7372e-04 - val_loss: 0.0105\n",
      "Epoch 85/100\n",
      "19/19 [==============================] - 13s 676ms/step - loss: 2.9048e-04 - val_loss: 0.0186\n",
      "Epoch 86/100\n",
      "19/19 [==============================] - 13s 690ms/step - loss: 3.4523e-04 - val_loss: 0.0068\n",
      "Epoch 87/100\n",
      "19/19 [==============================] - 13s 703ms/step - loss: 2.8423e-04 - val_loss: 0.0067\n",
      "Epoch 88/100\n",
      "19/19 [==============================] - 13s 678ms/step - loss: 2.9259e-04 - val_loss: 0.0091\n",
      "Epoch 89/100\n",
      "19/19 [==============================] - 13s 675ms/step - loss: 2.6865e-04 - val_loss: 0.0144\n",
      "Epoch 90/100\n",
      "19/19 [==============================] - 14s 737ms/step - loss: 2.9876e-04 - val_loss: 0.0093\n",
      "Epoch 91/100\n",
      "19/19 [==============================] - 14s 715ms/step - loss: 2.4831e-04 - val_loss: 0.0092\n",
      "Epoch 92/100\n",
      "19/19 [==============================] - 13s 696ms/step - loss: 2.5228e-04 - val_loss: 0.0109\n",
      "Epoch 93/100\n",
      "19/19 [==============================] - 13s 672ms/step - loss: 2.3952e-04 - val_loss: 0.0107\n",
      "Epoch 94/100\n",
      "19/19 [==============================] - 14s 715ms/step - loss: 2.8257e-04 - val_loss: 0.0075\n",
      "Epoch 95/100\n",
      "19/19 [==============================] - 14s 737ms/step - loss: 2.6812e-04 - val_loss: 0.0094\n",
      "Epoch 96/100\n",
      "19/19 [==============================] - 13s 709ms/step - loss: 2.8003e-04 - val_loss: 0.0088\n",
      "Epoch 97/100\n",
      "19/19 [==============================] - 13s 680ms/step - loss: 2.5841e-04 - val_loss: 0.0086\n",
      "Epoch 98/100\n",
      "19/19 [==============================] - 13s 691ms/step - loss: 2.6833e-04 - val_loss: 0.0067\n",
      "Epoch 99/100\n",
      "19/19 [==============================] - 13s 692ms/step - loss: 2.4475e-04 - val_loss: 0.0125\n",
      "Epoch 100/100\n",
      "19/19 [==============================] - 13s 688ms/step - loss: 2.3919e-04 - val_loss: 0.0067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_117_layer_call_fn, lstm_cell_117_layer_call_and_return_conditional_losses, lstm_cell_118_layer_call_fn, lstm_cell_118_layer_call_and_return_conditional_losses, lstm_cell_119_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/DOGE\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/DOGE\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 5s 91ms/step\n",
      "11/11 [==============================] - 1s 89ms/step\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Epoch 1/100\n",
      "10/10 [==============================] - 14s 755ms/step - loss: 0.0439 - val_loss: 0.0072\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 6s 569ms/step - loss: 0.0070 - val_loss: 1.6381e-04\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 6s 598ms/step - loss: 0.0047 - val_loss: 0.0013\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 6s 649ms/step - loss: 0.0040 - val_loss: 1.0649e-04\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 6s 605ms/step - loss: 0.0039 - val_loss: 0.0011\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 6s 608ms/step - loss: 0.0038 - val_loss: 2.1372e-04\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 6s 595ms/step - loss: 0.0039 - val_loss: 6.6942e-04\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 6s 596ms/step - loss: 0.0038 - val_loss: 2.4366e-04\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 6s 598ms/step - loss: 0.0038 - val_loss: 4.1247e-04\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 6s 610ms/step - loss: 0.0037 - val_loss: 4.4487e-04\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 6s 573ms/step - loss: 0.0037 - val_loss: 2.4624e-04\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 6s 564ms/step - loss: 0.0037 - val_loss: 4.8428e-04\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 6s 589ms/step - loss: 0.0037 - val_loss: 2.6677e-04\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 6s 575ms/step - loss: 0.0037 - val_loss: 5.4342e-05\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 6s 634ms/step - loss: 0.0038 - val_loss: 3.9479e-04\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 6s 637ms/step - loss: 0.0037 - val_loss: 6.0192e-04\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 6s 591ms/step - loss: 0.0036 - val_loss: 1.7117e-04\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 6s 574ms/step - loss: 0.0036 - val_loss: 3.3518e-04\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 6s 563ms/step - loss: 0.0036 - val_loss: 3.1773e-04\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 6s 568ms/step - loss: 0.0037 - val_loss: 1.8367e-04\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 6s 558ms/step - loss: 0.0037 - val_loss: 2.8424e-04\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 6s 592ms/step - loss: 0.0036 - val_loss: 1.1946e-04\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 6s 593ms/step - loss: 0.0036 - val_loss: 4.3676e-05\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 6s 571ms/step - loss: 0.0035 - val_loss: 1.0931e-04\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 6s 575ms/step - loss: 0.0036 - val_loss: 9.4688e-05\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 6s 573ms/step - loss: 0.0036 - val_loss: 1.2701e-04\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 6s 601ms/step - loss: 0.0035 - val_loss: 4.1726e-05\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 6s 570ms/step - loss: 0.0036 - val_loss: 2.1802e-05\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 6s 632ms/step - loss: 0.0035 - val_loss: 3.6304e-05\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 6s 600ms/step - loss: 0.0035 - val_loss: 3.2738e-04\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 6s 602ms/step - loss: 0.0035 - val_loss: 1.8915e-04\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 6s 565ms/step - loss: 0.0035 - val_loss: 6.1993e-05\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 6s 586ms/step - loss: 0.0035 - val_loss: 1.9850e-04\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 6s 611ms/step - loss: 0.0036 - val_loss: 6.2456e-04\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 6s 604ms/step - loss: 0.0036 - val_loss: 3.8094e-04\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 6s 566ms/step - loss: 0.0035 - val_loss: 1.7137e-04\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 6s 585ms/step - loss: 0.0035 - val_loss: 4.4706e-04\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 6s 572ms/step - loss: 0.0035 - val_loss: 5.0203e-04\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 6s 589ms/step - loss: 0.0037 - val_loss: 3.6656e-04\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 6s 590ms/step - loss: 0.0037 - val_loss: 1.5043e-04\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 6s 583ms/step - loss: 0.0035 - val_loss: 4.8436e-05\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 6s 560ms/step - loss: 0.0036 - val_loss: 2.4510e-05\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 6s 597ms/step - loss: 0.0035 - val_loss: 4.0485e-05\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 6s 563ms/step - loss: 0.0035 - val_loss: 2.2176e-04\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 6s 577ms/step - loss: 0.0035 - val_loss: 5.5258e-04\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 6s 605ms/step - loss: 0.0035 - val_loss: 2.0483e-04\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 6s 588ms/step - loss: 0.0034 - val_loss: 6.6325e-05\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 6s 569ms/step - loss: 0.0035 - val_loss: 2.2554e-05\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 6s 559ms/step - loss: 0.0035 - val_loss: 1.2175e-04\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 6s 572ms/step - loss: 0.0036 - val_loss: 3.5442e-05\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 6s 564ms/step - loss: 0.0034 - val_loss: 0.0012\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 6s 572ms/step - loss: 0.0035 - val_loss: 1.9279e-04\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 6s 579ms/step - loss: 0.0034 - val_loss: 3.0167e-04\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 6s 582ms/step - loss: 0.0034 - val_loss: 7.5075e-05\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 6s 562ms/step - loss: 0.0036 - val_loss: 1.5874e-04\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 6s 595ms/step - loss: 0.0036 - val_loss: 3.6079e-05\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 6s 575ms/step - loss: 0.0034 - val_loss: 1.7465e-05\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 6s 578ms/step - loss: 0.0034 - val_loss: 2.5957e-04\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 6s 565ms/step - loss: 0.0034 - val_loss: 2.6404e-04\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 6s 561ms/step - loss: 0.0035 - val_loss: 1.7532e-04\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 6s 584ms/step - loss: 0.0035 - val_loss: 3.3851e-04\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 6s 570ms/step - loss: 0.0034 - val_loss: 2.1024e-04\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 6s 560ms/step - loss: 0.0033 - val_loss: 2.1429e-04\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 6s 560ms/step - loss: 0.0034 - val_loss: 1.1687e-04\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 6s 592ms/step - loss: 0.0033 - val_loss: 2.4956e-05\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 6s 578ms/step - loss: 0.0034 - val_loss: 1.8317e-05\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 6s 589ms/step - loss: 0.0034 - val_loss: 2.6945e-05\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 6s 554ms/step - loss: 0.0033 - val_loss: 3.4698e-04\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 6s 576ms/step - loss: 0.0033 - val_loss: 2.5896e-05\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 6s 573ms/step - loss: 0.0034 - val_loss: 5.3600e-05\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 6s 585ms/step - loss: 0.0033 - val_loss: 1.4536e-04\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 6s 605ms/step - loss: 0.0034 - val_loss: 4.0329e-04\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 6s 585ms/step - loss: 0.0034 - val_loss: 7.4522e-04\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 6s 556ms/step - loss: 0.0035 - val_loss: 9.0844e-04\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 6s 590ms/step - loss: 0.0036 - val_loss: 2.8833e-04\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 6s 593ms/step - loss: 0.0033 - val_loss: 8.6428e-05\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 6s 564ms/step - loss: 0.0033 - val_loss: 2.5076e-05\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 6s 569ms/step - loss: 0.0034 - val_loss: 3.6252e-05\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 6s 597ms/step - loss: 0.0034 - val_loss: 1.2214e-04\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 6s 578ms/step - loss: 0.0034 - val_loss: 1.7653e-05\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 6s 566ms/step - loss: 0.0033 - val_loss: 2.7773e-05\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 6s 560ms/step - loss: 0.0033 - val_loss: 1.9263e-05\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 6s 594ms/step - loss: 0.0033 - val_loss: 4.2161e-05\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 6s 585ms/step - loss: 0.0033 - val_loss: 9.4834e-05\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 6s 569ms/step - loss: 0.0032 - val_loss: 6.4573e-05\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 6s 616ms/step - loss: 0.0032 - val_loss: 1.6972e-04\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 6s 654ms/step - loss: 0.0032 - val_loss: 4.0747e-05\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 7s 674ms/step - loss: 0.0033 - val_loss: 7.1757e-05\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 6s 608ms/step - loss: 0.0032 - val_loss: 3.2327e-04\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 6s 600ms/step - loss: 0.0033 - val_loss: 4.1585e-04\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 6s 593ms/step - loss: 0.0033 - val_loss: 1.7368e-04\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 6s 599ms/step - loss: 0.0032 - val_loss: 9.7500e-05\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 6s 602ms/step - loss: 0.0032 - val_loss: 3.8203e-04\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 6s 608ms/step - loss: 0.0032 - val_loss: 2.7883e-04\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 6s 626ms/step - loss: 0.0033 - val_loss: 8.5457e-05\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 6s 580ms/step - loss: 0.0033 - val_loss: 6.4814e-05\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 6s 581ms/step - loss: 0.0033 - val_loss: 2.7669e-05\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 6s 587ms/step - loss: 0.0033 - val_loss: 8.1115e-05\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 6s 561ms/step - loss: 0.0033 - val_loss: 7.2343e-05\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 6s 562ms/step - loss: 0.0032 - val_loss: 1.7339e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_120_layer_call_fn, lstm_cell_120_layer_call_and_return_conditional_losses, lstm_cell_121_layer_call_fn, lstm_cell_121_layer_call_and_return_conditional_losses, lstm_cell_122_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/DAI\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/DAI\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 3s 85ms/step\n",
      "5/5 [==============================] - 2s 85ms/step\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 13s 910ms/step - loss: 0.1092 - val_loss: 0.0420\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 5s 707ms/step - loss: 0.0241 - val_loss: 0.0050\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 5s 657ms/step - loss: 0.0187 - val_loss: 0.0200\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 5s 659ms/step - loss: 0.0148 - val_loss: 0.0119\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 5s 685ms/step - loss: 0.0129 - val_loss: 0.0080\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 4s 619ms/step - loss: 0.0113 - val_loss: 0.0096\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 5s 649ms/step - loss: 0.0109 - val_loss: 0.0040\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 4s 636ms/step - loss: 0.0100 - val_loss: 0.0050\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 4s 644ms/step - loss: 0.0099 - val_loss: 0.0028\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 5s 664ms/step - loss: 0.0093 - val_loss: 0.0026\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 5s 658ms/step - loss: 0.0089 - val_loss: 0.0022\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 4s 626ms/step - loss: 0.0086 - val_loss: 0.0026\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 5s 685ms/step - loss: 0.0083 - val_loss: 0.0020\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 5s 703ms/step - loss: 0.0079 - val_loss: 0.0027\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 5s 643ms/step - loss: 0.0074 - val_loss: 0.0022\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 5s 663ms/step - loss: 0.0073 - val_loss: 0.0021\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 5s 693ms/step - loss: 0.0071 - val_loss: 0.0028\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 5s 694ms/step - loss: 0.0071 - val_loss: 0.0018\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 5s 693ms/step - loss: 0.0069 - val_loss: 0.0017\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 5s 660ms/step - loss: 0.0067 - val_loss: 9.7882e-04\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 5s 640ms/step - loss: 0.0064 - val_loss: 0.0013\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 5s 669ms/step - loss: 0.0063 - val_loss: 0.0012\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 5s 640ms/step - loss: 0.0061 - val_loss: 0.0014\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 5s 657ms/step - loss: 0.0061 - val_loss: 9.6635e-04\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 5s 676ms/step - loss: 0.0062 - val_loss: 7.8573e-04\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 5s 689ms/step - loss: 0.0063 - val_loss: 0.0012\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 5s 668ms/step - loss: 0.0058 - val_loss: 0.0012\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 5s 723ms/step - loss: 0.0058 - val_loss: 7.7906e-04\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 5s 658ms/step - loss: 0.0056 - val_loss: 5.9272e-04\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 5s 658ms/step - loss: 0.0056 - val_loss: 5.5974e-04\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 5s 664ms/step - loss: 0.0056 - val_loss: 7.9152e-04\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 5s 695ms/step - loss: 0.0054 - val_loss: 0.0012\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 5s 657ms/step - loss: 0.0055 - val_loss: 9.9080e-04\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 4s 636ms/step - loss: 0.0053 - val_loss: 4.2205e-04\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 4s 635ms/step - loss: 0.0050 - val_loss: 2.8479e-04\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 5s 651ms/step - loss: 0.0056 - val_loss: 5.9441e-04\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 5s 702ms/step - loss: 0.0050 - val_loss: 5.8885e-04\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 5s 684ms/step - loss: 0.0049 - val_loss: 9.5202e-04\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 5s 654ms/step - loss: 0.0046 - val_loss: 9.5938e-04\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 5s 670ms/step - loss: 0.0045 - val_loss: 4.4131e-04\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 5s 681ms/step - loss: 0.0042 - val_loss: 6.7481e-04\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 5s 709ms/step - loss: 0.0041 - val_loss: 2.6451e-04\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 5s 727ms/step - loss: 0.0047 - val_loss: 2.8911e-04\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 5s 663ms/step - loss: 0.0044 - val_loss: 1.9162e-04\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 4s 642ms/step - loss: 0.0051 - val_loss: 3.6953e-04\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 5s 666ms/step - loss: 0.0047 - val_loss: 7.8705e-04\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 5s 679ms/step - loss: 0.0046 - val_loss: 0.0012\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 5s 697ms/step - loss: 0.0054 - val_loss: 0.0012\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 5s 683ms/step - loss: 0.0062 - val_loss: 2.2402e-04\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 4s 643ms/step - loss: 0.0055 - val_loss: 2.7370e-04\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 5s 679ms/step - loss: 0.0051 - val_loss: 0.0013\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 5s 660ms/step - loss: 0.0049 - val_loss: 4.3793e-04\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 4s 627ms/step - loss: 0.0042 - val_loss: 3.3307e-04\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 4s 618ms/step - loss: 0.0042 - val_loss: 9.6360e-04\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 5s 689ms/step - loss: 0.0039 - val_loss: 8.3121e-04\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 5s 725ms/step - loss: 0.0038 - val_loss: 2.7356e-04\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 5s 661ms/step - loss: 0.0039 - val_loss: 3.7888e-04\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 5s 656ms/step - loss: 0.0040 - val_loss: 5.9795e-04\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 4s 644ms/step - loss: 0.0035 - val_loss: 4.1281e-04\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 4s 629ms/step - loss: 0.0036 - val_loss: 3.6375e-04\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 5s 646ms/step - loss: 0.0038 - val_loss: 5.1673e-04\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 4s 636ms/step - loss: 0.0034 - val_loss: 5.4575e-04\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 5s 691ms/step - loss: 0.0035 - val_loss: 4.7552e-04\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 5s 658ms/step - loss: 0.0035 - val_loss: 6.0774e-04\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 5s 675ms/step - loss: 0.0033 - val_loss: 4.5516e-04\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 5s 711ms/step - loss: 0.0033 - val_loss: 2.8930e-04\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 5s 649ms/step - loss: 0.0034 - val_loss: 2.2528e-04\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 5s 635ms/step - loss: 0.0036 - val_loss: 4.7255e-04\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 5s 701ms/step - loss: 0.0031 - val_loss: 4.5709e-04\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 4s 631ms/step - loss: 0.0030 - val_loss: 2.5041e-04\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 5s 662ms/step - loss: 0.0032 - val_loss: 2.8698e-04\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 5s 669ms/step - loss: 0.0032 - val_loss: 3.2164e-04\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 5s 648ms/step - loss: 0.0038 - val_loss: 2.4328e-04\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 4s 621ms/step - loss: 0.0040 - val_loss: 3.5727e-04\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 5s 632ms/step - loss: 0.0034 - val_loss: 5.0498e-04\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 5s 673ms/step - loss: 0.0031 - val_loss: 5.2975e-04\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 5s 649ms/step - loss: 0.0032 - val_loss: 4.9502e-04\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 5s 649ms/step - loss: 0.0030 - val_loss: 5.4755e-04\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 5s 673ms/step - loss: 0.0027 - val_loss: 4.1919e-04\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 5s 690ms/step - loss: 0.0027 - val_loss: 4.3836e-04\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 5s 687ms/step - loss: 0.0027 - val_loss: 4.7651e-04\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 5s 656ms/step - loss: 0.0027 - val_loss: 5.1697e-04\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 4s 620ms/step - loss: 0.0025 - val_loss: 4.0020e-04\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 4s 633ms/step - loss: 0.0024 - val_loss: 4.6684e-04\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 5s 644ms/step - loss: 0.0026 - val_loss: 7.1083e-04\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 4s 628ms/step - loss: 0.0025 - val_loss: 9.5048e-04\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 5s 647ms/step - loss: 0.0023 - val_loss: 6.3330e-04\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 5s 644ms/step - loss: 0.0024 - val_loss: 3.8060e-04\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 5s 664ms/step - loss: 0.0024 - val_loss: 5.4036e-04\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 5s 646ms/step - loss: 0.0023 - val_loss: 4.4189e-04\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 5s 681ms/step - loss: 0.0025 - val_loss: 4.4846e-04\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 5s 642ms/step - loss: 0.0027 - val_loss: 4.1565e-04\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 5s 671ms/step - loss: 0.0028 - val_loss: 2.5954e-04\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 4s 606ms/step - loss: 0.0028 - val_loss: 2.7778e-04\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 4s 637ms/step - loss: 0.0024 - val_loss: 3.7734e-04\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 5s 656ms/step - loss: 0.0023 - val_loss: 4.7635e-04\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 5s 652ms/step - loss: 0.0023 - val_loss: 3.6208e-04\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 4s 649ms/step - loss: 0.0021 - val_loss: 5.1315e-04\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 4s 642ms/step - loss: 0.0023 - val_loss: 6.9153e-04\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 5s 646ms/step - loss: 0.0025 - val_loss: 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_123_layer_call_fn, lstm_cell_123_layer_call_and_return_conditional_losses, lstm_cell_124_layer_call_fn, lstm_cell_124_layer_call_and_return_conditional_losses, lstm_cell_125_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/DOT\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/DOT\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 3s 91ms/step\n",
      "3/3 [==============================] - 0s 82ms/step\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Epoch 1/100\n",
      "10/10 [==============================] - 18s 756ms/step - loss: 0.0381 - val_loss: 0.0097\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 5s 545ms/step - loss: 0.0072 - val_loss: 0.0030\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 6s 558ms/step - loss: 0.0048 - val_loss: 0.0030\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 6s 568ms/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 6s 567ms/step - loss: 0.0024 - val_loss: 0.0060\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 6s 554ms/step - loss: 0.0021 - val_loss: 0.0064\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 5s 552ms/step - loss: 0.0022 - val_loss: 0.0052\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 6s 564ms/step - loss: 0.0020 - val_loss: 0.0053\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 6s 572ms/step - loss: 0.0025 - val_loss: 0.0053\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 6s 552ms/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 6s 557ms/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 6s 575ms/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 6s 556ms/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 5s 551ms/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 6s 564ms/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 6s 559ms/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 6s 561ms/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 6s 562ms/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 6s 574ms/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 6s 558ms/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 5s 549ms/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 6s 562ms/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 6s 566ms/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 6s 559ms/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 6s 573ms/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 6s 574ms/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 6s 558ms/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 6s 581ms/step - loss: 0.0016 - val_loss: 0.0034\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 6s 579ms/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 6s 575ms/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 6s 569ms/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 6s 571ms/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 6s 572ms/step - loss: 0.0016 - val_loss: 0.0032\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 6s 566ms/step - loss: 0.0016 - val_loss: 0.0032\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 6s 559ms/step - loss: 0.0016 - val_loss: 0.0031\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 6s 555ms/step - loss: 0.0014 - val_loss: 0.0027\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 6s 561ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 6s 560ms/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 6s 592ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 6s 552ms/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 6s 571ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 6s 554ms/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 6s 579ms/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 5s 546ms/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 5s 536ms/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 6s 556ms/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 6s 570ms/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 6s 555ms/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 6s 575ms/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 6s 563ms/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 6s 569ms/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 5s 550ms/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 6s 565ms/step - loss: 0.0012 - val_loss: 0.0027\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 6s 574ms/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 6s 555ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 6s 572ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 5s 550ms/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 6s 581ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 6s 556ms/step - loss: 0.0012 - val_loss: 0.0025\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 6s 565ms/step - loss: 0.0011 - val_loss: 0.0025\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 6s 573ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 6s 570ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 6s 554ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 6s 554ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 6s 566ms/step - loss: 0.0010 - val_loss: 0.0029\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 5s 536ms/step - loss: 0.0010 - val_loss: 0.0020\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 6s 581ms/step - loss: 9.1197e-04 - val_loss: 0.0022\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 6s 563ms/step - loss: 9.7970e-04 - val_loss: 0.0020\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 6s 548ms/step - loss: 9.7186e-04 - val_loss: 0.0023\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 6s 561ms/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 6s 582ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 6s 548ms/step - loss: 8.6680e-04 - val_loss: 0.0020\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 6s 564ms/step - loss: 8.8051e-04 - val_loss: 0.0018\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 6s 563ms/step - loss: 9.1605e-04 - val_loss: 0.0015\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 6s 557ms/step - loss: 8.0620e-04 - val_loss: 0.0020\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 5s 540ms/step - loss: 7.9249e-04 - val_loss: 0.0016\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 5s 549ms/step - loss: 8.5973e-04 - val_loss: 0.0018\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 6s 560ms/step - loss: 8.0254e-04 - val_loss: 0.0016\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 6s 561ms/step - loss: 8.5702e-04 - val_loss: 0.0016\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 6s 555ms/step - loss: 7.7585e-04 - val_loss: 0.0020\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 6s 569ms/step - loss: 7.0621e-04 - val_loss: 0.0021\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 6s 574ms/step - loss: 7.1440e-04 - val_loss: 0.0023\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 6s 561ms/step - loss: 7.5668e-04 - val_loss: 0.0022\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 6s 560ms/step - loss: 7.7122e-04 - val_loss: 0.0018\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 6s 573ms/step - loss: 7.0549e-04 - val_loss: 0.0018\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 6s 565ms/step - loss: 8.5952e-04 - val_loss: 0.0032\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 5s 547ms/step - loss: 7.9805e-04 - val_loss: 0.0020\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 6s 581ms/step - loss: 7.3740e-04 - val_loss: 0.0016\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 6s 559ms/step - loss: 6.3687e-04 - val_loss: 0.0013\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 6s 563ms/step - loss: 6.2187e-04 - val_loss: 0.0015\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 5s 541ms/step - loss: 6.2652e-04 - val_loss: 0.0015\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 6s 584ms/step - loss: 6.4274e-04 - val_loss: 0.0015\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 6s 576ms/step - loss: 5.9619e-04 - val_loss: 0.0011\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 6s 565ms/step - loss: 8.1734e-04 - val_loss: 0.0011\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 5s 551ms/step - loss: 9.0184e-04 - val_loss: 0.0017\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 6s 582ms/step - loss: 7.9730e-04 - val_loss: 0.0020\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 6s 553ms/step - loss: 7.7899e-04 - val_loss: 0.0016\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 6s 562ms/step - loss: 6.7709e-04 - val_loss: 0.0013\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 6s 569ms/step - loss: 6.0308e-04 - val_loss: 0.0016\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 6s 560ms/step - loss: 6.5739e-04 - val_loss: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_126_layer_call_fn, lstm_cell_126_layer_call_and_return_conditional_losses, lstm_cell_127_layer_call_fn, lstm_cell_127_layer_call_and_return_conditional_losses, lstm_cell_128_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/HEX\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/HEX\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 4s 90ms/step\n",
      "5/5 [==============================] - 0s 85ms/step\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Epoch 1/100\n",
      "19/19 [==============================] - 22s 782ms/step - loss: 0.0092 - val_loss: 0.0036\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 13s 685ms/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - 13s 678ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 13s 707ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 13s 701ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 14s 715ms/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 13s 682ms/step - loss: 0.0013 - val_loss: 9.2446e-04\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 13s 697ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 13s 680ms/step - loss: 0.0011 - val_loss: 9.9504e-04\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 13s 662ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 13s 690ms/step - loss: 0.0012 - val_loss: 8.8940e-04\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 13s 674ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 13s 694ms/step - loss: 9.3365e-04 - val_loss: 7.8490e-04\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 13s 665ms/step - loss: 8.2362e-04 - val_loss: 8.1987e-04\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 13s 678ms/step - loss: 8.3673e-04 - val_loss: 7.5188e-04\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 13s 671ms/step - loss: 7.6774e-04 - val_loss: 8.3963e-04\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 13s 679ms/step - loss: 7.8150e-04 - val_loss: 0.0022\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 13s 679ms/step - loss: 8.4752e-04 - val_loss: 9.1206e-04\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 13s 669ms/step - loss: 7.0284e-04 - val_loss: 6.9279e-04\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 13s 680ms/step - loss: 6.9520e-04 - val_loss: 0.0015\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 13s 695ms/step - loss: 7.0912e-04 - val_loss: 7.9841e-04\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - 14s 716ms/step - loss: 8.0036e-04 - val_loss: 8.7685e-04\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 13s 711ms/step - loss: 6.8723e-04 - val_loss: 6.9548e-04\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 13s 685ms/step - loss: 7.1789e-04 - val_loss: 7.5319e-04\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 13s 674ms/step - loss: 6.2734e-04 - val_loss: 6.4926e-04\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 13s 711ms/step - loss: 5.9022e-04 - val_loss: 8.7186e-04\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 13s 689ms/step - loss: 6.7152e-04 - val_loss: 6.2284e-04\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 14s 743ms/step - loss: 5.7385e-04 - val_loss: 6.2999e-04\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - 13s 699ms/step - loss: 5.7772e-04 - val_loss: 7.2122e-04\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 12s 652ms/step - loss: 5.6211e-04 - val_loss: 0.0014\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 12s 636ms/step - loss: 5.5197e-04 - val_loss: 5.6395e-04\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 12s 640ms/step - loss: 5.0096e-04 - val_loss: 0.0011\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 12s 629ms/step - loss: 6.0014e-04 - val_loss: 5.6896e-04\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 13s 663ms/step - loss: 4.8663e-04 - val_loss: 5.1572e-04\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 14s 761ms/step - loss: 4.5662e-04 - val_loss: 9.5869e-04\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 14s 743ms/step - loss: 4.6459e-04 - val_loss: 7.5660e-04\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 15s 786ms/step - loss: 4.2258e-04 - val_loss: 7.9588e-04\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 15s 781ms/step - loss: 4.0103e-04 - val_loss: 4.6211e-04\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 14s 710ms/step - loss: 3.8584e-04 - val_loss: 4.4284e-04\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 13s 665ms/step - loss: 4.7904e-04 - val_loss: 6.5688e-04\n",
      "Epoch 41/100\n",
      "19/19 [==============================] - 12s 656ms/step - loss: 4.3968e-04 - val_loss: 4.5962e-04\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 13s 677ms/step - loss: 4.1366e-04 - val_loss: 6.4446e-04\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 13s 699ms/step - loss: 3.9359e-04 - val_loss: 5.7987e-04\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 14s 731ms/step - loss: 3.5786e-04 - val_loss: 5.7407e-04\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 13s 698ms/step - loss: 3.3920e-04 - val_loss: 4.0400e-04\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 13s 696ms/step - loss: 3.8509e-04 - val_loss: 0.0011\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 14s 750ms/step - loss: 4.1722e-04 - val_loss: 5.6446e-04\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - 14s 733ms/step - loss: 3.2459e-04 - val_loss: 3.8041e-04\n",
      "Epoch 49/100\n",
      "19/19 [==============================] - 13s 691ms/step - loss: 3.2029e-04 - val_loss: 4.5438e-04\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 14s 730ms/step - loss: 2.9395e-04 - val_loss: 3.3342e-04\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - 13s 686ms/step - loss: 2.8254e-04 - val_loss: 3.6034e-04\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 12s 655ms/step - loss: 3.0175e-04 - val_loss: 4.0954e-04\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 14s 724ms/step - loss: 2.9748e-04 - val_loss: 8.3028e-04\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 14s 724ms/step - loss: 3.1091e-04 - val_loss: 3.1887e-04\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 13s 697ms/step - loss: 3.1709e-04 - val_loss: 8.0695e-04\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 14s 752ms/step - loss: 3.8034e-04 - val_loss: 3.2032e-04\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 15s 775ms/step - loss: 3.1138e-04 - val_loss: 9.7967e-04\n",
      "Epoch 58/100\n",
      "19/19 [==============================] - 15s 787ms/step - loss: 3.4287e-04 - val_loss: 4.1520e-04\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 15s 778ms/step - loss: 2.9067e-04 - val_loss: 3.2306e-04\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 15s 796ms/step - loss: 3.1367e-04 - val_loss: 3.1208e-04\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 14s 754ms/step - loss: 3.2492e-04 - val_loss: 3.1056e-04\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 14s 712ms/step - loss: 2.7826e-04 - val_loss: 3.3678e-04\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 15s 764ms/step - loss: 2.6423e-04 - val_loss: 3.0654e-04\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - 14s 719ms/step - loss: 2.7894e-04 - val_loss: 6.2321e-04\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - 13s 707ms/step - loss: 3.2661e-04 - val_loss: 3.1359e-04\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - 13s 682ms/step - loss: 3.5047e-04 - val_loss: 3.3480e-04\n",
      "Epoch 67/100\n",
      "19/19 [==============================] - 15s 813ms/step - loss: 2.8601e-04 - val_loss: 3.2692e-04\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - 13s 693ms/step - loss: 3.0036e-04 - val_loss: 3.4209e-04\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - 14s 736ms/step - loss: 2.8510e-04 - val_loss: 6.6540e-04\n",
      "Epoch 70/100\n",
      "19/19 [==============================] - 13s 667ms/step - loss: 2.8480e-04 - val_loss: 3.2966e-04\n",
      "Epoch 71/100\n",
      "19/19 [==============================] - 13s 694ms/step - loss: 2.5868e-04 - val_loss: 3.2039e-04\n",
      "Epoch 72/100\n",
      "19/19 [==============================] - 13s 682ms/step - loss: 2.7640e-04 - val_loss: 2.9402e-04\n",
      "Epoch 73/100\n",
      "19/19 [==============================] - 13s 689ms/step - loss: 2.9262e-04 - val_loss: 0.0010\n",
      "Epoch 74/100\n",
      "19/19 [==============================] - 15s 813ms/step - loss: 3.4868e-04 - val_loss: 3.3906e-04\n",
      "Epoch 75/100\n",
      "19/19 [==============================] - 13s 684ms/step - loss: 3.1161e-04 - val_loss: 3.1519e-04\n",
      "Epoch 76/100\n",
      "19/19 [==============================] - 13s 710ms/step - loss: 2.8883e-04 - val_loss: 3.0043e-04\n",
      "Epoch 77/100\n",
      "19/19 [==============================] - 14s 742ms/step - loss: 2.5763e-04 - val_loss: 3.0977e-04\n",
      "Epoch 78/100\n",
      "19/19 [==============================] - 13s 705ms/step - loss: 2.6074e-04 - val_loss: 2.9821e-04\n",
      "Epoch 79/100\n",
      "19/19 [==============================] - 13s 669ms/step - loss: 2.5561e-04 - val_loss: 2.9829e-04\n",
      "Epoch 80/100\n",
      "19/19 [==============================] - 13s 679ms/step - loss: 2.4628e-04 - val_loss: 5.7925e-04\n",
      "Epoch 81/100\n",
      "19/19 [==============================] - 13s 672ms/step - loss: 2.6959e-04 - val_loss: 3.3332e-04\n",
      "Epoch 82/100\n",
      "19/19 [==============================] - 13s 670ms/step - loss: 2.6120e-04 - val_loss: 3.2967e-04\n",
      "Epoch 83/100\n",
      "19/19 [==============================] - 13s 673ms/step - loss: 2.5408e-04 - val_loss: 4.2633e-04\n",
      "Epoch 84/100\n",
      "19/19 [==============================] - 13s 670ms/step - loss: 2.6895e-04 - val_loss: 4.6794e-04\n",
      "Epoch 85/100\n",
      "19/19 [==============================] - 14s 736ms/step - loss: 2.5319e-04 - val_loss: 4.2591e-04\n",
      "Epoch 86/100\n",
      "19/19 [==============================] - 14s 722ms/step - loss: 2.7807e-04 - val_loss: 3.5281e-04\n",
      "Epoch 87/100\n",
      "19/19 [==============================] - 13s 667ms/step - loss: 2.8349e-04 - val_loss: 4.3433e-04\n",
      "Epoch 88/100\n",
      "19/19 [==============================] - 13s 671ms/step - loss: 2.6460e-04 - val_loss: 3.0016e-04\n",
      "Epoch 89/100\n",
      "19/19 [==============================] - 14s 744ms/step - loss: 2.9097e-04 - val_loss: 3.3196e-04\n",
      "Epoch 90/100\n",
      "19/19 [==============================] - 14s 715ms/step - loss: 2.6980e-04 - val_loss: 3.5923e-04\n",
      "Epoch 91/100\n",
      "19/19 [==============================] - 13s 675ms/step - loss: 2.6279e-04 - val_loss: 5.5741e-04\n",
      "Epoch 92/100\n",
      "19/19 [==============================] - 13s 672ms/step - loss: 2.4420e-04 - val_loss: 2.8588e-04\n",
      "Epoch 93/100\n",
      "19/19 [==============================] - 13s 667ms/step - loss: 2.3867e-04 - val_loss: 2.8615e-04\n",
      "Epoch 94/100\n",
      "19/19 [==============================] - 13s 675ms/step - loss: 2.5492e-04 - val_loss: 3.6064e-04\n",
      "Epoch 95/100\n",
      "19/19 [==============================] - 13s 691ms/step - loss: 2.9426e-04 - val_loss: 2.8870e-04\n",
      "Epoch 96/100\n",
      "19/19 [==============================] - 15s 784ms/step - loss: 2.4574e-04 - val_loss: 3.0628e-04\n",
      "Epoch 97/100\n",
      "19/19 [==============================] - 14s 721ms/step - loss: 2.5438e-04 - val_loss: 4.8347e-04\n",
      "Epoch 98/100\n",
      "19/19 [==============================] - 15s 799ms/step - loss: 2.5091e-04 - val_loss: 3.1957e-04\n",
      "Epoch 99/100\n",
      "19/19 [==============================] - 15s 767ms/step - loss: 2.8678e-04 - val_loss: 7.7864e-04\n",
      "Epoch 100/100\n",
      "19/19 [==============================] - 14s 732ms/step - loss: 2.7584e-04 - val_loss: 4.6569e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_129_layer_call_fn, lstm_cell_129_layer_call_and_return_conditional_losses, lstm_cell_130_layer_call_fn, lstm_cell_130_layer_call_and_return_conditional_losses, lstm_cell_131_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/TRX\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/TRX\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 6s 110ms/step\n",
      "11/11 [==============================] - 1s 107ms/step\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 16s 1s/step - loss: 0.0325 - val_loss: 0.0115\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 6s 781ms/step - loss: 0.0114 - val_loss: 0.0010\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 6s 692ms/step - loss: 0.0092 - val_loss: 0.0016\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 6s 730ms/step - loss: 0.0072 - val_loss: 4.4500e-04\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 6s 702ms/step - loss: 0.0070 - val_loss: 5.0412e-04\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 5s 610ms/step - loss: 0.0075 - val_loss: 4.2617e-04\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 5s 679ms/step - loss: 0.0059 - val_loss: 9.1724e-04\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 5s 629ms/step - loss: 0.0057 - val_loss: 3.3822e-04\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 5s 588ms/step - loss: 0.0056 - val_loss: 4.0509e-04\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 5s 603ms/step - loss: 0.0053 - val_loss: 3.8162e-04\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 5s 586ms/step - loss: 0.0050 - val_loss: 3.0221e-04\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 5s 571ms/step - loss: 0.0049 - val_loss: 0.0013\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 5s 588ms/step - loss: 0.0050 - val_loss: 3.0046e-04\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 5s 588ms/step - loss: 0.0049 - val_loss: 7.6265e-04\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 5s 592ms/step - loss: 0.0046 - val_loss: 6.4316e-04\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 5s 682ms/step - loss: 0.0046 - val_loss: 0.0012\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 6s 728ms/step - loss: 0.0061 - val_loss: 2.3251e-04\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 0.0051 - val_loss: 0.0012\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 6s 686ms/step - loss: 0.0043 - val_loss: 2.3036e-04\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 5s 618ms/step - loss: 0.0043 - val_loss: 0.0011\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 6s 729ms/step - loss: 0.0042 - val_loss: 2.8699e-04\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 6s 726ms/step - loss: 0.0041 - val_loss: 5.4494e-04\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 6s 712ms/step - loss: 0.0040 - val_loss: 3.1586e-04\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 6s 673ms/step - loss: 0.0040 - val_loss: 2.8635e-04\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 6s 779ms/step - loss: 0.0042 - val_loss: 0.0011\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 5s 606ms/step - loss: 0.0041 - val_loss: 2.3613e-04\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 5s 631ms/step - loss: 0.0047 - val_loss: 6.5864e-04\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 5s 605ms/step - loss: 0.0039 - val_loss: 2.2144e-04\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 5s 580ms/step - loss: 0.0040 - val_loss: 5.0428e-04\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 5s 596ms/step - loss: 0.0037 - val_loss: 2.9016e-04\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 5s 599ms/step - loss: 0.0036 - val_loss: 3.4528e-04\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 5s 575ms/step - loss: 0.0035 - val_loss: 2.2297e-04\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 5s 596ms/step - loss: 0.0033 - val_loss: 3.1960e-04\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 5s 609ms/step - loss: 0.0032 - val_loss: 2.4530e-04\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 5s 570ms/step - loss: 0.0032 - val_loss: 2.4492e-04\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 5s 582ms/step - loss: 0.0036 - val_loss: 6.9023e-04\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 5s 592ms/step - loss: 0.0031 - val_loss: 1.8946e-04\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 5s 598ms/step - loss: 0.0031 - val_loss: 8.0274e-04\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 5s 601ms/step - loss: 0.0034 - val_loss: 1.4354e-04\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 5s 664ms/step - loss: 0.0029 - val_loss: 4.2384e-04\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 5s 666ms/step - loss: 0.0027 - val_loss: 2.6108e-04\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 6s 735ms/step - loss: 0.0028 - val_loss: 1.3562e-04\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 5s 667ms/step - loss: 0.0027 - val_loss: 4.2575e-04\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 5s 660ms/step - loss: 0.0026 - val_loss: 8.4753e-04\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 6s 731ms/step - loss: 0.0039 - val_loss: 2.4269e-04\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 6s 748ms/step - loss: 0.0045 - val_loss: 0.0012\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 5s 590ms/step - loss: 0.0028 - val_loss: 2.4568e-04\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 5s 605ms/step - loss: 0.0030 - val_loss: 1.5066e-04\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 5s 589ms/step - loss: 0.0024 - val_loss: 6.5248e-04\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 5s 590ms/step - loss: 0.0025 - val_loss: 1.1378e-04\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 5s 591ms/step - loss: 0.0022 - val_loss: 1.4043e-04\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 5s 595ms/step - loss: 0.0023 - val_loss: 1.8530e-04\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 6s 736ms/step - loss: 0.0022 - val_loss: 1.1482e-04\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 6s 767ms/step - loss: 0.0022 - val_loss: 1.1864e-04\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 5s 664ms/step - loss: 0.0022 - val_loss: 2.6824e-04\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 5s 619ms/step - loss: 0.0020 - val_loss: 1.3456e-04\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 5s 648ms/step - loss: 0.0021 - val_loss: 2.3832e-04\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 5s 624ms/step - loss: 0.0020 - val_loss: 1.2940e-04\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 5s 626ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 5s 625ms/step - loss: 0.0045 - val_loss: 0.0023\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 5s 619ms/step - loss: 0.0039 - val_loss: 0.0014\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 5s 621ms/step - loss: 0.0026 - val_loss: 1.8248e-04\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 6s 740ms/step - loss: 0.0022 - val_loss: 3.5274e-04\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 6s 695ms/step - loss: 0.0021 - val_loss: 1.0879e-04\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 6s 706ms/step - loss: 0.0020 - val_loss: 3.3647e-04\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 6s 722ms/step - loss: 0.0020 - val_loss: 1.8330e-04\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 6s 758ms/step - loss: 0.0021 - val_loss: 5.8201e-04\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 6s 764ms/step - loss: 0.0018 - val_loss: 1.3408e-04\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 5s 639ms/step - loss: 0.0019 - val_loss: 1.9953e-04\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 5s 631ms/step - loss: 0.0018 - val_loss: 1.1099e-04\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 6s 709ms/step - loss: 0.0019 - val_loss: 2.2836e-04\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 6s 743ms/step - loss: 0.0018 - val_loss: 1.2548e-04\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 6s 757ms/step - loss: 0.0018 - val_loss: 1.1831e-04\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 6s 719ms/step - loss: 0.0018 - val_loss: 1.5618e-04\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 6s 706ms/step - loss: 0.0018 - val_loss: 1.2484e-04\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 6s 703ms/step - loss: 0.0017 - val_loss: 1.6377e-04\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 6s 691ms/step - loss: 0.0018 - val_loss: 1.2555e-04\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 6s 696ms/step - loss: 0.0018 - val_loss: 2.1394e-04\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 6s 698ms/step - loss: 0.0017 - val_loss: 1.0885e-04\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 6s 726ms/step - loss: 0.0017 - val_loss: 1.7730e-04\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 5s 627ms/step - loss: 0.0017 - val_loss: 1.3606e-04\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 6s 736ms/step - loss: 0.0016 - val_loss: 1.1712e-04\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 6s 706ms/step - loss: 0.0017 - val_loss: 1.1149e-04\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 5s 647ms/step - loss: 0.0016 - val_loss: 2.6271e-04\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 6s 707ms/step - loss: 0.0041 - val_loss: 0.0023\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 5s 613ms/step - loss: 0.0031 - val_loss: 9.4036e-04\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 5s 594ms/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 5s 583ms/step - loss: 0.0042 - val_loss: 0.0011\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 5s 616ms/step - loss: 0.0033 - val_loss: 6.7913e-04\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 5s 589ms/step - loss: 0.0024 - val_loss: 2.0623e-04\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 5s 581ms/step - loss: 0.0022 - val_loss: 1.1175e-04\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 5s 581ms/step - loss: 0.0020 - val_loss: 1.9669e-04\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 5s 606ms/step - loss: 0.0017 - val_loss: 1.2467e-04\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 5s 588ms/step - loss: 0.0016 - val_loss: 1.4954e-04\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 5s 598ms/step - loss: 0.0016 - val_loss: 1.1268e-04\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 5s 636ms/step - loss: 0.0016 - val_loss: 2.0076e-04\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 5s 584ms/step - loss: 0.0016 - val_loss: 1.1612e-04\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 5s 596ms/step - loss: 0.0016 - val_loss: 1.3462e-04\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 5s 603ms/step - loss: 0.0015 - val_loss: 1.1424e-04\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 5s 583ms/step - loss: 0.0016 - val_loss: 1.0990e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_132_layer_call_fn, lstm_cell_132_layer_call_and_return_conditional_losses, lstm_cell_133_layer_call_fn, lstm_cell_133_layer_call_and_return_conditional_losses, lstm_cell_134_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/SHIB\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/SHIB\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 4s 111ms/step\n",
      "3/3 [==============================] - 0s 112ms/step\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Epoch 1/100\n",
      "13/13 [==============================] - 17s 741ms/step - loss: 0.0057 - val_loss: 0.0381\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 8s 604ms/step - loss: 0.0012 - val_loss: 0.0161\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 8s 600ms/step - loss: 7.4468e-04 - val_loss: 0.0150\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 8s 598ms/step - loss: 6.8239e-04 - val_loss: 0.0110\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 8s 594ms/step - loss: 6.7274e-04 - val_loss: 0.0165\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 8s 599ms/step - loss: 6.6333e-04 - val_loss: 0.0192\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 8s 595ms/step - loss: 6.4536e-04 - val_loss: 0.0212\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 8s 603ms/step - loss: 6.1891e-04 - val_loss: 0.0153\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 8s 605ms/step - loss: 5.9251e-04 - val_loss: 0.0216\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 8s 606ms/step - loss: 5.7518e-04 - val_loss: 0.0158\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 8s 606ms/step - loss: 5.9297e-04 - val_loss: 0.0205\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 8s 601ms/step - loss: 5.9717e-04 - val_loss: 0.0229\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 8s 613ms/step - loss: 5.9058e-04 - val_loss: 0.0277\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 8s 603ms/step - loss: 5.7433e-04 - val_loss: 0.0213\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 8s 607ms/step - loss: 5.4926e-04 - val_loss: 0.0317\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 8s 611ms/step - loss: 5.1217e-04 - val_loss: 0.0216\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 8s 602ms/step - loss: 5.6020e-04 - val_loss: 0.0177\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 8s 630ms/step - loss: 5.0816e-04 - val_loss: 0.0192\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 9s 653ms/step - loss: 5.0145e-04 - val_loss: 0.0414\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 8s 627ms/step - loss: 5.0419e-04 - val_loss: 0.0322\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 8s 606ms/step - loss: 4.1480e-04 - val_loss: 0.0399\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 8s 600ms/step - loss: 4.1386e-04 - val_loss: 0.0370\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 8s 654ms/step - loss: 3.5553e-04 - val_loss: 0.0340\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 8s 611ms/step - loss: 3.7813e-04 - val_loss: 0.0365\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 8s 591ms/step - loss: 3.3424e-04 - val_loss: 0.0532\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 8s 599ms/step - loss: 3.4471e-04 - val_loss: 0.0285\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 8s 594ms/step - loss: 3.2063e-04 - val_loss: 0.0262\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 8s 605ms/step - loss: 3.1543e-04 - val_loss: 0.0363\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 8s 594ms/step - loss: 3.5190e-04 - val_loss: 0.0351\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 8s 606ms/step - loss: 2.9390e-04 - val_loss: 0.0273\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 8s 602ms/step - loss: 2.8168e-04 - val_loss: 0.0318\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 8s 605ms/step - loss: 2.6018e-04 - val_loss: 0.0313\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 8s 588ms/step - loss: 2.5134e-04 - val_loss: 0.0334\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 8s 593ms/step - loss: 2.3593e-04 - val_loss: 0.0296\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 8s 610ms/step - loss: 2.4483e-04 - val_loss: 0.0305\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 8s 592ms/step - loss: 2.3250e-04 - val_loss: 0.0229\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 8s 643ms/step - loss: 2.5063e-04 - val_loss: 0.0276\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 8s 632ms/step - loss: 2.2849e-04 - val_loss: 0.0235\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 8s 639ms/step - loss: 2.2500e-04 - val_loss: 0.0288\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 8s 596ms/step - loss: 2.2515e-04 - val_loss: 0.0267\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 8s 591ms/step - loss: 2.3272e-04 - val_loss: 0.0220\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 8s 599ms/step - loss: 2.1411e-04 - val_loss: 0.0312\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 8s 614ms/step - loss: 2.1593e-04 - val_loss: 0.0191\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 8s 597ms/step - loss: 2.3781e-04 - val_loss: 0.0392\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 8s 588ms/step - loss: 2.2428e-04 - val_loss: 0.0261\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 8s 601ms/step - loss: 2.0436e-04 - val_loss: 0.0288\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 8s 618ms/step - loss: 1.9549e-04 - val_loss: 0.0259\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 8s 587ms/step - loss: 1.9694e-04 - val_loss: 0.0242\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 8s 593ms/step - loss: 1.9947e-04 - val_loss: 0.0361\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 8s 604ms/step - loss: 1.9497e-04 - val_loss: 0.0309\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 8s 596ms/step - loss: 1.9964e-04 - val_loss: 0.0372\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 8s 587ms/step - loss: 2.1685e-04 - val_loss: 0.0475\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 8s 602ms/step - loss: 2.3432e-04 - val_loss: 0.0325\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 8s 626ms/step - loss: 1.8936e-04 - val_loss: 0.0275\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 8s 611ms/step - loss: 1.9290e-04 - val_loss: 0.0383\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 8s 614ms/step - loss: 1.9106e-04 - val_loss: 0.0531\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 8s 589ms/step - loss: 1.9056e-04 - val_loss: 0.0289\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 8s 601ms/step - loss: 1.9657e-04 - val_loss: 0.0313\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 8s 599ms/step - loss: 1.9396e-04 - val_loss: 0.0362\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 8s 590ms/step - loss: 2.2781e-04 - val_loss: 0.0254\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 8s 607ms/step - loss: 2.4405e-04 - val_loss: 0.0400\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 8s 618ms/step - loss: 2.2682e-04 - val_loss: 0.0331\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 8s 596ms/step - loss: 1.9457e-04 - val_loss: 0.0330\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 8s 595ms/step - loss: 1.8766e-04 - val_loss: 0.0407\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 8s 604ms/step - loss: 1.8733e-04 - val_loss: 0.0427\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 8s 609ms/step - loss: 1.8172e-04 - val_loss: 0.0254\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 8s 593ms/step - loss: 2.2302e-04 - val_loss: 0.0437\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 8s 607ms/step - loss: 1.9821e-04 - val_loss: 0.0436\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 8s 599ms/step - loss: 2.1036e-04 - val_loss: 0.0281\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 8s 655ms/step - loss: 1.9424e-04 - val_loss: 0.0514\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 8s 598ms/step - loss: 1.6936e-04 - val_loss: 0.0451\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 8s 604ms/step - loss: 1.8194e-04 - val_loss: 0.0557\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 8s 614ms/step - loss: 1.7859e-04 - val_loss: 0.0387\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 8s 598ms/step - loss: 1.7458e-04 - val_loss: 0.0580\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 8s 607ms/step - loss: 1.7880e-04 - val_loss: 0.0490\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 8s 596ms/step - loss: 1.6724e-04 - val_loss: 0.0335\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 8s 605ms/step - loss: 1.8524e-04 - val_loss: 0.0601\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 8s 601ms/step - loss: 1.9093e-04 - val_loss: 0.0487\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 8s 616ms/step - loss: 1.6901e-04 - val_loss: 0.0611\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 8s 606ms/step - loss: 1.9826e-04 - val_loss: 0.0571\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 8s 606ms/step - loss: 1.7514e-04 - val_loss: 0.0418\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 8s 609ms/step - loss: 1.7994e-04 - val_loss: 0.0681\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 8s 592ms/step - loss: 1.8370e-04 - val_loss: 0.0506\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 8s 606ms/step - loss: 1.6292e-04 - val_loss: 0.0627\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 8s 606ms/step - loss: 1.6855e-04 - val_loss: 0.0319\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 8s 608ms/step - loss: 1.7342e-04 - val_loss: 0.0530\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 8s 606ms/step - loss: 1.8168e-04 - val_loss: 0.0526\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 8s 590ms/step - loss: 1.9076e-04 - val_loss: 0.0467\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 8s 609ms/step - loss: 1.6470e-04 - val_loss: 0.0409\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 8s 604ms/step - loss: 1.6519e-04 - val_loss: 0.0489\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 8s 612ms/step - loss: 1.5735e-04 - val_loss: 0.0515\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 8s 647ms/step - loss: 1.5821e-04 - val_loss: 0.0490\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 8s 606ms/step - loss: 1.7045e-04 - val_loss: 0.0654\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 8s 609ms/step - loss: 1.6308e-04 - val_loss: 0.0405\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 8s 602ms/step - loss: 2.3411e-04 - val_loss: 0.0569\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 8s 614ms/step - loss: 1.8280e-04 - val_loss: 0.0575\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 8s 593ms/step - loss: 1.7898e-04 - val_loss: 0.0581\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 8s 608ms/step - loss: 1.7230e-04 - val_loss: 0.0693\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 8s 601ms/step - loss: 1.5989e-04 - val_loss: 0.0638\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 8s 613ms/step - loss: 1.6142e-04 - val_loss: 0.0772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_135_layer_call_fn, lstm_cell_135_layer_call_and_return_conditional_losses, lstm_cell_136_layer_call_fn, lstm_cell_136_layer_call_and_return_conditional_losses, lstm_cell_137_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/LEO\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/LEO\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 4s 97ms/step\n",
      "7/7 [==============================] - 1s 83ms/step\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 19s 950ms/step - loss: 0.0288 - val_loss: 0.0093\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 10s 675ms/step - loss: 0.0044 - val_loss: 0.0030\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 9s 649ms/step - loss: 0.0029 - val_loss: 0.0049\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 9s 659ms/step - loss: 0.0027 - val_loss: 0.0052\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 9s 647ms/step - loss: 0.0024 - val_loss: 0.0047\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 9s 637ms/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 9s 669ms/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 9s 640ms/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 9s 681ms/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 10s 732ms/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 9s 653ms/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 9s 652ms/step - loss: 0.0020 - val_loss: 0.0053\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 9s 658ms/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 9s 660ms/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 9s 649ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 9s 657ms/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 9s 654ms/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 9s 638ms/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 9s 643ms/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 9s 662ms/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 9s 653ms/step - loss: 0.0013 - val_loss: 0.0034\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 9s 656ms/step - loss: 0.0014 - val_loss: 0.0031\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 9s 649ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 9s 644ms/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 9s 669ms/step - loss: 0.0012 - val_loss: 0.0029\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 10s 692ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 9s 670ms/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 9s 648ms/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 29/100\n",
      "14/14 [==============================] - 9s 679ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 30/100\n",
      "14/14 [==============================] - 9s 678ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 31/100\n",
      "14/14 [==============================] - 10s 693ms/step - loss: 9.5857e-04 - val_loss: 0.0032\n",
      "Epoch 32/100\n",
      "14/14 [==============================] - 10s 711ms/step - loss: 8.9830e-04 - val_loss: 0.0013\n",
      "Epoch 33/100\n",
      "14/14 [==============================] - 10s 693ms/step - loss: 9.2808e-04 - val_loss: 0.0023\n",
      "Epoch 34/100\n",
      "14/14 [==============================] - 10s 703ms/step - loss: 0.0010 - val_loss: 0.0020\n",
      "Epoch 35/100\n",
      "14/14 [==============================] - 9s 662ms/step - loss: 9.1545e-04 - val_loss: 0.0016\n",
      "Epoch 36/100\n",
      "14/14 [==============================] - 10s 686ms/step - loss: 9.4196e-04 - val_loss: 0.0023\n",
      "Epoch 37/100\n",
      "14/14 [==============================] - 9s 654ms/step - loss: 8.5231e-04 - val_loss: 0.0012\n",
      "Epoch 38/100\n",
      "14/14 [==============================] - 9s 650ms/step - loss: 9.8517e-04 - val_loss: 0.0027\n",
      "Epoch 39/100\n",
      "14/14 [==============================] - 9s 653ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 40/100\n",
      "14/14 [==============================] - 9s 650ms/step - loss: 8.5481e-04 - val_loss: 0.0013\n",
      "Epoch 41/100\n",
      "14/14 [==============================] - 9s 647ms/step - loss: 7.9809e-04 - val_loss: 0.0015\n",
      "Epoch 42/100\n",
      "14/14 [==============================] - 9s 648ms/step - loss: 7.5544e-04 - val_loss: 0.0011\n",
      "Epoch 43/100\n",
      "14/14 [==============================] - 9s 662ms/step - loss: 8.7865e-04 - val_loss: 0.0013\n",
      "Epoch 44/100\n",
      "14/14 [==============================] - 9s 658ms/step - loss: 9.1773e-04 - val_loss: 0.0016\n",
      "Epoch 45/100\n",
      "14/14 [==============================] - 9s 665ms/step - loss: 8.0460e-04 - val_loss: 0.0011\n",
      "Epoch 46/100\n",
      "14/14 [==============================] - 9s 649ms/step - loss: 8.1343e-04 - val_loss: 0.0013\n",
      "Epoch 47/100\n",
      "14/14 [==============================] - 9s 652ms/step - loss: 7.0330e-04 - val_loss: 0.0018\n",
      "Epoch 48/100\n",
      "14/14 [==============================] - 9s 653ms/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 49/100\n",
      "14/14 [==============================] - 9s 668ms/step - loss: 9.1024e-04 - val_loss: 0.0019\n",
      "Epoch 50/100\n",
      "14/14 [==============================] - 9s 649ms/step - loss: 6.9543e-04 - val_loss: 0.0011\n",
      "Epoch 51/100\n",
      "14/14 [==============================] - 9s 646ms/step - loss: 8.5868e-04 - val_loss: 0.0024\n",
      "Epoch 52/100\n",
      "14/14 [==============================] - 9s 657ms/step - loss: 7.1856e-04 - val_loss: 0.0011\n",
      "Epoch 53/100\n",
      "14/14 [==============================] - 9s 638ms/step - loss: 6.4812e-04 - val_loss: 0.0014\n",
      "Epoch 54/100\n",
      "14/14 [==============================] - 9s 653ms/step - loss: 6.5589e-04 - val_loss: 0.0011\n",
      "Epoch 55/100\n",
      "14/14 [==============================] - 9s 665ms/step - loss: 7.2507e-04 - val_loss: 0.0013\n",
      "Epoch 56/100\n",
      "14/14 [==============================] - 9s 649ms/step - loss: 9.1286e-04 - val_loss: 0.0014\n",
      "Epoch 57/100\n",
      "14/14 [==============================] - 9s 645ms/step - loss: 6.8766e-04 - val_loss: 0.0010\n",
      "Epoch 58/100\n",
      "14/14 [==============================] - 9s 659ms/step - loss: 6.6412e-04 - val_loss: 0.0012\n",
      "Epoch 59/100\n",
      "14/14 [==============================] - 9s 640ms/step - loss: 7.2946e-04 - val_loss: 0.0014\n",
      "Epoch 60/100\n",
      "14/14 [==============================] - 9s 657ms/step - loss: 6.5695e-04 - val_loss: 0.0012\n",
      "Epoch 61/100\n",
      "14/14 [==============================] - 10s 693ms/step - loss: 6.2423e-04 - val_loss: 0.0012\n",
      "Epoch 62/100\n",
      "14/14 [==============================] - 10s 687ms/step - loss: 6.4242e-04 - val_loss: 0.0016\n",
      "Epoch 63/100\n",
      "14/14 [==============================] - 9s 657ms/step - loss: 8.3360e-04 - val_loss: 0.0011\n",
      "Epoch 64/100\n",
      "14/14 [==============================] - 9s 649ms/step - loss: 7.6409e-04 - val_loss: 0.0013\n",
      "Epoch 65/100\n",
      "14/14 [==============================] - 9s 663ms/step - loss: 6.2964e-04 - val_loss: 9.6628e-04\n",
      "Epoch 66/100\n",
      "14/14 [==============================] - 9s 639ms/step - loss: 5.5632e-04 - val_loss: 0.0013\n",
      "Epoch 67/100\n",
      "14/14 [==============================] - 9s 671ms/step - loss: 5.8019e-04 - val_loss: 0.0012\n",
      "Epoch 68/100\n",
      "14/14 [==============================] - 9s 667ms/step - loss: 6.4990e-04 - val_loss: 0.0010\n",
      "Epoch 69/100\n",
      "14/14 [==============================] - 9s 662ms/step - loss: 5.9917e-04 - val_loss: 0.0013\n",
      "Epoch 70/100\n",
      "14/14 [==============================] - 9s 653ms/step - loss: 5.3379e-04 - val_loss: 0.0010\n",
      "Epoch 71/100\n",
      "14/14 [==============================] - 9s 652ms/step - loss: 5.2578e-04 - val_loss: 0.0015\n",
      "Epoch 72/100\n",
      "14/14 [==============================] - 9s 646ms/step - loss: 5.3712e-04 - val_loss: 0.0010\n",
      "Epoch 73/100\n",
      "14/14 [==============================] - 9s 659ms/step - loss: 5.4561e-04 - val_loss: 0.0016\n",
      "Epoch 74/100\n",
      "14/14 [==============================] - 9s 649ms/step - loss: 5.2535e-04 - val_loss: 0.0011\n",
      "Epoch 75/100\n",
      "14/14 [==============================] - 9s 665ms/step - loss: 5.7995e-04 - val_loss: 0.0014\n",
      "Epoch 76/100\n",
      "14/14 [==============================] - 9s 645ms/step - loss: 5.4877e-04 - val_loss: 0.0015\n",
      "Epoch 77/100\n",
      "14/14 [==============================] - 9s 652ms/step - loss: 5.9616e-04 - val_loss: 9.4025e-04\n",
      "Epoch 78/100\n",
      "14/14 [==============================] - 9s 665ms/step - loss: 5.4565e-04 - val_loss: 0.0015\n",
      "Epoch 79/100\n",
      "14/14 [==============================] - 9s 642ms/step - loss: 5.0819e-04 - val_loss: 0.0013\n",
      "Epoch 80/100\n",
      "14/14 [==============================] - 9s 651ms/step - loss: 5.1144e-04 - val_loss: 9.6239e-04\n",
      "Epoch 81/100\n",
      "14/14 [==============================] - 9s 657ms/step - loss: 4.9588e-04 - val_loss: 0.0012\n",
      "Epoch 82/100\n",
      "14/14 [==============================] - 9s 653ms/step - loss: 4.7093e-04 - val_loss: 0.0010\n",
      "Epoch 83/100\n",
      "14/14 [==============================] - 9s 669ms/step - loss: 5.0293e-04 - val_loss: 0.0013\n",
      "Epoch 84/100\n",
      "14/14 [==============================] - 9s 674ms/step - loss: 5.3584e-04 - val_loss: 9.8748e-04\n",
      "Epoch 85/100\n",
      "14/14 [==============================] - 10s 673ms/step - loss: 4.5362e-04 - val_loss: 0.0011\n",
      "Epoch 86/100\n",
      "14/14 [==============================] - 9s 659ms/step - loss: 5.3429e-04 - val_loss: 9.3791e-04\n",
      "Epoch 87/100\n",
      "14/14 [==============================] - 9s 647ms/step - loss: 5.4180e-04 - val_loss: 8.4393e-04\n",
      "Epoch 88/100\n",
      "14/14 [==============================] - 9s 679ms/step - loss: 5.5872e-04 - val_loss: 0.0021\n",
      "Epoch 89/100\n",
      "14/14 [==============================] - 9s 651ms/step - loss: 5.1620e-04 - val_loss: 0.0011\n",
      "Epoch 90/100\n",
      "14/14 [==============================] - 9s 653ms/step - loss: 4.3737e-04 - val_loss: 0.0011\n",
      "Epoch 91/100\n",
      "14/14 [==============================] - 9s 656ms/step - loss: 4.2781e-04 - val_loss: 8.4854e-04\n",
      "Epoch 92/100\n",
      "14/14 [==============================] - 9s 660ms/step - loss: 4.3388e-04 - val_loss: 9.8885e-04\n",
      "Epoch 93/100\n",
      "14/14 [==============================] - 9s 642ms/step - loss: 5.9698e-04 - val_loss: 8.2087e-04\n",
      "Epoch 94/100\n",
      "14/14 [==============================] - 9s 646ms/step - loss: 5.9665e-04 - val_loss: 0.0012\n",
      "Epoch 95/100\n",
      "14/14 [==============================] - 10s 702ms/step - loss: 6.3748e-04 - val_loss: 0.0010\n",
      "Epoch 96/100\n",
      "14/14 [==============================] - 9s 651ms/step - loss: 5.4785e-04 - val_loss: 8.4637e-04\n",
      "Epoch 97/100\n",
      "14/14 [==============================] - 9s 651ms/step - loss: 5.6780e-04 - val_loss: 0.0017\n",
      "Epoch 98/100\n",
      "14/14 [==============================] - 9s 652ms/step - loss: 4.3616e-04 - val_loss: 0.0010\n",
      "Epoch 99/100\n",
      "14/14 [==============================] - 9s 668ms/step - loss: 4.2348e-04 - val_loss: 0.0013\n",
      "Epoch 100/100\n",
      "14/14 [==============================] - 9s 652ms/step - loss: 3.9042e-04 - val_loss: 9.3501e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_138_layer_call_fn, lstm_cell_138_layer_call_and_return_conditional_losses, lstm_cell_139_layer_call_fn, lstm_cell_139_layer_call_and_return_conditional_losses, lstm_cell_140_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/WBTC\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/WBTC\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 4s 98ms/step\n",
      "7/7 [==============================] - 1s 99ms/step\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 12s 761ms/step - loss: 0.1015 - val_loss: 0.0282\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 4s 510ms/step - loss: 0.0219 - val_loss: 0.0045\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 4s 517ms/step - loss: 0.0170 - val_loss: 0.0045\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 4s 515ms/step - loss: 0.0105 - val_loss: 0.0069\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 4s 512ms/step - loss: 0.0088 - val_loss: 0.0014\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 4s 519ms/step - loss: 0.0081 - val_loss: 0.0030\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 4s 509ms/step - loss: 0.0085 - val_loss: 0.0018\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 4s 509ms/step - loss: 0.0077 - val_loss: 0.0021\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 4s 504ms/step - loss: 0.0074 - val_loss: 0.0022\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 4s 515ms/step - loss: 0.0072 - val_loss: 0.0023\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 4s 522ms/step - loss: 0.0070 - val_loss: 0.0016\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 4s 511ms/step - loss: 0.0070 - val_loss: 0.0018\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 4s 517ms/step - loss: 0.0067 - val_loss: 0.0017\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 4s 512ms/step - loss: 0.0066 - val_loss: 0.0012\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 4s 504ms/step - loss: 0.0067 - val_loss: 0.0018\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 4s 506ms/step - loss: 0.0063 - val_loss: 0.0017\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 4s 498ms/step - loss: 0.0059 - val_loss: 0.0014\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 4s 514ms/step - loss: 0.0057 - val_loss: 0.0012\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 4s 507ms/step - loss: 0.0055 - val_loss: 0.0012\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 4s 506ms/step - loss: 0.0054 - val_loss: 8.1570e-04\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 4s 514ms/step - loss: 0.0054 - val_loss: 0.0014\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 4s 516ms/step - loss: 0.0050 - val_loss: 0.0013\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 4s 507ms/step - loss: 0.0048 - val_loss: 0.0015\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 4s 523ms/step - loss: 0.0047 - val_loss: 9.3625e-04\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 4s 508ms/step - loss: 0.0046 - val_loss: 9.3195e-04\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 4s 498ms/step - loss: 0.0047 - val_loss: 0.0018\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 4s 502ms/step - loss: 0.0045 - val_loss: 0.0014\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 4s 510ms/step - loss: 0.0040 - val_loss: 0.0013\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 4s 506ms/step - loss: 0.0042 - val_loss: 7.6582e-04\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 4s 512ms/step - loss: 0.0038 - val_loss: 0.0013\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 4s 518ms/step - loss: 0.0039 - val_loss: 0.0012\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 4s 509ms/step - loss: 0.0038 - val_loss: 9.2846e-04\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 4s 499ms/step - loss: 0.0037 - val_loss: 0.0010\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 4s 507ms/step - loss: 0.0037 - val_loss: 7.8897e-04\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 4s 538ms/step - loss: 0.0037 - val_loss: 6.5431e-04\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 4s 516ms/step - loss: 0.0035 - val_loss: 0.0010\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 4s 504ms/step - loss: 0.0038 - val_loss: 0.0012\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 4s 531ms/step - loss: 0.0037 - val_loss: 9.4421e-04\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 4s 515ms/step - loss: 0.0035 - val_loss: 0.0011\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 4s 504ms/step - loss: 0.0035 - val_loss: 0.0013\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 4s 506ms/step - loss: 0.0048 - val_loss: 5.1996e-04\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 4s 510ms/step - loss: 0.0036 - val_loss: 7.9097e-04\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 4s 510ms/step - loss: 0.0036 - val_loss: 0.0012\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 4s 499ms/step - loss: 0.0035 - val_loss: 8.3136e-04\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 4s 503ms/step - loss: 0.0033 - val_loss: 5.5966e-04\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 4s 518ms/step - loss: 0.0035 - val_loss: 8.2109e-04\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 4s 505ms/step - loss: 0.0033 - val_loss: 0.0011\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 4s 523ms/step - loss: 0.0032 - val_loss: 7.4799e-04\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 4s 526ms/step - loss: 0.0031 - val_loss: 7.3888e-04\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 4s 537ms/step - loss: 0.0031 - val_loss: 0.0011\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 4s 528ms/step - loss: 0.0033 - val_loss: 6.3463e-04\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 4s 518ms/step - loss: 0.0031 - val_loss: 7.2318e-04\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 4s 529ms/step - loss: 0.0030 - val_loss: 6.0372e-04\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 4s 517ms/step - loss: 0.0032 - val_loss: 8.8936e-04\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 4s 522ms/step - loss: 0.0031 - val_loss: 0.0012\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 4s 503ms/step - loss: 0.0032 - val_loss: 8.2347e-04\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 4s 515ms/step - loss: 0.0031 - val_loss: 5.5561e-04\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 4s 506ms/step - loss: 0.0028 - val_loss: 6.5497e-04\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 4s 492ms/step - loss: 0.0028 - val_loss: 5.9078e-04\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 4s 511ms/step - loss: 0.0029 - val_loss: 4.5060e-04\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 4s 550ms/step - loss: 0.0032 - val_loss: 7.3266e-04\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 4s 512ms/step - loss: 0.0028 - val_loss: 4.7542e-04\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 4s 519ms/step - loss: 0.0030 - val_loss: 6.0753e-04\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 4s 513ms/step - loss: 0.0027 - val_loss: 0.0011\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 4s 504ms/step - loss: 0.0029 - val_loss: 4.4539e-04\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 4s 501ms/step - loss: 0.0027 - val_loss: 4.4925e-04\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 4s 508ms/step - loss: 0.0027 - val_loss: 9.0029e-04\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 4s 545ms/step - loss: 0.0026 - val_loss: 6.9630e-04\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 4s 516ms/step - loss: 0.0027 - val_loss: 4.0731e-04\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 4s 500ms/step - loss: 0.0027 - val_loss: 4.4481e-04\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 4s 513ms/step - loss: 0.0026 - val_loss: 5.6896e-04\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 4s 524ms/step - loss: 0.0026 - val_loss: 7.1048e-04\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 4s 505ms/step - loss: 0.0026 - val_loss: 8.7944e-04\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 4s 509ms/step - loss: 0.0028 - val_loss: 4.1249e-04\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 4s 512ms/step - loss: 0.0025 - val_loss: 5.0084e-04\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 4s 515ms/step - loss: 0.0024 - val_loss: 7.6576e-04\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 4s 498ms/step - loss: 0.0024 - val_loss: 4.4293e-04\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 4s 509ms/step - loss: 0.0024 - val_loss: 4.2613e-04\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 4s 508ms/step - loss: 0.0022 - val_loss: 6.9541e-04\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 4s 511ms/step - loss: 0.0023 - val_loss: 4.3312e-04\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 4s 498ms/step - loss: 0.0022 - val_loss: 4.1323e-04\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 4s 508ms/step - loss: 0.0021 - val_loss: 4.2576e-04\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 4s 516ms/step - loss: 0.0021 - val_loss: 5.8071e-04\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 4s 518ms/step - loss: 0.0023 - val_loss: 4.3951e-04\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 4s 506ms/step - loss: 0.0021 - val_loss: 4.7543e-04\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 4s 505ms/step - loss: 0.0023 - val_loss: 4.2247e-04\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 4s 512ms/step - loss: 0.0022 - val_loss: 3.3768e-04\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 4s 514ms/step - loss: 0.0023 - val_loss: 3.8469e-04\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 4s 515ms/step - loss: 0.0021 - val_loss: 3.4225e-04\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 4s 499ms/step - loss: 0.0020 - val_loss: 3.8960e-04\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 4s 500ms/step - loss: 0.0020 - val_loss: 6.5663e-04\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 4s 507ms/step - loss: 0.0020 - val_loss: 3.3545e-04\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 4s 507ms/step - loss: 0.0019 - val_loss: 3.2529e-04\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 4s 501ms/step - loss: 0.0021 - val_loss: 3.3542e-04\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 4s 508ms/step - loss: 0.0019 - val_loss: 3.2239e-04\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 4s 512ms/step - loss: 0.0020 - val_loss: 3.1954e-04\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 4s 516ms/step - loss: 0.0019 - val_loss: 4.0891e-04\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 4s 495ms/step - loss: 0.0019 - val_loss: 3.1421e-04\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 4s 507ms/step - loss: 0.0019 - val_loss: 3.1200e-04\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 4s 521ms/step - loss: 0.0019 - val_loss: 3.0183e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_141_layer_call_fn, lstm_cell_141_layer_call_and_return_conditional_losses, lstm_cell_142_layer_call_fn, lstm_cell_142_layer_call_and_return_conditional_losses, lstm_cell_143_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/AVAX\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/AVAX\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 3s 94ms/step\n",
      "3/3 [==============================] - 0s 75ms/step\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 12s 847ms/step - loss: 0.0299 - val_loss: 0.0139\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 4s 585ms/step - loss: 0.0074 - val_loss: 0.1837\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 4s 615ms/step - loss: 0.0054 - val_loss: 0.0309\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 4s 607ms/step - loss: 0.0039 - val_loss: 0.0442\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 4s 596ms/step - loss: 0.0032 - val_loss: 0.0178\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 4s 608ms/step - loss: 0.0029 - val_loss: 0.0153\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 4s 584ms/step - loss: 0.0026 - val_loss: 0.0227\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 4s 598ms/step - loss: 0.0026 - val_loss: 0.0299\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 4s 633ms/step - loss: 0.0025 - val_loss: 0.0301\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 4s 601ms/step - loss: 0.0023 - val_loss: 0.0238\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 4s 612ms/step - loss: 0.0023 - val_loss: 0.0230\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 4s 605ms/step - loss: 0.0022 - val_loss: 0.0269\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 4s 611ms/step - loss: 0.0023 - val_loss: 0.0258\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 4s 597ms/step - loss: 0.0022 - val_loss: 0.0338\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 4s 618ms/step - loss: 0.0022 - val_loss: 0.0196\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 4s 625ms/step - loss: 0.0024 - val_loss: 0.0428\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 4s 612ms/step - loss: 0.0022 - val_loss: 0.0200\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 4s 608ms/step - loss: 0.0021 - val_loss: 0.0344\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 4s 599ms/step - loss: 0.0020 - val_loss: 0.0339\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 4s 609ms/step - loss: 0.0020 - val_loss: 0.0307\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 4s 581ms/step - loss: 0.0019 - val_loss: 0.0350\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 5s 665ms/step - loss: 0.0019 - val_loss: 0.0471\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 5s 647ms/step - loss: 0.0018 - val_loss: 0.0395\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 4s 618ms/step - loss: 0.0019 - val_loss: 0.0666\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 5s 642ms/step - loss: 0.0019 - val_loss: 0.0682\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 4s 618ms/step - loss: 0.0019 - val_loss: 0.0717\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 4s 591ms/step - loss: 0.0019 - val_loss: 0.0553\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 4s 590ms/step - loss: 0.0018 - val_loss: 0.0590\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 5s 655ms/step - loss: 0.0018 - val_loss: 0.0982\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 4s 616ms/step - loss: 0.0019 - val_loss: 0.0680\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 5s 690ms/step - loss: 0.0018 - val_loss: 0.0439\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 4s 615ms/step - loss: 0.0018 - val_loss: 0.0702\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 5s 676ms/step - loss: 0.0018 - val_loss: 0.0611\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 5s 648ms/step - loss: 0.0018 - val_loss: 0.0773\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 4s 614ms/step - loss: 0.0017 - val_loss: 0.0437\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 4s 620ms/step - loss: 0.0017 - val_loss: 0.0683\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 4s 587ms/step - loss: 0.0018 - val_loss: 0.0715\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 4s 604ms/step - loss: 0.0017 - val_loss: 0.0446\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 4s 614ms/step - loss: 0.0018 - val_loss: 0.0375\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 5s 627ms/step - loss: 0.0019 - val_loss: 0.0787\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 4s 596ms/step - loss: 0.0019 - val_loss: 0.0638\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 4s 594ms/step - loss: 0.0017 - val_loss: 0.0373\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 4s 585ms/step - loss: 0.0016 - val_loss: 0.0715\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 4s 588ms/step - loss: 0.0017 - val_loss: 0.0558\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 4s 611ms/step - loss: 0.0016 - val_loss: 0.0482\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 4s 616ms/step - loss: 0.0016 - val_loss: 0.0635\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 4s 608ms/step - loss: 0.0016 - val_loss: 0.0447\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 4s 609ms/step - loss: 0.0017 - val_loss: 0.0589\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 4s 591ms/step - loss: 0.0017 - val_loss: 0.0666\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 4s 620ms/step - loss: 0.0016 - val_loss: 0.0604\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 4s 586ms/step - loss: 0.0016 - val_loss: 0.0442\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 4s 582ms/step - loss: 0.0017 - val_loss: 0.0796\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 4s 605ms/step - loss: 0.0016 - val_loss: 0.0522\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 4s 593ms/step - loss: 0.0015 - val_loss: 0.0572\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 4s 589ms/step - loss: 0.0015 - val_loss: 0.0455\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 4s 608ms/step - loss: 0.0015 - val_loss: 0.0515\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 4s 566ms/step - loss: 0.0015 - val_loss: 0.0730\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 4s 595ms/step - loss: 0.0015 - val_loss: 0.0608\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 4s 599ms/step - loss: 0.0015 - val_loss: 0.0647\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 4s 605ms/step - loss: 0.0015 - val_loss: 0.0392\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 4s 601ms/step - loss: 0.0015 - val_loss: 0.0503\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 4s 602ms/step - loss: 0.0015 - val_loss: 0.0636\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 4s 610ms/step - loss: 0.0017 - val_loss: 0.0158\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 4s 618ms/step - loss: 0.0018 - val_loss: 0.0953\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 4s 632ms/step - loss: 0.0017 - val_loss: 0.0355\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 5s 657ms/step - loss: 0.0015 - val_loss: 0.0315\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 4s 618ms/step - loss: 0.0015 - val_loss: 0.0561\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 4s 613ms/step - loss: 0.0014 - val_loss: 0.0490\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 4s 608ms/step - loss: 0.0014 - val_loss: 0.0367\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 4s 603ms/step - loss: 0.0013 - val_loss: 0.0497\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 4s 584ms/step - loss: 0.0013 - val_loss: 0.0412\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 4s 601ms/step - loss: 0.0013 - val_loss: 0.0377\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 4s 583ms/step - loss: 0.0013 - val_loss: 0.0549\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 4s 609ms/step - loss: 0.0013 - val_loss: 0.0369\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 4s 598ms/step - loss: 0.0013 - val_loss: 0.0318\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 4s 616ms/step - loss: 0.0013 - val_loss: 0.0532\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 4s 589ms/step - loss: 0.0013 - val_loss: 0.0426\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 4s 610ms/step - loss: 0.0012 - val_loss: 0.0309\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 4s 627ms/step - loss: 0.0012 - val_loss: 0.0552\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 4s 598ms/step - loss: 0.0012 - val_loss: 0.0597\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 4s 596ms/step - loss: 0.0013 - val_loss: 0.0234\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 4s 604ms/step - loss: 0.0012 - val_loss: 0.0542\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 4s 600ms/step - loss: 0.0012 - val_loss: 0.0388\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 4s 589ms/step - loss: 0.0011 - val_loss: 0.0308\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 4s 607ms/step - loss: 0.0011 - val_loss: 0.0604\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 4s 591ms/step - loss: 0.0013 - val_loss: 0.0222\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 4s 599ms/step - loss: 0.0012 - val_loss: 0.0462\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 4s 606ms/step - loss: 0.0011 - val_loss: 0.0487\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 4s 603ms/step - loss: 0.0011 - val_loss: 0.0342\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 4s 622ms/step - loss: 0.0011 - val_loss: 0.0271\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 4s 602ms/step - loss: 0.0010 - val_loss: 0.0349\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 4s 591ms/step - loss: 0.0011 - val_loss: 0.0542\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 4s 597ms/step - loss: 0.0011 - val_loss: 0.0285\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 4s 591ms/step - loss: 9.6783e-04 - val_loss: 0.0318\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 4s 615ms/step - loss: 9.5289e-04 - val_loss: 0.0369\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 4s 598ms/step - loss: 9.7190e-04 - val_loss: 0.0346\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 4s 601ms/step - loss: 9.2772e-04 - val_loss: 0.0159\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 4s 584ms/step - loss: 9.9820e-04 - val_loss: 0.0307\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 4s 588ms/step - loss: 0.0010 - val_loss: 0.0389\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 4s 596ms/step - loss: 9.7107e-04 - val_loss: 0.0234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_144_layer_call_fn, lstm_cell_144_layer_call_and_return_conditional_losses, lstm_cell_145_layer_call_fn, lstm_cell_145_layer_call_and_return_conditional_losses, lstm_cell_146_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/YOUC\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/YOUC\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 3s 92ms/step\n",
      "3/3 [==============================] - 0s 70ms/step\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Epoch 1/100\n",
      "13/13 [==============================] - 19s 949ms/step - loss: 0.0165 - val_loss: 0.0072\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 9s 669ms/step - loss: 0.0037 - val_loss: 0.0056\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 9s 672ms/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 8s 623ms/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 8s 651ms/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 9s 679ms/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 8s 640ms/step - loss: 0.0012 - val_loss: 0.0054\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 9s 675ms/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 8s 652ms/step - loss: 0.0012 - val_loss: 0.0056\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 9s 674ms/step - loss: 0.0013 - val_loss: 0.0056\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 8s 649ms/step - loss: 0.0011 - val_loss: 0.0055\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 8s 637ms/step - loss: 0.0012 - val_loss: 0.0055\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 8s 644ms/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 9s 664ms/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 9s 689ms/step - loss: 0.0012 - val_loss: 0.0062\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 9s 711ms/step - loss: 0.0014 - val_loss: 0.0052\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 9s 702ms/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 9s 708ms/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 8s 632ms/step - loss: 0.0011 - val_loss: 0.0044\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 8s 633ms/step - loss: 0.0011 - val_loss: 0.0051\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 8s 640ms/step - loss: 0.0011 - val_loss: 0.0046\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 8s 629ms/step - loss: 0.0011 - val_loss: 0.0052\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 8s 652ms/step - loss: 0.0011 - val_loss: 0.0045\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 8s 623ms/step - loss: 0.0012 - val_loss: 0.0048\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 8s 634ms/step - loss: 0.0011 - val_loss: 0.0040\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 8s 637ms/step - loss: 0.0012 - val_loss: 0.0047\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 8s 620ms/step - loss: 0.0011 - val_loss: 0.0041\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 8s 638ms/step - loss: 0.0010 - val_loss: 0.0052\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 8s 645ms/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 8s 619ms/step - loss: 0.0011 - val_loss: 0.0044\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 8s 627ms/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 8s 623ms/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 9s 669ms/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 8s 642ms/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 8s 639ms/step - loss: 0.0012 - val_loss: 0.0049\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 8s 632ms/step - loss: 0.0011 - val_loss: 0.0045\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 8s 627ms/step - loss: 0.0011 - val_loss: 0.0048\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 8s 630ms/step - loss: 0.0011 - val_loss: 0.0050\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 8s 634ms/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 9s 679ms/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 8s 620ms/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 8s 623ms/step - loss: 0.0011 - val_loss: 0.0046\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 8s 642ms/step - loss: 0.0011 - val_loss: 0.0048\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 8s 634ms/step - loss: 9.8408e-04 - val_loss: 0.0057\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 8s 636ms/step - loss: 0.0010 - val_loss: 0.0048\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 8s 633ms/step - loss: 9.9524e-04 - val_loss: 0.0041\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 8s 618ms/step - loss: 9.8324e-04 - val_loss: 0.0046\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 8s 647ms/step - loss: 9.8310e-04 - val_loss: 0.0045\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 8s 628ms/step - loss: 9.9200e-04 - val_loss: 0.0059\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 8s 634ms/step - loss: 9.8630e-04 - val_loss: 0.0053\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 8s 637ms/step - loss: 9.8735e-04 - val_loss: 0.0053\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 8s 634ms/step - loss: 9.6507e-04 - val_loss: 0.0052\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 8s 622ms/step - loss: 9.0806e-04 - val_loss: 0.0049\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 8s 636ms/step - loss: 0.0010 - val_loss: 0.0056\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 8s 654ms/step - loss: 0.0010 - val_loss: 0.0049\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 8s 623ms/step - loss: 8.9304e-04 - val_loss: 0.0051\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 8s 635ms/step - loss: 9.0246e-04 - val_loss: 0.0088\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 8s 627ms/step - loss: 9.4309e-04 - val_loss: 0.0054\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 8s 630ms/step - loss: 9.1821e-04 - val_loss: 0.0056\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 8s 631ms/step - loss: 9.9244e-04 - val_loss: 0.0056\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 8s 631ms/step - loss: 9.3681e-04 - val_loss: 0.0053\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 8s 646ms/step - loss: 0.0012 - val_loss: 0.0054\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 8s 646ms/step - loss: 9.0385e-04 - val_loss: 0.0055\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 8s 634ms/step - loss: 8.6518e-04 - val_loss: 0.0056\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 9s 667ms/step - loss: 0.0013 - val_loss: 0.0052\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 9s 656ms/step - loss: 0.0012 - val_loss: 0.0052\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 8s 630ms/step - loss: 0.0011 - val_loss: 0.0053\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 8s 621ms/step - loss: 8.9615e-04 - val_loss: 0.0050\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 9s 671ms/step - loss: 8.8504e-04 - val_loss: 0.0058\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 8s 639ms/step - loss: 8.2300e-04 - val_loss: 0.0063\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 8s 616ms/step - loss: 8.1072e-04 - val_loss: 0.0063\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 8s 635ms/step - loss: 8.5802e-04 - val_loss: 0.0057\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 8s 634ms/step - loss: 9.5156e-04 - val_loss: 0.0061\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 8s 631ms/step - loss: 8.4964e-04 - val_loss: 0.0070\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 8s 630ms/step - loss: 8.4749e-04 - val_loss: 0.0062\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 8s 624ms/step - loss: 8.9974e-04 - val_loss: 0.0067\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 8s 638ms/step - loss: 9.6004e-04 - val_loss: 0.0081\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 8s 622ms/step - loss: 8.6951e-04 - val_loss: 0.0080\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 8s 629ms/step - loss: 9.1035e-04 - val_loss: 0.0071\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 8s 637ms/step - loss: 8.6054e-04 - val_loss: 0.0074\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 8s 627ms/step - loss: 9.7214e-04 - val_loss: 0.0069\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 8s 616ms/step - loss: 9.3164e-04 - val_loss: 0.0097\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 8s 629ms/step - loss: 7.4998e-04 - val_loss: 0.0095\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 8s 630ms/step - loss: 6.9653e-04 - val_loss: 0.0111\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 8s 626ms/step - loss: 6.7717e-04 - val_loss: 0.0097\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 8s 637ms/step - loss: 6.8823e-04 - val_loss: 0.0134\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 8s 620ms/step - loss: 6.8557e-04 - val_loss: 0.0107\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 8s 627ms/step - loss: 7.2965e-04 - val_loss: 0.0090\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 8s 629ms/step - loss: 5.9066e-04 - val_loss: 0.0098\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 8s 624ms/step - loss: 6.0454e-04 - val_loss: 0.0103\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 8s 638ms/step - loss: 6.0489e-04 - val_loss: 0.0106\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 8s 630ms/step - loss: 6.0888e-04 - val_loss: 0.0091\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 8s 625ms/step - loss: 6.5547e-04 - val_loss: 0.0105\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 8s 632ms/step - loss: 5.8974e-04 - val_loss: 0.0090\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 8s 627ms/step - loss: 6.2929e-04 - val_loss: 0.0091\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 8s 627ms/step - loss: 6.2016e-04 - val_loss: 0.0090\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 8s 626ms/step - loss: 6.3618e-04 - val_loss: 0.0095\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 8s 630ms/step - loss: 6.1107e-04 - val_loss: 0.0091\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 8s 638ms/step - loss: 6.2524e-04 - val_loss: 0.0063\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 8s 624ms/step - loss: 5.7895e-04 - val_loss: 0.0084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_147_layer_call_fn, lstm_cell_147_layer_call_and_return_conditional_losses, lstm_cell_148_layer_call_fn, lstm_cell_148_layer_call_and_return_conditional_losses, lstm_cell_149_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/MATIC\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/MATIC\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 4s 95ms/step\n",
      "7/7 [==============================] - 1s 96ms/step\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Epoch 1/100\n",
      "6/6 [==============================] - 15s 940ms/step - loss: 0.1114 - val_loss: 0.0391\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 4s 593ms/step - loss: 0.0294 - val_loss: 0.0045\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 4s 611ms/step - loss: 0.0250 - val_loss: 0.0142\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 4s 636ms/step - loss: 0.0169 - val_loss: 0.0244\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 4s 648ms/step - loss: 0.0128 - val_loss: 0.0101\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 4s 607ms/step - loss: 0.0137 - val_loss: 0.0142\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 4s 586ms/step - loss: 0.0113 - val_loss: 0.0167\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 4s 582ms/step - loss: 0.0110 - val_loss: 0.0108\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 4s 613ms/step - loss: 0.0106 - val_loss: 0.0112\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 4s 621ms/step - loss: 0.0101 - val_loss: 0.0096\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 4s 587ms/step - loss: 0.0098 - val_loss: 0.0085\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 4s 584ms/step - loss: 0.0095 - val_loss: 0.0079\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 4s 607ms/step - loss: 0.0093 - val_loss: 0.0066\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 4s 599ms/step - loss: 0.0092 - val_loss: 0.0057\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 4s 575ms/step - loss: 0.0089 - val_loss: 0.0054\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 4s 590ms/step - loss: 0.0085 - val_loss: 0.0043\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 4s 635ms/step - loss: 0.0087 - val_loss: 0.0049\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 4s 616ms/step - loss: 0.0081 - val_loss: 0.0040\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 4s 590ms/step - loss: 0.0083 - val_loss: 0.0038\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 4s 618ms/step - loss: 0.0085 - val_loss: 0.0042\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 4s 607ms/step - loss: 0.0074 - val_loss: 0.0039\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 4s 593ms/step - loss: 0.0073 - val_loss: 0.0047\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 4s 594ms/step - loss: 0.0080 - val_loss: 0.0031\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 4s 604ms/step - loss: 0.0075 - val_loss: 0.0043\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 4s 616ms/step - loss: 0.0077 - val_loss: 0.0051\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 4s 608ms/step - loss: 0.0074 - val_loss: 0.0032\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 4s 577ms/step - loss: 0.0074 - val_loss: 0.0049\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 4s 619ms/step - loss: 0.0069 - val_loss: 0.0044\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 4s 624ms/step - loss: 0.0065 - val_loss: 0.0034\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 4s 611ms/step - loss: 0.0066 - val_loss: 0.0039\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 4s 585ms/step - loss: 0.0062 - val_loss: 0.0031\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 4s 626ms/step - loss: 0.0064 - val_loss: 0.0034\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 4s 599ms/step - loss: 0.0066 - val_loss: 0.0041\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 4s 596ms/step - loss: 0.0059 - val_loss: 0.0034\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 4s 587ms/step - loss: 0.0059 - val_loss: 0.0041\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 4s 603ms/step - loss: 0.0059 - val_loss: 0.0029\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 4s 618ms/step - loss: 0.0065 - val_loss: 0.0052\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 4s 587ms/step - loss: 0.0062 - val_loss: 0.0039\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 4s 609ms/step - loss: 0.0056 - val_loss: 0.0032\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 4s 605ms/step - loss: 0.0059 - val_loss: 0.0051\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 4s 605ms/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 4s 593ms/step - loss: 0.0055 - val_loss: 0.0033\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 4s 613ms/step - loss: 0.0051 - val_loss: 0.0054\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 4s 616ms/step - loss: 0.0060 - val_loss: 0.0037\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 4s 590ms/step - loss: 0.0055 - val_loss: 0.0030\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 4s 598ms/step - loss: 0.0053 - val_loss: 0.0037\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 4s 630ms/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 4s 599ms/step - loss: 0.0056 - val_loss: 0.0031\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 4s 589ms/step - loss: 0.0048 - val_loss: 0.0034\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 4s 592ms/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 4s 610ms/step - loss: 0.0045 - val_loss: 0.0031\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 4s 593ms/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 4s 589ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 4s 603ms/step - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 4s 590ms/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 4s 629ms/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 4s 594ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 4s 609ms/step - loss: 0.0037 - val_loss: 0.0027\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 4s 617ms/step - loss: 0.0035 - val_loss: 0.0028\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 4s 582ms/step - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 4s 602ms/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 4s 620ms/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 4s 593ms/step - loss: 0.0037 - val_loss: 0.0025\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 4s 589ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 4s 585ms/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 4s 612ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 4s 600ms/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 4s 659ms/step - loss: 0.0037 - val_loss: 0.0025\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 4s 616ms/step - loss: 0.0034 - val_loss: 0.0027\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 4s 600ms/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 4s 630ms/step - loss: 0.0032 - val_loss: 0.0024\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 4s 580ms/step - loss: 0.0033 - val_loss: 0.0026\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 4s 586ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 4s 630ms/step - loss: 0.0031 - val_loss: 0.0017\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 4s 613ms/step - loss: 0.0040 - val_loss: 0.0033\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 4s 620ms/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 4s 583ms/step - loss: 0.0033 - val_loss: 0.0025\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 4s 626ms/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 4s 598ms/step - loss: 0.0034 - val_loss: 0.0016\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 4s 587ms/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 4s 594ms/step - loss: 0.0031 - val_loss: 0.0018\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 4s 611ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 83/100\n",
      "6/6 [==============================] - 4s 609ms/step - loss: 0.0030 - val_loss: 0.0022\n",
      "Epoch 84/100\n",
      "6/6 [==============================] - 4s 585ms/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 4s 639ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - 4s 615ms/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 87/100\n",
      "6/6 [==============================] - 4s 597ms/step - loss: 0.0029 - val_loss: 0.0020\n",
      "Epoch 88/100\n",
      "6/6 [==============================] - 4s 594ms/step - loss: 0.0034 - val_loss: 0.0026\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - 4s 603ms/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - 4s 633ms/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 91/100\n",
      "6/6 [==============================] - 4s 600ms/step - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - 4s 585ms/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 93/100\n",
      "6/6 [==============================] - 4s 605ms/step - loss: 0.0028 - val_loss: 0.0017\n",
      "Epoch 94/100\n",
      "6/6 [==============================] - 4s 614ms/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - 4s 587ms/step - loss: 0.0029 - val_loss: 0.0020\n",
      "Epoch 96/100\n",
      "6/6 [==============================] - 4s 584ms/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 97/100\n",
      "6/6 [==============================] - 4s 602ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - 4s 585ms/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 99/100\n",
      "6/6 [==============================] - 4s 620ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 100/100\n",
      "6/6 [==============================] - 4s 615ms/step - loss: 0.0026 - val_loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_150_layer_call_fn, lstm_cell_150_layer_call_and_return_conditional_losses, lstm_cell_151_layer_call_fn, lstm_cell_151_layer_call_and_return_conditional_losses, lstm_cell_152_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/STETH\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/STETH\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 3s 97ms/step\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 12s 801ms/step - loss: 0.1401 - val_loss: 0.0218\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 4s 590ms/step - loss: 0.0281 - val_loss: 0.0068\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 4s 577ms/step - loss: 0.0192 - val_loss: 0.0135\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 4s 542ms/step - loss: 0.0138 - val_loss: 0.0198\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 4s 531ms/step - loss: 0.0111 - val_loss: 0.0094\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 4s 541ms/step - loss: 0.0111 - val_loss: 0.0121\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 4s 601ms/step - loss: 0.0096 - val_loss: 0.0084\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 4s 509ms/step - loss: 0.0089 - val_loss: 0.0063\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 3s 491ms/step - loss: 0.0085 - val_loss: 0.0051\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 4s 500ms/step - loss: 0.0082 - val_loss: 0.0034\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 4s 502ms/step - loss: 0.0078 - val_loss: 0.0028\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 4s 511ms/step - loss: 0.0077 - val_loss: 0.0024\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 4s 503ms/step - loss: 0.0074 - val_loss: 0.0022\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 4s 498ms/step - loss: 0.0070 - val_loss: 0.0021\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 4s 514ms/step - loss: 0.0067 - val_loss: 0.0029\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 4s 504ms/step - loss: 0.0068 - val_loss: 0.0029\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 4s 500ms/step - loss: 0.0065 - val_loss: 0.0030\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 4s 505ms/step - loss: 0.0062 - val_loss: 0.0032\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 4s 502ms/step - loss: 0.0064 - val_loss: 0.0029\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 4s 504ms/step - loss: 0.0063 - val_loss: 0.0018\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 4s 518ms/step - loss: 0.0062 - val_loss: 0.0019\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 4s 499ms/step - loss: 0.0062 - val_loss: 0.0029\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 3s 482ms/step - loss: 0.0066 - val_loss: 0.0029\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 4s 507ms/step - loss: 0.0062 - val_loss: 0.0015\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 4s 503ms/step - loss: 0.0060 - val_loss: 0.0015\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 4s 507ms/step - loss: 0.0057 - val_loss: 0.0019\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 4s 536ms/step - loss: 0.0056 - val_loss: 0.0017\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 4s 540ms/step - loss: 0.0054 - val_loss: 0.0013\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 4s 533ms/step - loss: 0.0054 - val_loss: 0.0017\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 4s 522ms/step - loss: 0.0053 - val_loss: 0.0012\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 4s 506ms/step - loss: 0.0055 - val_loss: 0.0020\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 4s 539ms/step - loss: 0.0056 - val_loss: 0.0014\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 4s 533ms/step - loss: 0.0051 - val_loss: 0.0012\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 4s 517ms/step - loss: 0.0056 - val_loss: 0.0014\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 4s 499ms/step - loss: 0.0057 - val_loss: 0.0021\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 4s 529ms/step - loss: 0.0055 - val_loss: 0.0011\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 4s 516ms/step - loss: 0.0050 - val_loss: 0.0011\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 4s 492ms/step - loss: 0.0049 - val_loss: 9.8799e-04\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 4s 503ms/step - loss: 0.0048 - val_loss: 0.0010\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 4s 502ms/step - loss: 0.0047 - val_loss: 9.7913e-04\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 4s 517ms/step - loss: 0.0048 - val_loss: 0.0011\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 4s 527ms/step - loss: 0.0046 - val_loss: 0.0012\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 4s 517ms/step - loss: 0.0046 - val_loss: 0.0010\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 4s 528ms/step - loss: 0.0046 - val_loss: 9.7446e-04\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 4s 527ms/step - loss: 0.0045 - val_loss: 6.8677e-04\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 4s 522ms/step - loss: 0.0052 - val_loss: 9.6643e-04\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 4s 522ms/step - loss: 0.0050 - val_loss: 0.0014\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 4s 535ms/step - loss: 0.0046 - val_loss: 0.0011\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 4s 538ms/step - loss: 0.0045 - val_loss: 0.0011\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 4s 533ms/step - loss: 0.0044 - val_loss: 7.9183e-04\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 4s 537ms/step - loss: 0.0047 - val_loss: 5.1449e-04\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 4s 500ms/step - loss: 0.0051 - val_loss: 0.0012\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 4s 503ms/step - loss: 0.0046 - val_loss: 0.0018\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 4s 496ms/step - loss: 0.0054 - val_loss: 0.0013\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 4s 500ms/step - loss: 0.0045 - val_loss: 6.7410e-04\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 4s 501ms/step - loss: 0.0042 - val_loss: 0.0010\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 3s 498ms/step - loss: 0.0041 - val_loss: 8.9570e-04\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 4s 499ms/step - loss: 0.0041 - val_loss: 0.0011\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 4s 500ms/step - loss: 0.0040 - val_loss: 0.0011\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 4s 506ms/step - loss: 0.0039 - val_loss: 0.0010\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 4s 519ms/step - loss: 0.0038 - val_loss: 8.3377e-04\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 4s 501ms/step - loss: 0.0037 - val_loss: 7.3690e-04\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 3s 492ms/step - loss: 0.0042 - val_loss: 7.3064e-04\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 3s 493ms/step - loss: 0.0044 - val_loss: 9.6333e-04\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 4s 592ms/step - loss: 0.0040 - val_loss: 0.0011\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 4s 530ms/step - loss: 0.0036 - val_loss: 8.4998e-04\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 3s 488ms/step - loss: 0.0035 - val_loss: 0.0013\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 4s 492ms/step - loss: 0.0036 - val_loss: 9.3618e-04\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 4s 503ms/step - loss: 0.0037 - val_loss: 0.0010\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 4s 503ms/step - loss: 0.0040 - val_loss: 5.8921e-04\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 4s 499ms/step - loss: 0.0037 - val_loss: 5.5677e-04\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 4s 501ms/step - loss: 0.0039 - val_loss: 5.4901e-04\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 4s 501ms/step - loss: 0.0037 - val_loss: 8.9617e-04\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 4s 501ms/step - loss: 0.0035 - val_loss: 0.0014\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 4s 492ms/step - loss: 0.0040 - val_loss: 8.2830e-04\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 3s 496ms/step - loss: 0.0036 - val_loss: 3.6507e-04\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 4s 505ms/step - loss: 0.0036 - val_loss: 7.2816e-04\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 4s 507ms/step - loss: 0.0031 - val_loss: 5.8808e-04\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 4s 514ms/step - loss: 0.0031 - val_loss: 0.0011\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 4s 501ms/step - loss: 0.0031 - val_loss: 8.3797e-04\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 3s 497ms/step - loss: 0.0029 - val_loss: 5.8654e-04\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 4s 507ms/step - loss: 0.0029 - val_loss: 7.5330e-04\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 3s 498ms/step - loss: 0.0028 - val_loss: 7.0799e-04\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 3s 483ms/step - loss: 0.0029 - val_loss: 8.4263e-04\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 4s 497ms/step - loss: 0.0029 - val_loss: 6.9486e-04\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 4s 501ms/step - loss: 0.0027 - val_loss: 6.4445e-04\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 3s 497ms/step - loss: 0.0026 - val_loss: 8.4426e-04\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 3s 499ms/step - loss: 0.0028 - val_loss: 8.4010e-04\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 4s 503ms/step - loss: 0.0027 - val_loss: 8.8087e-04\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 4s 498ms/step - loss: 0.0027 - val_loss: 7.3457e-04\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 3s 490ms/step - loss: 0.0026 - val_loss: 7.2669e-04\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 4s 494ms/step - loss: 0.0024 - val_loss: 5.6257e-04\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 4s 499ms/step - loss: 0.0024 - val_loss: 6.4597e-04\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 3s 492ms/step - loss: 0.0024 - val_loss: 6.3780e-04\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 4s 487ms/step - loss: 0.0023 - val_loss: 7.9223e-04\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 4s 497ms/step - loss: 0.0023 - val_loss: 4.7230e-04\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 4s 503ms/step - loss: 0.0027 - val_loss: 4.0171e-04\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 3s 485ms/step - loss: 0.0025 - val_loss: 5.4805e-04\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 4s 503ms/step - loss: 0.0022 - val_loss: 5.8578e-04\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 4s 506ms/step - loss: 0.0023 - val_loss: 9.2357e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_153_layer_call_fn, lstm_cell_153_layer_call_and_return_conditional_losses, lstm_cell_154_layer_call_fn, lstm_cell_154_layer_call_and_return_conditional_losses, lstm_cell_155_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/UNI1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/UNI1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 3s 94ms/step\n",
      "3/3 [==============================] - 0s 79ms/step\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 28s 660ms/step - loss: 0.0065 - val_loss: 0.0094\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 20s 607ms/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 20s 617ms/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 21s 626ms/step - loss: 0.0012 - val_loss: 0.0036\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 20s 609ms/step - loss: 0.0011 - val_loss: 0.0033\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 20s 601ms/step - loss: 0.0010 - val_loss: 0.0040\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 20s 622ms/step - loss: 0.0012 - val_loss: 0.0026\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 20s 605ms/step - loss: 7.8448e-04 - val_loss: 0.0034\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 20s 605ms/step - loss: 7.5304e-04 - val_loss: 0.0023\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 20s 600ms/step - loss: 6.4692e-04 - val_loss: 0.0020\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 20s 604ms/step - loss: 6.1684e-04 - val_loss: 0.0021\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 20s 606ms/step - loss: 5.8717e-04 - val_loss: 0.0039\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 20s 605ms/step - loss: 5.9943e-04 - val_loss: 0.0018\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 20s 608ms/step - loss: 5.3459e-04 - val_loss: 0.0019\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 20s 607ms/step - loss: 4.7321e-04 - val_loss: 0.0017\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 20s 602ms/step - loss: 4.9300e-04 - val_loss: 0.0016\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 20s 607ms/step - loss: 5.1143e-04 - val_loss: 0.0021\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 20s 604ms/step - loss: 5.3395e-04 - val_loss: 0.0024\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 20s 609ms/step - loss: 5.2256e-04 - val_loss: 0.0014\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 20s 608ms/step - loss: 4.4832e-04 - val_loss: 0.0016\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 20s 611ms/step - loss: 5.0699e-04 - val_loss: 0.0014\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 21s 624ms/step - loss: 4.3194e-04 - val_loss: 0.0014\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 20s 607ms/step - loss: 4.1017e-04 - val_loss: 0.0013\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 20s 605ms/step - loss: 4.7667e-04 - val_loss: 0.0013\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 20s 605ms/step - loss: 4.3528e-04 - val_loss: 0.0018\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 20s 604ms/step - loss: 6.1882e-04 - val_loss: 0.0016\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 20s 602ms/step - loss: 3.7358e-04 - val_loss: 0.0012\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 20s 607ms/step - loss: 3.7064e-04 - val_loss: 0.0011\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 22s 661ms/step - loss: 3.6640e-04 - val_loss: 0.0014\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 21s 635ms/step - loss: 3.8278e-04 - val_loss: 0.0013\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 21s 648ms/step - loss: 3.9735e-04 - val_loss: 0.0011\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 20s 621ms/step - loss: 3.4260e-04 - val_loss: 0.0011\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 20s 618ms/step - loss: 3.3501e-04 - val_loss: 0.0011\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 20s 607ms/step - loss: 3.2217e-04 - val_loss: 0.0018\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 21s 635ms/step - loss: 3.3679e-04 - val_loss: 0.0017\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 20s 610ms/step - loss: 3.5573e-04 - val_loss: 0.0013\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 20s 612ms/step - loss: 3.5669e-04 - val_loss: 9.8973e-04\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 20s 605ms/step - loss: 3.0212e-04 - val_loss: 0.0015\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 20s 604ms/step - loss: 3.0420e-04 - val_loss: 9.6096e-04\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 20s 613ms/step - loss: 2.7672e-04 - val_loss: 0.0011\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 20s 609ms/step - loss: 2.7639e-04 - val_loss: 9.3676e-04\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 20s 605ms/step - loss: 2.8044e-04 - val_loss: 9.2091e-04\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 20s 610ms/step - loss: 2.5558e-04 - val_loss: 9.5337e-04\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 20s 606ms/step - loss: 2.5289e-04 - val_loss: 0.0013\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 20s 598ms/step - loss: 2.7062e-04 - val_loss: 0.0010\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 20s 607ms/step - loss: 2.6692e-04 - val_loss: 9.2437e-04\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 20s 603ms/step - loss: 2.4505e-04 - val_loss: 0.0012\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 20s 601ms/step - loss: 3.1024e-04 - val_loss: 8.7501e-04\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 20s 614ms/step - loss: 2.5911e-04 - val_loss: 9.1925e-04\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 20s 601ms/step - loss: 2.4688e-04 - val_loss: 8.4471e-04\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 20s 600ms/step - loss: 2.3263e-04 - val_loss: 8.4752e-04\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 20s 616ms/step - loss: 2.3053e-04 - val_loss: 8.9270e-04\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 20s 612ms/step - loss: 2.3720e-04 - val_loss: 0.0013\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 20s 603ms/step - loss: 2.8549e-04 - val_loss: 0.0011\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 20s 600ms/step - loss: 2.3374e-04 - val_loss: 0.0011\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 20s 598ms/step - loss: 2.3470e-04 - val_loss: 0.0012\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 20s 598ms/step - loss: 2.5647e-04 - val_loss: 8.7678e-04\n",
      "Epoch 58/100\n",
      "33/33 [==============================] - 20s 605ms/step - loss: 2.2334e-04 - val_loss: 8.3687e-04\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 20s 613ms/step - loss: 2.5319e-04 - val_loss: 0.0014\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 20s 598ms/step - loss: 2.5229e-04 - val_loss: 8.4447e-04\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 20s 614ms/step - loss: 2.7111e-04 - val_loss: 9.5689e-04\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 20s 603ms/step - loss: 2.7627e-04 - val_loss: 9.4711e-04\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 20s 599ms/step - loss: 2.3140e-04 - val_loss: 8.6068e-04\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 21s 651ms/step - loss: 2.1141e-04 - val_loss: 9.7828e-04\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 20s 618ms/step - loss: 2.1857e-04 - val_loss: 9.1529e-04\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 20s 602ms/step - loss: 2.2302e-04 - val_loss: 9.6287e-04\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 21s 624ms/step - loss: 2.1667e-04 - val_loss: 0.0013\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 20s 604ms/step - loss: 2.4356e-04 - val_loss: 0.0012\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 21s 633ms/step - loss: 2.1489e-04 - val_loss: 8.7967e-04\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 20s 608ms/step - loss: 2.3916e-04 - val_loss: 0.0011\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 20s 600ms/step - loss: 2.2802e-04 - val_loss: 8.7852e-04\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 20s 605ms/step - loss: 2.2761e-04 - val_loss: 9.6032e-04\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 20s 605ms/step - loss: 2.2032e-04 - val_loss: 0.0014\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 20s 621ms/step - loss: 2.3922e-04 - val_loss: 8.9074e-04\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 21s 628ms/step - loss: 2.1367e-04 - val_loss: 8.7733e-04\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 20s 608ms/step - loss: 2.0627e-04 - val_loss: 8.6243e-04\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 20s 605ms/step - loss: 2.2077e-04 - val_loss: 8.5937e-04\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 20s 603ms/step - loss: 2.2624e-04 - val_loss: 0.0013\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 20s 607ms/step - loss: 2.2711e-04 - val_loss: 0.0011\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 20s 604ms/step - loss: 2.2398e-04 - val_loss: 9.2682e-04\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 20s 600ms/step - loss: 2.2694e-04 - val_loss: 0.0010\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 20s 617ms/step - loss: 2.5642e-04 - val_loss: 8.8794e-04\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 20s 599ms/step - loss: 2.1858e-04 - val_loss: 8.7507e-04\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 20s 601ms/step - loss: 2.2232e-04 - val_loss: 0.0013\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 20s 614ms/step - loss: 2.2111e-04 - val_loss: 8.8116e-04\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 20s 602ms/step - loss: 2.1136e-04 - val_loss: 9.0253e-04\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 20s 612ms/step - loss: 2.1485e-04 - val_loss: 8.6542e-04\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 20s 602ms/step - loss: 2.3727e-04 - val_loss: 9.3865e-04\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 20s 605ms/step - loss: 2.1227e-04 - val_loss: 0.0010\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 20s 603ms/step - loss: 2.1590e-04 - val_loss: 9.5650e-04\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 20s 609ms/step - loss: 2.2911e-04 - val_loss: 0.0010\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 20s 601ms/step - loss: 2.1077e-04 - val_loss: 8.9369e-04\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 20s 610ms/step - loss: 2.2923e-04 - val_loss: 0.0010\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 20s 615ms/step - loss: 2.0777e-04 - val_loss: 0.0012\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 20s 600ms/step - loss: 2.4862e-04 - val_loss: 0.0011\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 20s 598ms/step - loss: 2.2639e-04 - val_loss: 9.7926e-04\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 20s 616ms/step - loss: 2.1326e-04 - val_loss: 0.0012\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 20s 599ms/step - loss: 2.0019e-04 - val_loss: 9.8218e-04\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 21s 641ms/step - loss: 2.1063e-04 - val_loss: 9.6759e-04\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 20s 612ms/step - loss: 2.0579e-04 - val_loss: 9.7125e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_156_layer_call_fn, lstm_cell_156_layer_call_and_return_conditional_losses, lstm_cell_157_layer_call_fn, lstm_cell_157_layer_call_and_return_conditional_losses, lstm_cell_158_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/LTC\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/LTC\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 7s 85ms/step\n",
      "20/20 [==============================] - 2s 86ms/step\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 15s 656ms/step - loss: 0.0343 - val_loss: 0.0083\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 6s 509ms/step - loss: 0.0083 - val_loss: 0.0083\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 6s 514ms/step - loss: 0.0051 - val_loss: 0.0081\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 6s 533ms/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 6s 525ms/step - loss: 0.0036 - val_loss: 0.0016\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 6s 517ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 6s 512ms/step - loss: 0.0032 - val_loss: 0.0046\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 6s 514ms/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 6s 510ms/step - loss: 0.0030 - val_loss: 0.0018\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 6s 509ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 6s 515ms/step - loss: 0.0028 - val_loss: 0.0067\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 6s 519ms/step - loss: 0.0026 - val_loss: 0.0015\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 6s 511ms/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 6s 525ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 6s 520ms/step - loss: 0.0024 - val_loss: 0.0015\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 6s 515ms/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 6s 511ms/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 6s 515ms/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 6s 525ms/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 6s 517ms/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 6s 520ms/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 6s 526ms/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 6s 525ms/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 6s 514ms/step - loss: 0.0018 - val_loss: 0.0051\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 6s 519ms/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 6s 513ms/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 6s 514ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 6s 514ms/step - loss: 0.0013 - val_loss: 0.0025\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 6s 511ms/step - loss: 0.0013 - val_loss: 8.3455e-04\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 6s 516ms/step - loss: 0.0013 - val_loss: 7.9476e-04\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 6s 514ms/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 7s 546ms/step - loss: 0.0014 - val_loss: 8.2057e-04\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 6s 533ms/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 6s 521ms/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 6s 510ms/step - loss: 0.0012 - val_loss: 0.0026\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 6s 515ms/step - loss: 0.0011 - val_loss: 7.8607e-04\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 6s 511ms/step - loss: 9.8523e-04 - val_loss: 0.0013\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 6s 514ms/step - loss: 0.0011 - val_loss: 7.4634e-04\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 6s 517ms/step - loss: 0.0011 - val_loss: 7.7590e-04\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 6s 536ms/step - loss: 9.4597e-04 - val_loss: 9.2422e-04\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 6s 520ms/step - loss: 9.8341e-04 - val_loss: 9.6345e-04\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 6s 510ms/step - loss: 9.4828e-04 - val_loss: 9.5593e-04\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 6s 528ms/step - loss: 9.2298e-04 - val_loss: 8.2680e-04\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 6s 515ms/step - loss: 9.5438e-04 - val_loss: 7.9213e-04\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 6s 507ms/step - loss: 9.0224e-04 - val_loss: 8.5061e-04\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 6s 512ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 6s 508ms/step - loss: 9.3237e-04 - val_loss: 0.0013\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 6s 515ms/step - loss: 0.0011 - val_loss: 9.5029e-04\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 6s 513ms/step - loss: 0.0012 - val_loss: 9.1691e-04\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 6s 509ms/step - loss: 8.8516e-04 - val_loss: 0.0012\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 6s 526ms/step - loss: 8.8443e-04 - val_loss: 8.0970e-04\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 6s 516ms/step - loss: 8.4443e-04 - val_loss: 9.6719e-04\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 6s 514ms/step - loss: 8.4708e-04 - val_loss: 7.2014e-04\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 6s 513ms/step - loss: 8.3948e-04 - val_loss: 8.1315e-04\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 6s 520ms/step - loss: 8.4358e-04 - val_loss: 0.0017\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 6s 523ms/step - loss: 9.3980e-04 - val_loss: 9.0636e-04\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 6s 520ms/step - loss: 7.8394e-04 - val_loss: 0.0020\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 6s 518ms/step - loss: 9.3572e-04 - val_loss: 7.2437e-04\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 6s 518ms/step - loss: 9.4481e-04 - val_loss: 7.2506e-04\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 6s 514ms/step - loss: 8.3901e-04 - val_loss: 8.7330e-04\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 6s 513ms/step - loss: 8.3926e-04 - val_loss: 0.0011\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 6s 522ms/step - loss: 8.5050e-04 - val_loss: 7.1400e-04\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 6s 524ms/step - loss: 0.0010 - val_loss: 9.9535e-04\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 6s 523ms/step - loss: 9.1448e-04 - val_loss: 0.0015\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 6s 515ms/step - loss: 8.5038e-04 - val_loss: 7.0981e-04\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 6s 513ms/step - loss: 7.7021e-04 - val_loss: 0.0011\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 6s 513ms/step - loss: 7.5359e-04 - val_loss: 7.1463e-04\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 6s 511ms/step - loss: 7.8407e-04 - val_loss: 7.2288e-04\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 6s 516ms/step - loss: 8.8778e-04 - val_loss: 0.0011\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 6s 539ms/step - loss: 9.5864e-04 - val_loss: 0.0015\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 6s 525ms/step - loss: 9.0624e-04 - val_loss: 6.5678e-04\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 6s 516ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 6s 520ms/step - loss: 8.1599e-04 - val_loss: 0.0011\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 6s 512ms/step - loss: 7.6051e-04 - val_loss: 0.0011\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 6s 519ms/step - loss: 7.3489e-04 - val_loss: 6.3921e-04\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 6s 511ms/step - loss: 7.0882e-04 - val_loss: 0.0012\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 6s 516ms/step - loss: 7.1909e-04 - val_loss: 0.0014\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 6s 508ms/step - loss: 7.6353e-04 - val_loss: 0.0021\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 6s 508ms/step - loss: 8.5163e-04 - val_loss: 0.0010\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 6s 539ms/step - loss: 7.2004e-04 - val_loss: 7.9145e-04\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 6s 527ms/step - loss: 7.5047e-04 - val_loss: 0.0011\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 6s 516ms/step - loss: 7.4738e-04 - val_loss: 6.5765e-04\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 6s 514ms/step - loss: 7.8601e-04 - val_loss: 0.0024\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 6s 519ms/step - loss: 7.7217e-04 - val_loss: 8.0697e-04\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 6s 515ms/step - loss: 7.0341e-04 - val_loss: 7.4355e-04\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 6s 521ms/step - loss: 7.0163e-04 - val_loss: 6.2622e-04\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 6s 507ms/step - loss: 7.4203e-04 - val_loss: 7.5697e-04\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 6s 516ms/step - loss: 7.3144e-04 - val_loss: 0.0013\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 6s 513ms/step - loss: 8.9244e-04 - val_loss: 6.9013e-04\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 6s 519ms/step - loss: 8.6756e-04 - val_loss: 7.2602e-04\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 6s 518ms/step - loss: 7.4248e-04 - val_loss: 0.0015\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 6s 517ms/step - loss: 7.3291e-04 - val_loss: 6.3434e-04\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 6s 517ms/step - loss: 7.2456e-04 - val_loss: 0.0011\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 6s 512ms/step - loss: 7.5246e-04 - val_loss: 0.0025\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 6s 511ms/step - loss: 8.2105e-04 - val_loss: 7.2596e-04\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 6s 531ms/step - loss: 6.8482e-04 - val_loss: 8.4291e-04\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 6s 510ms/step - loss: 6.7758e-04 - val_loss: 7.4029e-04\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 6s 515ms/step - loss: 7.7473e-04 - val_loss: 6.1536e-04\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 6s 508ms/step - loss: 8.1178e-04 - val_loss: 0.0018\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 6s 534ms/step - loss: 7.3223e-04 - val_loss: 5.8008e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_159_layer_call_fn, lstm_cell_159_layer_call_and_return_conditional_losses, lstm_cell_160_layer_call_fn, lstm_cell_160_layer_call_and_return_conditional_losses, lstm_cell_161_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/FTT\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/FTT\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 4s 87ms/step\n",
      "6/6 [==============================] - 1s 83ms/step\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Epoch 1/100\n",
      "19/19 [==============================] - 19s 697ms/step - loss: 0.0098 - val_loss: 0.0135\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 12s 649ms/step - loss: 0.0027 - val_loss: 0.0076\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - 12s 628ms/step - loss: 0.0021 - val_loss: 0.0062\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 12s 619ms/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 12s 621ms/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 12s 625ms/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 12s 627ms/step - loss: 0.0020 - val_loss: 0.0106\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 12s 629ms/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 12s 624ms/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 12s 625ms/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 12s 617ms/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 12s 623ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 13s 667ms/step - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 12s 620ms/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 12s 634ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 12s 612ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 12s 614ms/step - loss: 9.4716e-04 - val_loss: 0.0019\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 12s 628ms/step - loss: 8.1167e-04 - val_loss: 0.0020\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 12s 612ms/step - loss: 7.6352e-04 - val_loss: 0.0017\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 12s 611ms/step - loss: 7.5377e-04 - val_loss: 0.0030\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 12s 626ms/step - loss: 8.4822e-04 - val_loss: 0.0014\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - 12s 624ms/step - loss: 8.4758e-04 - val_loss: 0.0020\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 12s 624ms/step - loss: 9.7732e-04 - val_loss: 0.0019\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 12s 627ms/step - loss: 7.8937e-04 - val_loss: 0.0017\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 12s 625ms/step - loss: 7.2766e-04 - val_loss: 0.0022\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 12s 617ms/step - loss: 7.4604e-04 - val_loss: 0.0012\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 12s 630ms/step - loss: 6.9258e-04 - val_loss: 0.0026\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 12s 617ms/step - loss: 6.7874e-04 - val_loss: 0.0012\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - 12s 620ms/step - loss: 7.1770e-04 - val_loss: 0.0015\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 12s 620ms/step - loss: 7.6959e-04 - val_loss: 0.0013\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 12s 625ms/step - loss: 7.2665e-04 - val_loss: 0.0012\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 12s 631ms/step - loss: 6.3333e-04 - val_loss: 0.0019\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 12s 651ms/step - loss: 6.9976e-04 - val_loss: 0.0016\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 12s 624ms/step - loss: 6.5607e-04 - val_loss: 0.0031\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 12s 617ms/step - loss: 8.0575e-04 - val_loss: 0.0013\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 12s 622ms/step - loss: 6.8243e-04 - val_loss: 0.0015\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 12s 625ms/step - loss: 6.6269e-04 - val_loss: 0.0019\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 12s 641ms/step - loss: 6.4541e-04 - val_loss: 0.0013\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 12s 644ms/step - loss: 5.5335e-04 - val_loss: 0.0012\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 12s 624ms/step - loss: 5.5933e-04 - val_loss: 0.0010\n",
      "Epoch 41/100\n",
      "19/19 [==============================] - 12s 623ms/step - loss: 6.5430e-04 - val_loss: 0.0011\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 12s 631ms/step - loss: 5.7783e-04 - val_loss: 0.0017\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 12s 633ms/step - loss: 6.0860e-04 - val_loss: 0.0011\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 12s 615ms/step - loss: 6.0000e-04 - val_loss: 0.0011\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 12s 620ms/step - loss: 5.1563e-04 - val_loss: 0.0014\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 12s 617ms/step - loss: 5.1375e-04 - val_loss: 0.0012\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 12s 619ms/step - loss: 5.0594e-04 - val_loss: 0.0018\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - 12s 625ms/step - loss: 5.5600e-04 - val_loss: 0.0012\n",
      "Epoch 49/100\n",
      "19/19 [==============================] - 12s 633ms/step - loss: 5.2060e-04 - val_loss: 0.0010\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 12s 622ms/step - loss: 6.2818e-04 - val_loss: 0.0011\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - 12s 621ms/step - loss: 5.3452e-04 - val_loss: 0.0021\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 12s 622ms/step - loss: 4.7957e-04 - val_loss: 9.4897e-04\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 12s 621ms/step - loss: 4.9278e-04 - val_loss: 0.0015\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 12s 618ms/step - loss: 4.4903e-04 - val_loss: 0.0010\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 12s 627ms/step - loss: 4.6320e-04 - val_loss: 0.0011\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 12s 616ms/step - loss: 4.9281e-04 - val_loss: 0.0018\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 12s 619ms/step - loss: 5.6198e-04 - val_loss: 8.7876e-04\n",
      "Epoch 58/100\n",
      "19/19 [==============================] - 12s 629ms/step - loss: 5.0596e-04 - val_loss: 0.0012\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 12s 635ms/step - loss: 4.3302e-04 - val_loss: 0.0012\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 12s 631ms/step - loss: 4.5774e-04 - val_loss: 0.0011\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 12s 619ms/step - loss: 6.3865e-04 - val_loss: 0.0022\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 12s 623ms/step - loss: 5.8936e-04 - val_loss: 8.7050e-04\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 12s 622ms/step - loss: 4.5185e-04 - val_loss: 0.0012\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - 12s 637ms/step - loss: 4.3179e-04 - val_loss: 0.0013\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - 12s 617ms/step - loss: 4.3752e-04 - val_loss: 0.0011\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - 12s 617ms/step - loss: 4.3035e-04 - val_loss: 8.6574e-04\n",
      "Epoch 67/100\n",
      "19/19 [==============================] - 12s 624ms/step - loss: 4.3343e-04 - val_loss: 0.0017\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - 12s 618ms/step - loss: 4.0562e-04 - val_loss: 9.0318e-04\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - 12s 628ms/step - loss: 4.0682e-04 - val_loss: 0.0012\n",
      "Epoch 70/100\n",
      "19/19 [==============================] - 12s 648ms/step - loss: 4.2283e-04 - val_loss: 8.2493e-04\n",
      "Epoch 71/100\n",
      "19/19 [==============================] - 12s 616ms/step - loss: 4.7342e-04 - val_loss: 7.9860e-04\n",
      "Epoch 72/100\n",
      "19/19 [==============================] - 12s 616ms/step - loss: 4.4636e-04 - val_loss: 0.0010\n",
      "Epoch 73/100\n",
      "19/19 [==============================] - 12s 630ms/step - loss: 4.0264e-04 - val_loss: 0.0010\n",
      "Epoch 74/100\n",
      "19/19 [==============================] - 12s 627ms/step - loss: 4.1352e-04 - val_loss: 0.0013\n",
      "Epoch 75/100\n",
      "19/19 [==============================] - 12s 615ms/step - loss: 4.5151e-04 - val_loss: 7.9903e-04\n",
      "Epoch 76/100\n",
      "19/19 [==============================] - 12s 624ms/step - loss: 4.2528e-04 - val_loss: 0.0016\n",
      "Epoch 77/100\n",
      "19/19 [==============================] - 12s 621ms/step - loss: 4.4086e-04 - val_loss: 0.0011\n",
      "Epoch 78/100\n",
      "19/19 [==============================] - 12s 625ms/step - loss: 3.8914e-04 - val_loss: 7.7404e-04\n",
      "Epoch 79/100\n",
      "19/19 [==============================] - 12s 630ms/step - loss: 4.2247e-04 - val_loss: 0.0012\n",
      "Epoch 80/100\n",
      "19/19 [==============================] - 12s 624ms/step - loss: 4.0404e-04 - val_loss: 8.5075e-04\n",
      "Epoch 81/100\n",
      "19/19 [==============================] - 12s 613ms/step - loss: 3.8241e-04 - val_loss: 0.0020\n",
      "Epoch 82/100\n",
      "19/19 [==============================] - 12s 618ms/step - loss: 4.8870e-04 - val_loss: 0.0010\n",
      "Epoch 83/100\n",
      "19/19 [==============================] - 12s 616ms/step - loss: 3.9286e-04 - val_loss: 8.5503e-04\n",
      "Epoch 84/100\n",
      "19/19 [==============================] - 12s 637ms/step - loss: 4.3153e-04 - val_loss: 0.0015\n",
      "Epoch 85/100\n",
      "19/19 [==============================] - 12s 633ms/step - loss: 3.9036e-04 - val_loss: 0.0012\n",
      "Epoch 86/100\n",
      "19/19 [==============================] - 12s 627ms/step - loss: 4.1383e-04 - val_loss: 7.5759e-04\n",
      "Epoch 87/100\n",
      "19/19 [==============================] - 12s 625ms/step - loss: 4.6847e-04 - val_loss: 0.0015\n",
      "Epoch 88/100\n",
      "19/19 [==============================] - 12s 614ms/step - loss: 3.7685e-04 - val_loss: 7.5885e-04\n",
      "Epoch 89/100\n",
      "19/19 [==============================] - 12s 649ms/step - loss: 3.6819e-04 - val_loss: 7.3252e-04\n",
      "Epoch 90/100\n",
      "19/19 [==============================] - 12s 618ms/step - loss: 3.8190e-04 - val_loss: 9.6704e-04\n",
      "Epoch 91/100\n",
      "19/19 [==============================] - 12s 622ms/step - loss: 4.0550e-04 - val_loss: 0.0011\n",
      "Epoch 92/100\n",
      "19/19 [==============================] - 12s 625ms/step - loss: 4.4639e-04 - val_loss: 9.7136e-04\n",
      "Epoch 93/100\n",
      "19/19 [==============================] - 12s 647ms/step - loss: 4.1739e-04 - val_loss: 7.3997e-04\n",
      "Epoch 94/100\n",
      "19/19 [==============================] - 12s 626ms/step - loss: 4.6704e-04 - val_loss: 9.1488e-04\n",
      "Epoch 95/100\n",
      "19/19 [==============================] - 12s 626ms/step - loss: 3.6482e-04 - val_loss: 6.9761e-04\n",
      "Epoch 96/100\n",
      "19/19 [==============================] - 12s 628ms/step - loss: 3.7241e-04 - val_loss: 7.8702e-04\n",
      "Epoch 97/100\n",
      "19/19 [==============================] - 12s 616ms/step - loss: 3.5401e-04 - val_loss: 8.5695e-04\n",
      "Epoch 98/100\n",
      "19/19 [==============================] - 12s 621ms/step - loss: 3.7956e-04 - val_loss: 8.0772e-04\n",
      "Epoch 99/100\n",
      "19/19 [==============================] - 12s 619ms/step - loss: 3.5518e-04 - val_loss: 0.0012\n",
      "Epoch 100/100\n",
      "19/19 [==============================] - 12s 628ms/step - loss: 4.1523e-04 - val_loss: 7.1911e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_162_layer_call_fn, lstm_cell_162_layer_call_and_return_conditional_losses, lstm_cell_163_layer_call_fn, lstm_cell_163_layer_call_and_return_conditional_losses, lstm_cell_164_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/LINK\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/LINK\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 5s 96ms/step\n",
      "11/11 [==============================] - 1s 97ms/step\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Epoch 1/100\n",
      "15/15 [==============================] - 17s 627ms/step - loss: 0.0026 - val_loss: 0.0183\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 8s 520ms/step - loss: 6.2290e-04 - val_loss: 0.0038\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 8s 520ms/step - loss: 4.0170e-04 - val_loss: 0.0034\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 8s 519ms/step - loss: 3.2440e-04 - val_loss: 0.0035\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 8s 507ms/step - loss: 3.0347e-04 - val_loss: 0.0030\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 8s 518ms/step - loss: 2.7118e-04 - val_loss: 0.0026\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 8s 541ms/step - loss: 2.5390e-04 - val_loss: 0.0025\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 8s 554ms/step - loss: 2.3268e-04 - val_loss: 0.0040\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 8s 546ms/step - loss: 2.5449e-04 - val_loss: 0.0053\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 8s 532ms/step - loss: 4.5059e-04 - val_loss: 0.0044\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 8s 517ms/step - loss: 2.8910e-04 - val_loss: 0.0024\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 8s 513ms/step - loss: 2.9193e-04 - val_loss: 0.0023\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 8s 513ms/step - loss: 2.3562e-04 - val_loss: 0.0034\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 8s 511ms/step - loss: 2.1075e-04 - val_loss: 0.0023\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 8s 518ms/step - loss: 2.1983e-04 - val_loss: 0.0024\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 8s 514ms/step - loss: 2.1368e-04 - val_loss: 0.0044\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 8s 520ms/step - loss: 2.0070e-04 - val_loss: 0.0029\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 8s 545ms/step - loss: 1.9428e-04 - val_loss: 0.0038\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 8s 511ms/step - loss: 1.9864e-04 - val_loss: 0.0053\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 8s 523ms/step - loss: 2.0747e-04 - val_loss: 0.0034\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 8s 505ms/step - loss: 1.8732e-04 - val_loss: 0.0084\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 8s 508ms/step - loss: 1.8746e-04 - val_loss: 0.0055\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 8s 512ms/step - loss: 1.7940e-04 - val_loss: 0.0059\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 8s 513ms/step - loss: 1.7356e-04 - val_loss: 0.0067\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 8s 520ms/step - loss: 1.7856e-04 - val_loss: 0.0091\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 8s 515ms/step - loss: 1.6963e-04 - val_loss: 0.0118\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 8s 521ms/step - loss: 1.6302e-04 - val_loss: 0.0080\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 8s 511ms/step - loss: 1.7314e-04 - val_loss: 0.0106\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 8s 511ms/step - loss: 1.8312e-04 - val_loss: 0.0102\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 8s 508ms/step - loss: 1.6504e-04 - val_loss: 0.0263\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 8s 514ms/step - loss: 1.8982e-04 - val_loss: 0.0217\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 8s 509ms/step - loss: 1.6292e-04 - val_loss: 0.0323\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 8s 520ms/step - loss: 1.6819e-04 - val_loss: 0.0163\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 8s 511ms/step - loss: 1.6921e-04 - val_loss: 0.0214\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 8s 513ms/step - loss: 1.4639e-04 - val_loss: 0.0197\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 8s 509ms/step - loss: 1.5539e-04 - val_loss: 0.0226\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 8s 519ms/step - loss: 1.5124e-04 - val_loss: 0.0251\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 8s 514ms/step - loss: 1.3847e-04 - val_loss: 0.0316\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 8s 514ms/step - loss: 1.3854e-04 - val_loss: 0.0391\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 8s 510ms/step - loss: 1.5535e-04 - val_loss: 0.0336\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 8s 529ms/step - loss: 1.5533e-04 - val_loss: 0.0160\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 8s 534ms/step - loss: 1.5060e-04 - val_loss: 0.0132\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 8s 517ms/step - loss: 1.3508e-04 - val_loss: 0.0175\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 8s 515ms/step - loss: 1.3866e-04 - val_loss: 0.0205\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 8s 510ms/step - loss: 1.5560e-04 - val_loss: 0.0178\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 8s 506ms/step - loss: 1.2655e-04 - val_loss: 0.0251\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 8s 510ms/step - loss: 1.2575e-04 - val_loss: 0.0286\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 8s 516ms/step - loss: 1.4934e-04 - val_loss: 0.0147\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 8s 520ms/step - loss: 1.3799e-04 - val_loss: 0.0157\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 8s 516ms/step - loss: 1.1750e-04 - val_loss: 0.0293\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 8s 519ms/step - loss: 1.2217e-04 - val_loss: 0.0218\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 8s 517ms/step - loss: 1.1634e-04 - val_loss: 0.0166\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 8s 519ms/step - loss: 1.0939e-04 - val_loss: 0.0247\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 8s 517ms/step - loss: 1.1467e-04 - val_loss: 0.0206\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 8s 517ms/step - loss: 1.1021e-04 - val_loss: 0.0182\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 8s 540ms/step - loss: 1.1584e-04 - val_loss: 0.0274\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 8s 521ms/step - loss: 1.1947e-04 - val_loss: 0.0226\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 8s 519ms/step - loss: 1.1458e-04 - val_loss: 0.0157\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 8s 516ms/step - loss: 1.2873e-04 - val_loss: 0.0282\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 8s 520ms/step - loss: 1.2844e-04 - val_loss: 0.0157\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 8s 513ms/step - loss: 1.0593e-04 - val_loss: 0.0264\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 8s 525ms/step - loss: 1.1866e-04 - val_loss: 0.0158\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 8s 511ms/step - loss: 9.8994e-05 - val_loss: 0.0162\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 8s 522ms/step - loss: 1.0084e-04 - val_loss: 0.0273\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 8s 518ms/step - loss: 1.0736e-04 - val_loss: 0.0211\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 8s 532ms/step - loss: 1.0010e-04 - val_loss: 0.0124\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 8s 520ms/step - loss: 1.1443e-04 - val_loss: 0.0149\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 8s 510ms/step - loss: 1.0580e-04 - val_loss: 0.0144\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 8s 518ms/step - loss: 9.2728e-05 - val_loss: 0.0128\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 8s 514ms/step - loss: 9.9561e-05 - val_loss: 0.0106\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 8s 514ms/step - loss: 1.2771e-04 - val_loss: 0.0158\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 8s 520ms/step - loss: 1.1519e-04 - val_loss: 0.0188\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 8s 519ms/step - loss: 1.3728e-04 - val_loss: 0.0051\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 8s 514ms/step - loss: 1.9756e-04 - val_loss: 0.0033\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 8s 508ms/step - loss: 1.0798e-04 - val_loss: 0.0059\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 8s 521ms/step - loss: 8.9319e-05 - val_loss: 0.0072\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 8s 514ms/step - loss: 8.7503e-05 - val_loss: 0.0127\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 8s 513ms/step - loss: 9.8960e-05 - val_loss: 0.0068\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 8s 516ms/step - loss: 1.2294e-04 - val_loss: 0.0039\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 8s 519ms/step - loss: 1.4404e-04 - val_loss: 0.0026\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 8s 521ms/step - loss: 9.8917e-05 - val_loss: 0.0036\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 8s 513ms/step - loss: 1.2522e-04 - val_loss: 0.0041\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 8s 523ms/step - loss: 9.6729e-05 - val_loss: 0.0078\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 8s 510ms/step - loss: 9.1244e-05 - val_loss: 0.0051\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 8s 518ms/step - loss: 8.9892e-05 - val_loss: 0.0032\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 8s 506ms/step - loss: 8.0374e-05 - val_loss: 0.0029\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 8s 529ms/step - loss: 1.6118e-04 - val_loss: 0.0101\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 7s 482ms/step - loss: 1.2056e-04 - val_loss: 0.0040\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 7s 482ms/step - loss: 8.3628e-05 - val_loss: 0.0044\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 8s 502ms/step - loss: 7.8737e-05 - val_loss: 0.0055\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 8s 513ms/step - loss: 7.2902e-05 - val_loss: 0.0072\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 8s 512ms/step - loss: 7.5292e-05 - val_loss: 0.0080\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 8s 515ms/step - loss: 7.8264e-05 - val_loss: 0.0078\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 8s 509ms/step - loss: 7.2013e-05 - val_loss: 0.0069\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 8s 542ms/step - loss: 7.0975e-05 - val_loss: 0.0064\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 8s 523ms/step - loss: 7.0499e-05 - val_loss: 0.0092\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 8s 516ms/step - loss: 6.8816e-05 - val_loss: 0.0099\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 8s 514ms/step - loss: 6.9781e-05 - val_loss: 0.0050\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 8s 509ms/step - loss: 7.2606e-05 - val_loss: 0.0136\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 8s 508ms/step - loss: 1.3378e-04 - val_loss: 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_165_layer_call_fn, lstm_cell_165_layer_call_and_return_conditional_losses, lstm_cell_166_layer_call_fn, lstm_cell_166_layer_call_and_return_conditional_losses, lstm_cell_167_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/CRO\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/CRO\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 4s 88ms/step\n",
      "8/8 [==============================] - 1s 92ms/step\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Epoch 1/100\n",
      "19/19 [==============================] - 19s 699ms/step - loss: 0.0121 - val_loss: 0.0017\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 12s 619ms/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - 12s 622ms/step - loss: 0.0029 - val_loss: 0.0012\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 12s 613ms/step - loss: 0.0026 - val_loss: 8.3595e-04\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 12s 615ms/step - loss: 0.0024 - val_loss: 9.2391e-04\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 13s 667ms/step - loss: 0.0024 - val_loss: 7.2846e-04\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 12s 619ms/step - loss: 0.0021 - val_loss: 6.7965e-04\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 12s 616ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 12s 623ms/step - loss: 0.0019 - val_loss: 6.6320e-04\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 12s 624ms/step - loss: 0.0017 - val_loss: 5.3111e-04\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 12s 627ms/step - loss: 0.0014 - val_loss: 4.9394e-04\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 12s 612ms/step - loss: 0.0013 - val_loss: 8.8968e-04\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 12s 617ms/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 12s 644ms/step - loss: 0.0013 - val_loss: 4.2308e-04\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 12s 627ms/step - loss: 0.0011 - val_loss: 5.2874e-04\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 12s 623ms/step - loss: 0.0010 - val_loss: 8.4999e-04\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 12s 626ms/step - loss: 9.3299e-04 - val_loss: 6.2321e-04\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 12s 618ms/step - loss: 0.0010 - val_loss: 4.7292e-04\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 12s 624ms/step - loss: 9.1340e-04 - val_loss: 5.7264e-04\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 13s 671ms/step - loss: 8.3229e-04 - val_loss: 4.0586e-04\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 12s 622ms/step - loss: 8.0614e-04 - val_loss: 4.8724e-04\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - 12s 630ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 12s 616ms/step - loss: 0.0011 - val_loss: 5.4098e-04\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 12s 616ms/step - loss: 8.6983e-04 - val_loss: 3.7051e-04\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 12s 628ms/step - loss: 9.6757e-04 - val_loss: 5.8085e-04\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 12s 620ms/step - loss: 8.5710e-04 - val_loss: 6.4120e-04\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 12s 616ms/step - loss: 7.2648e-04 - val_loss: 3.7411e-04\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 12s 617ms/step - loss: 6.9838e-04 - val_loss: 3.5501e-04\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - 12s 623ms/step - loss: 7.1861e-04 - val_loss: 3.4446e-04\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 12s 627ms/step - loss: 7.6483e-04 - val_loss: 6.5618e-04\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 12s 615ms/step - loss: 7.3702e-04 - val_loss: 3.4131e-04\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 12s 622ms/step - loss: 6.5509e-04 - val_loss: 3.3195e-04\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 12s 617ms/step - loss: 6.4607e-04 - val_loss: 4.3781e-04\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 12s 627ms/step - loss: 6.7637e-04 - val_loss: 3.1692e-04\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 12s 628ms/step - loss: 6.1337e-04 - val_loss: 5.9675e-04\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 12s 628ms/step - loss: 6.7535e-04 - val_loss: 3.4499e-04\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 12s 621ms/step - loss: 5.8571e-04 - val_loss: 3.3762e-04\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 12s 612ms/step - loss: 6.1525e-04 - val_loss: 3.5195e-04\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 12s 633ms/step - loss: 6.1633e-04 - val_loss: 2.9192e-04\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 12s 634ms/step - loss: 6.0669e-04 - val_loss: 6.6405e-04\n",
      "Epoch 41/100\n",
      "19/19 [==============================] - 12s 626ms/step - loss: 6.5402e-04 - val_loss: 3.6346e-04\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 12s 619ms/step - loss: 5.6017e-04 - val_loss: 3.0109e-04\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 12s 617ms/step - loss: 5.8774e-04 - val_loss: 4.4846e-04\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 12s 633ms/step - loss: 6.1068e-04 - val_loss: 2.8697e-04\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 13s 674ms/step - loss: 5.3898e-04 - val_loss: 3.0609e-04\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 14s 746ms/step - loss: 5.0542e-04 - val_loss: 2.6245e-04\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 14s 722ms/step - loss: 4.9644e-04 - val_loss: 2.8480e-04\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - 12s 653ms/step - loss: 5.6740e-04 - val_loss: 2.9181e-04\n",
      "Epoch 49/100\n",
      "19/19 [==============================] - 12s 661ms/step - loss: 5.3548e-04 - val_loss: 2.6531e-04\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 13s 682ms/step - loss: 4.9983e-04 - val_loss: 4.0113e-04\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - 12s 633ms/step - loss: 5.0781e-04 - val_loss: 2.4360e-04\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 13s 703ms/step - loss: 4.7204e-04 - val_loss: 2.4136e-04\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 12s 630ms/step - loss: 4.7262e-04 - val_loss: 3.3763e-04\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 12s 642ms/step - loss: 4.9872e-04 - val_loss: 3.2891e-04\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 12s 647ms/step - loss: 5.1422e-04 - val_loss: 2.7149e-04\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 12s 643ms/step - loss: 4.7863e-04 - val_loss: 2.5930e-04\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 13s 677ms/step - loss: 4.3879e-04 - val_loss: 2.6043e-04\n",
      "Epoch 58/100\n",
      "19/19 [==============================] - 13s 667ms/step - loss: 5.1667e-04 - val_loss: 2.3453e-04\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 12s 641ms/step - loss: 4.6128e-04 - val_loss: 2.4279e-04\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 12s 625ms/step - loss: 4.6779e-04 - val_loss: 2.8321e-04\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 12s 620ms/step - loss: 4.6472e-04 - val_loss: 2.2138e-04\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 12s 624ms/step - loss: 4.3873e-04 - val_loss: 2.3068e-04\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 12s 626ms/step - loss: 4.3946e-04 - val_loss: 2.1420e-04\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - 12s 635ms/step - loss: 4.2570e-04 - val_loss: 2.1356e-04\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - 12s 634ms/step - loss: 4.8756e-04 - val_loss: 2.3935e-04\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - 12s 618ms/step - loss: 4.3456e-04 - val_loss: 2.1929e-04\n",
      "Epoch 67/100\n",
      "19/19 [==============================] - 12s 624ms/step - loss: 4.2571e-04 - val_loss: 2.7022e-04\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - 12s 620ms/step - loss: 4.4259e-04 - val_loss: 2.2745e-04\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - 12s 631ms/step - loss: 4.2864e-04 - val_loss: 5.1193e-04\n",
      "Epoch 70/100\n",
      "19/19 [==============================] - 12s 642ms/step - loss: 5.7756e-04 - val_loss: 4.5578e-04\n",
      "Epoch 71/100\n",
      "19/19 [==============================] - 12s 631ms/step - loss: 4.6168e-04 - val_loss: 2.8212e-04\n",
      "Epoch 72/100\n",
      "19/19 [==============================] - 12s 616ms/step - loss: 4.5145e-04 - val_loss: 2.2686e-04\n",
      "Epoch 73/100\n",
      "19/19 [==============================] - 12s 616ms/step - loss: 4.7892e-04 - val_loss: 2.7757e-04\n",
      "Epoch 74/100\n",
      "19/19 [==============================] - 12s 616ms/step - loss: 5.8457e-04 - val_loss: 3.7735e-04\n",
      "Epoch 75/100\n",
      "19/19 [==============================] - 12s 618ms/step - loss: 4.8025e-04 - val_loss: 2.1307e-04\n",
      "Epoch 76/100\n",
      "19/19 [==============================] - 12s 617ms/step - loss: 4.3668e-04 - val_loss: 2.4537e-04\n",
      "Epoch 77/100\n",
      "19/19 [==============================] - 12s 616ms/step - loss: 4.3258e-04 - val_loss: 2.3413e-04\n",
      "Epoch 78/100\n",
      "19/19 [==============================] - 12s 623ms/step - loss: 3.9740e-04 - val_loss: 2.0984e-04\n",
      "Epoch 79/100\n",
      "19/19 [==============================] - 12s 656ms/step - loss: 4.0084e-04 - val_loss: 2.8514e-04\n",
      "Epoch 80/100\n",
      "19/19 [==============================] - 12s 624ms/step - loss: 4.0619e-04 - val_loss: 2.0069e-04\n",
      "Epoch 81/100\n",
      "19/19 [==============================] - 12s 646ms/step - loss: 3.9671e-04 - val_loss: 2.0515e-04\n",
      "Epoch 82/100\n",
      "19/19 [==============================] - 12s 614ms/step - loss: 3.8938e-04 - val_loss: 2.3923e-04\n",
      "Epoch 83/100\n",
      "19/19 [==============================] - 12s 621ms/step - loss: 4.6120e-04 - val_loss: 2.7047e-04\n",
      "Epoch 84/100\n",
      "19/19 [==============================] - 12s 619ms/step - loss: 4.2990e-04 - val_loss: 3.3546e-04\n",
      "Epoch 85/100\n",
      "19/19 [==============================] - 12s 636ms/step - loss: 4.3572e-04 - val_loss: 2.2047e-04\n",
      "Epoch 86/100\n",
      "19/19 [==============================] - 12s 615ms/step - loss: 4.1920e-04 - val_loss: 2.0582e-04\n",
      "Epoch 87/100\n",
      "19/19 [==============================] - 12s 614ms/step - loss: 3.7918e-04 - val_loss: 2.4685e-04\n",
      "Epoch 88/100\n",
      "19/19 [==============================] - 12s 620ms/step - loss: 4.2757e-04 - val_loss: 2.0847e-04\n",
      "Epoch 89/100\n",
      "19/19 [==============================] - 12s 617ms/step - loss: 4.6009e-04 - val_loss: 2.1617e-04\n",
      "Epoch 90/100\n",
      "19/19 [==============================] - 12s 628ms/step - loss: 4.9940e-04 - val_loss: 3.4045e-04\n",
      "Epoch 91/100\n",
      "19/19 [==============================] - 12s 619ms/step - loss: 4.1507e-04 - val_loss: 2.0583e-04\n",
      "Epoch 92/100\n",
      "19/19 [==============================] - 12s 617ms/step - loss: 3.8889e-04 - val_loss: 2.1843e-04\n",
      "Epoch 93/100\n",
      "19/19 [==============================] - 12s 626ms/step - loss: 3.9102e-04 - val_loss: 2.1026e-04\n",
      "Epoch 94/100\n",
      "19/19 [==============================] - 12s 627ms/step - loss: 4.1807e-04 - val_loss: 2.1637e-04\n",
      "Epoch 95/100\n",
      "19/19 [==============================] - 13s 671ms/step - loss: 4.4254e-04 - val_loss: 2.0005e-04\n",
      "Epoch 96/100\n",
      "19/19 [==============================] - 13s 663ms/step - loss: 4.3455e-04 - val_loss: 3.6339e-04\n",
      "Epoch 97/100\n",
      "19/19 [==============================] - 12s 658ms/step - loss: 4.3253e-04 - val_loss: 2.3626e-04\n",
      "Epoch 98/100\n",
      "19/19 [==============================] - 12s 643ms/step - loss: 3.9278e-04 - val_loss: 3.4479e-04\n",
      "Epoch 99/100\n",
      "19/19 [==============================] - 12s 617ms/step - loss: 4.0365e-04 - val_loss: 2.1147e-04\n",
      "Epoch 100/100\n",
      "19/19 [==============================] - 12s 629ms/step - loss: 3.6781e-04 - val_loss: 2.0755e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_168_layer_call_fn, lstm_cell_168_layer_call_and_return_conditional_losses, lstm_cell_169_layer_call_fn, lstm_cell_169_layer_call_and_return_conditional_losses, lstm_cell_170_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/XLM\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/XLM\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 5s 89ms/step\n",
      "11/11 [==============================] - 1s 84ms/step\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 12s 763ms/step - loss: 0.0707 - val_loss: 0.0787\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 4s 509ms/step - loss: 0.0290 - val_loss: 8.1284e-04\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 4s 524ms/step - loss: 0.0228 - val_loss: 0.0015\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 4s 524ms/step - loss: 0.0113 - val_loss: 0.0155\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 4s 516ms/step - loss: 0.0110 - val_loss: 0.0042\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 4s 545ms/step - loss: 0.0089 - val_loss: 0.0023\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 4s 539ms/step - loss: 0.0078 - val_loss: 0.0044\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 4s 520ms/step - loss: 0.0075 - val_loss: 0.0017\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 4s 538ms/step - loss: 0.0084 - val_loss: 0.0019\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 4s 528ms/step - loss: 0.0073 - val_loss: 0.0046\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 4s 514ms/step - loss: 0.0071 - val_loss: 0.0016\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 4s 508ms/step - loss: 0.0070 - val_loss: 0.0027\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 4s 515ms/step - loss: 0.0069 - val_loss: 0.0022\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 4s 524ms/step - loss: 0.0065 - val_loss: 0.0017\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 4s 521ms/step - loss: 0.0064 - val_loss: 0.0017\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 4s 503ms/step - loss: 0.0064 - val_loss: 0.0018\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 4s 505ms/step - loss: 0.0063 - val_loss: 0.0017\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 4s 520ms/step - loss: 0.0065 - val_loss: 0.0018\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 4s 515ms/step - loss: 0.0068 - val_loss: 0.0015\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 4s 501ms/step - loss: 0.0063 - val_loss: 0.0015\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 4s 514ms/step - loss: 0.0058 - val_loss: 0.0019\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 4s 525ms/step - loss: 0.0061 - val_loss: 0.0017\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 4s 510ms/step - loss: 0.0060 - val_loss: 0.0013\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 4s 526ms/step - loss: 0.0060 - val_loss: 0.0016\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 4s 514ms/step - loss: 0.0055 - val_loss: 0.0015\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 4s 531ms/step - loss: 0.0054 - val_loss: 0.0013\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 4s 502ms/step - loss: 0.0054 - val_loss: 0.0018\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 4s 518ms/step - loss: 0.0057 - val_loss: 9.0097e-04\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 4s 528ms/step - loss: 0.0068 - val_loss: 0.0034\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 4s 516ms/step - loss: 0.0065 - val_loss: 0.0010\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 4s 496ms/step - loss: 0.0056 - val_loss: 0.0019\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 4s 496ms/step - loss: 0.0057 - val_loss: 0.0011\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 4s 512ms/step - loss: 0.0054 - val_loss: 0.0013\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 4s 509ms/step - loss: 0.0051 - val_loss: 0.0015\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 4s 504ms/step - loss: 0.0056 - val_loss: 0.0017\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 4s 507ms/step - loss: 0.0051 - val_loss: 0.0016\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 4s 515ms/step - loss: 0.0049 - val_loss: 0.0012\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 4s 498ms/step - loss: 0.0049 - val_loss: 0.0014\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 4s 500ms/step - loss: 0.0048 - val_loss: 0.0014\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 4s 513ms/step - loss: 0.0048 - val_loss: 0.0013\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 4s 523ms/step - loss: 0.0050 - val_loss: 0.0019\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 4s 496ms/step - loss: 0.0052 - val_loss: 9.2699e-04\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 4s 508ms/step - loss: 0.0048 - val_loss: 0.0014\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 4s 509ms/step - loss: 0.0051 - val_loss: 8.4311e-04\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 4s 499ms/step - loss: 0.0054 - val_loss: 0.0019\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 4s 500ms/step - loss: 0.0054 - val_loss: 0.0010\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 4s 510ms/step - loss: 0.0052 - val_loss: 0.0015\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 4s 505ms/step - loss: 0.0045 - val_loss: 0.0011\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 4s 499ms/step - loss: 0.0045 - val_loss: 9.2374e-04\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 4s 505ms/step - loss: 0.0043 - val_loss: 0.0010\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 4s 507ms/step - loss: 0.0041 - val_loss: 0.0011\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 4s 501ms/step - loss: 0.0042 - val_loss: 0.0014\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 4s 496ms/step - loss: 0.0041 - val_loss: 0.0012\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 4s 521ms/step - loss: 0.0039 - val_loss: 0.0011\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 4s 522ms/step - loss: 0.0039 - val_loss: 8.1909e-04\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 4s 523ms/step - loss: 0.0038 - val_loss: 0.0011\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 4s 526ms/step - loss: 0.0038 - val_loss: 7.2078e-04\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 4s 506ms/step - loss: 0.0036 - val_loss: 0.0011\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 4s 510ms/step - loss: 0.0036 - val_loss: 0.0012\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 4s 509ms/step - loss: 0.0035 - val_loss: 0.0013\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 4s 512ms/step - loss: 0.0037 - val_loss: 7.7177e-04\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 4s 508ms/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 4s 492ms/step - loss: 0.0041 - val_loss: 7.1951e-04\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 4s 506ms/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 4s 512ms/step - loss: 0.0038 - val_loss: 7.1228e-04\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 4s 497ms/step - loss: 0.0033 - val_loss: 7.4695e-04\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 4s 498ms/step - loss: 0.0032 - val_loss: 6.2354e-04\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 4s 517ms/step - loss: 0.0029 - val_loss: 8.5777e-04\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 4s 498ms/step - loss: 0.0029 - val_loss: 5.7970e-04\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 4s 508ms/step - loss: 0.0029 - val_loss: 9.0529e-04\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 4s 495ms/step - loss: 0.0028 - val_loss: 5.6281e-04\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 4s 518ms/step - loss: 0.0027 - val_loss: 5.7673e-04\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 4s 506ms/step - loss: 0.0026 - val_loss: 6.0031e-04\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 3s 495ms/step - loss: 0.0026 - val_loss: 7.7471e-04\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 4s 509ms/step - loss: 0.0026 - val_loss: 4.8680e-04\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 4s 505ms/step - loss: 0.0026 - val_loss: 6.3008e-04\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 4s 499ms/step - loss: 0.0025 - val_loss: 5.6938e-04\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 4s 501ms/step - loss: 0.0024 - val_loss: 4.5324e-04\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 4s 518ms/step - loss: 0.0027 - val_loss: 7.9520e-04\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 4s 502ms/step - loss: 0.0025 - val_loss: 4.6978e-04\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 4s 497ms/step - loss: 0.0024 - val_loss: 4.4498e-04\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 4s 511ms/step - loss: 0.0023 - val_loss: 4.4295e-04\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 4s 501ms/step - loss: 0.0022 - val_loss: 4.5935e-04\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 3s 491ms/step - loss: 0.0022 - val_loss: 4.4314e-04\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 4s 508ms/step - loss: 0.0022 - val_loss: 5.0588e-04\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 4s 510ms/step - loss: 0.0021 - val_loss: 4.4545e-04\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 4s 510ms/step - loss: 0.0021 - val_loss: 4.1359e-04\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 3s 491ms/step - loss: 0.0022 - val_loss: 4.0033e-04\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 4s 507ms/step - loss: 0.0026 - val_loss: 5.0642e-04\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 4s 519ms/step - loss: 0.0023 - val_loss: 6.8318e-04\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 3s 489ms/step - loss: 0.0021 - val_loss: 3.8976e-04\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 4s 497ms/step - loss: 0.0021 - val_loss: 3.7536e-04\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 4s 516ms/step - loss: 0.0020 - val_loss: 5.7286e-04\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 4s 499ms/step - loss: 0.0019 - val_loss: 3.7301e-04\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 4s 509ms/step - loss: 0.0021 - val_loss: 3.9647e-04\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 4s 507ms/step - loss: 0.0021 - val_loss: 5.2987e-04\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 4s 521ms/step - loss: 0.0019 - val_loss: 3.4995e-04\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 4s 518ms/step - loss: 0.0018 - val_loss: 4.0430e-04\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 4s 501ms/step - loss: 0.0018 - val_loss: 3.1966e-04\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 4s 516ms/step - loss: 0.0020 - val_loss: 3.8538e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_171_layer_call_fn, lstm_cell_171_layer_call_and_return_conditional_losses, lstm_cell_172_layer_call_fn, lstm_cell_172_layer_call_and_return_conditional_losses, lstm_cell_173_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/NEAR\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/NEAR\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 3s 89ms/step\n",
      "3/3 [==============================] - 0s 56ms/step\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Epoch 1/100\n",
      "13/13 [==============================] - 16s 786ms/step - loss: 0.0226 - val_loss: 0.0145\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 9s 666ms/step - loss: 0.0058 - val_loss: 0.0237\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 9s 668ms/step - loss: 0.0041 - val_loss: 0.0211\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 9s 688ms/step - loss: 0.0035 - val_loss: 0.0091\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 9s 672ms/step - loss: 0.0032 - val_loss: 0.0047\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 9s 716ms/step - loss: 0.0027 - val_loss: 0.0057\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 9s 701ms/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 9s 676ms/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 9s 666ms/step - loss: 0.0023 - val_loss: 0.0051\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 9s 681ms/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 9s 676ms/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 9s 666ms/step - loss: 0.0020 - val_loss: 0.0075\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 9s 687ms/step - loss: 0.0024 - val_loss: 0.0068\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 9s 725ms/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 9s 696ms/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 9s 671ms/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 9s 667ms/step - loss: 0.0016 - val_loss: 0.0072\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 9s 688ms/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 9s 673ms/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 9s 680ms/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 9s 675ms/step - loss: 0.0016 - val_loss: 0.0084\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 9s 680ms/step - loss: 0.0019 - val_loss: 0.0058\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 9s 688ms/step - loss: 0.0017 - val_loss: 0.0067\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 9s 679ms/step - loss: 0.0016 - val_loss: 0.0034\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 9s 670ms/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 9s 688ms/step - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 9s 688ms/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 9s 675ms/step - loss: 0.0013 - val_loss: 0.0032\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 9s 732ms/step - loss: 0.0013 - val_loss: 0.0051\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 9s 675ms/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 9s 677ms/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 9s 685ms/step - loss: 0.0012 - val_loss: 0.0029\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 9s 685ms/step - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 9s 668ms/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 9s 685ms/step - loss: 0.0012 - val_loss: 0.0032\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 9s 687ms/step - loss: 0.0013 - val_loss: 0.0025\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 9s 672ms/step - loss: 0.0012 - val_loss: 0.0026\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 9s 676ms/step - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 9s 668ms/step - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 9s 706ms/step - loss: 0.0012 - val_loss: 0.0034\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 9s 669ms/step - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 9s 672ms/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 9s 671ms/step - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 9s 659ms/step - loss: 0.0012 - val_loss: 0.0025\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 9s 668ms/step - loss: 0.0012 - val_loss: 0.0025\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 9s 664ms/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 9s 671ms/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 9s 688ms/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 9s 672ms/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 9s 669ms/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 9s 681ms/step - loss: 0.0011 - val_loss: 0.0032\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 9s 673ms/step - loss: 0.0011 - val_loss: 0.0022\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 9s 671ms/step - loss: 0.0010 - val_loss: 0.0020\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 9s 678ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 9s 666ms/step - loss: 0.0011 - val_loss: 0.0030\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 9s 683ms/step - loss: 0.0011 - val_loss: 0.0027\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 9s 678ms/step - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 9s 674ms/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 9s 660ms/step - loss: 0.0010 - val_loss: 0.0021\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 9s 683ms/step - loss: 9.8050e-04 - val_loss: 0.0018\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 9s 670ms/step - loss: 9.9915e-04 - val_loss: 0.0017\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 9s 678ms/step - loss: 9.7142e-04 - val_loss: 0.0020\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 9s 674ms/step - loss: 9.4562e-04 - val_loss: 0.0017\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 9s 677ms/step - loss: 9.3183e-04 - val_loss: 0.0025\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 9s 669ms/step - loss: 9.7899e-04 - val_loss: 0.0016\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 9s 675ms/step - loss: 9.0982e-04 - val_loss: 0.0016\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 9s 668ms/step - loss: 9.4931e-04 - val_loss: 0.0020\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 9s 677ms/step - loss: 9.5080e-04 - val_loss: 0.0040\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 9s 669ms/step - loss: 0.0013 - val_loss: 0.0025\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 9s 677ms/step - loss: 9.2355e-04 - val_loss: 0.0017\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 9s 668ms/step - loss: 8.9299e-04 - val_loss: 0.0015\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 9s 675ms/step - loss: 8.6346e-04 - val_loss: 0.0015\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 9s 675ms/step - loss: 8.8536e-04 - val_loss: 0.0015\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 9s 665ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 9s 670ms/step - loss: 8.7659e-04 - val_loss: 0.0018\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 9s 687ms/step - loss: 9.3686e-04 - val_loss: 0.0025\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 9s 686ms/step - loss: 8.9203e-04 - val_loss: 0.0020\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 9s 677ms/step - loss: 7.7887e-04 - val_loss: 0.0032\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 9s 660ms/step - loss: 9.0326e-04 - val_loss: 0.0021\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 9s 681ms/step - loss: 8.3889e-04 - val_loss: 0.0053\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 9s 682ms/step - loss: 8.6097e-04 - val_loss: 0.0021\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 9s 678ms/step - loss: 8.6018e-04 - val_loss: 0.0032\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 9s 676ms/step - loss: 8.1426e-04 - val_loss: 0.0019\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 9s 673ms/step - loss: 7.8062e-04 - val_loss: 0.0013\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 9s 680ms/step - loss: 7.5029e-04 - val_loss: 0.0017\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 9s 675ms/step - loss: 7.4592e-04 - val_loss: 0.0013\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 9s 676ms/step - loss: 7.4566e-04 - val_loss: 0.0013\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 9s 664ms/step - loss: 8.3909e-04 - val_loss: 0.0016\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 9s 675ms/step - loss: 8.5634e-04 - val_loss: 0.0013\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 9s 667ms/step - loss: 7.4007e-04 - val_loss: 0.0013\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 9s 672ms/step - loss: 7.2800e-04 - val_loss: 0.0023\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 9s 684ms/step - loss: 7.3713e-04 - val_loss: 0.0016\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 9s 667ms/step - loss: 6.9470e-04 - val_loss: 0.0012\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 9s 654ms/step - loss: 7.0567e-04 - val_loss: 0.0013\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 9s 667ms/step - loss: 6.7395e-04 - val_loss: 0.0016\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 9s 672ms/step - loss: 6.9854e-04 - val_loss: 0.0014\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 9s 678ms/step - loss: 6.6089e-04 - val_loss: 0.0014\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 9s 676ms/step - loss: 6.7489e-04 - val_loss: 0.0013\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 9s 663ms/step - loss: 6.7404e-04 - val_loss: 0.0013\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 9s 683ms/step - loss: 6.9158e-04 - val_loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_174_layer_call_fn, lstm_cell_174_layer_call_and_return_conditional_losses, lstm_cell_175_layer_call_fn, lstm_cell_175_layer_call_and_return_conditional_losses, lstm_cell_176_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/ATOM\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crypto_models/ATOM\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 4s 94ms/step\n",
      "7/7 [==============================] - 1s 94ms/step\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\oriyomi\\Desktop\\AI_Workspace\\COM724\\Data Preprocessing.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/oriyomi/Desktop/AI_Workspace/COM724/Data%20Preprocessing.ipynb#ch0000058?line=50'>51</a>\u001b[0m \u001b[39m# reshape input to be [samples, time steps, features] which is required for LSTM\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/oriyomi/Desktop/AI_Workspace/COM724/Data%20Preprocessing.ipynb#ch0000058?line=51'>52</a>\u001b[0m X_train \u001b[39m=\u001b[39mX_train\u001b[39m.\u001b[39mreshape(X_train\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m],X_train\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] , \u001b[39m1\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/oriyomi/Desktop/AI_Workspace/COM724/Data%20Preprocessing.ipynb#ch0000058?line=52'>53</a>\u001b[0m X_test \u001b[39m=\u001b[39m X_test\u001b[39m.\u001b[39mreshape(X_test\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m],X_test\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m] , \u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/oriyomi/Desktop/AI_Workspace/COM724/Data%20Preprocessing.ipynb#ch0000058?line=54'>55</a>\u001b[0m model\u001b[39m=\u001b[39mSequential()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/oriyomi/Desktop/AI_Workspace/COM724/Data%20Preprocessing.ipynb#ch0000058?line=55'>56</a>\u001b[0m model\u001b[39m.\u001b[39madd(LSTM(\u001b[39m50\u001b[39m,return_sequences\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,input_shape\u001b[39m=\u001b[39m(\u001b[39m100\u001b[39m,\u001b[39m1\u001b[39m)))\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, time_step=1):\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-time_step-1):\n",
    "\t\ta = dataset[i:(i+time_step), 0]   ###i=0, 0,1,2,3-----99   100 \n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + time_step, 0])\n",
    "\treturn np.array(dataX), np.array(dataY)\n",
    "\n",
    "today = date.today()\n",
    "\n",
    "# dd/mm/YY\n",
    "d1 = today.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# define coin symbols\n",
    "crypto_symbols = ['BTC', 'ETH', 'USDT', 'USDC', 'BNB',\n",
    "'BUSD', 'XRP', 'ADA', 'SOL', 'DOGE',\n",
    "'DAI', 'DOT', 'HEX', 'TRX',\n",
    "'SHIB', 'LEO', 'WBTC', 'AVAX', 'YOUC',\n",
    "'MATIC', 'STETH', 'UNI1', 'LTC', 'FTT',\n",
    "'LINK', 'CRO', 'XLM', 'NEAR', 'ATOM', 'WTRX']\n",
    "\n",
    "for coins in crypto_symbols:\n",
    "#   ticker.append(f'{coins}-USD')\n",
    "    coin_set = yf.download([f'{coins}-USD'], start='2014-01-01', end=d1, interval='1d')\n",
    "    coin_data = coin_set.copy().dropna()\n",
    "    coin_data = coin_data.reset_index()\n",
    "    coin_data_close = coin_data['Close']\n",
    "    min_max_scaler = MinMaxScaler() #this returns values between 0.10\n",
    "\n",
    "    close_price = np.array(coin_data_close).reshape(-1,1)\n",
    "    scaled_close = min_max_scaler.fit_transform(close_price)\n",
    "\n",
    "    ##splitting dataset into train and test split\n",
    "    training_size=int(len(scaled_close)*0.75)\n",
    "    test_size=len(scaled_close)-training_size\n",
    "    train_data,test_data=scaled_close[0:training_size,:],scaled_close[training_size:len(scaled_close),:1]\n",
    "    \n",
    "    # reshape into X=t,t+1,t+2,t+3 and Y=t+4\n",
    "    time_step = 100\n",
    "    X_train, y_train = create_dataset(train_data, time_step)\n",
    "    X_test, ytest = create_dataset(test_data, time_step)\n",
    "    \n",
    "    # reshape input to be [samples, time steps, features] which is required for LSTM\n",
    "    X_train =X_train.reshape(X_train.shape[0],X_train.shape[1] , 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0],X_test.shape[1] , 1)\n",
    "    \n",
    "    model=Sequential()\n",
    "    model.add(LSTM(50,return_sequences=True,input_shape=(100,1)))\n",
    "    model.add(LSTM(50,return_sequences=True))\n",
    "    model.add(LSTM(50))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "    \n",
    "    model.fit(X_train,y_train,validation_data=(X_test,ytest),epochs=100,batch_size=64,verbose=1)\n",
    "    model.save(f'crypto_models/{coins}')\n",
    "    \n",
    "    train_predict=model.predict(X_train)\n",
    "    test_predict=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "crypto_symbols = ['BTC', 'ETH', 'USDT', 'USDC', 'BNB',\n",
    "'BUSD', 'XRP', 'ADA', 'SOL', 'DOGE',\n",
    "'DAI', 'DOT', 'WTRX', 'HEX', 'TRX',\n",
    "'SHIB', 'LEO', 'WBTC', 'AVAX', 'YOUC',\n",
    "'MATIC', 'STETH', 'UNI1', 'LTC', 'FTT',\n",
    "'LINK', 'CRO', 'XLM', 'NEAR', 'ATOM']\n",
    "\n",
    "today = date.today()\n",
    "\n",
    "# dd/mm/YY\n",
    "d1 = today.strftime(\"%Y/%m/%d\")\n",
    "\n",
    "for coin in crypto_symbols:\n",
    "    coin_set = yf.download([f'{coin}-USD'], start=\"2013-09-17\", end=today)\n",
    "    coin_set2 = coin_set.copy().dropna()\n",
    "\n",
    "    predict = ['Close_Predict', 'Open_Predict', 'High_Predict', \n",
    "    'Low_Predict', 'Volume_Predict']\n",
    "    projection = 7\n",
    "    coin_set2['Close_Predict']=coin_set2[['Close']].shift(-projection)\n",
    "    coin_set2['Open_Predict']=coin_set2[['Open']].shift(-projection)\n",
    "    coin_set2['High_Predict']=coin_set2[['High']].shift(-projection)\n",
    "    coin_set2['Low_Predict']=coin_set2[['Low']].shift(-projection)\n",
    "    coin_set2['Volume_Predict']=coin_set2[['Volume']].shift(-projection)\n",
    "\n",
    "    coin_set3 = coin_set2.tail(projection)\n",
    "    coin_set3 = np.array(coin_set3[['Open','High','Low','Close','Volume']])\n",
    "\n",
    "    #Creating the dataset based on the Independent variable X as numpy array\n",
    "    X = np.array(coin_set2[['Open','High','Low','Close','Volume']])\n",
    "    X = X[:-projection]\n",
    "\n",
    "    predic_result = {}\n",
    "\n",
    "    for pred in predict:\n",
    "        y = np.array(coin_set2[pred])\n",
    "        y = y[:-projection]\n",
    "\n",
    "        #Spliting the dataset into 80% training and 20% testing datasets\n",
    "        X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20)\n",
    "        xg_reg = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "        xg_reg.fit(X_train, y_train)\n",
    "        y_pred = xg_reg.predict(X_test)\n",
    "\n",
    "        predic_result[pred] = xg_reg.predict(coin_set3)\n",
    "\n",
    "    output = pd.DataFrame(predic_result).to_csv(f'crypto_models/{coin}-USD_result_{today}.csv')\n",
    "\n",
    "    # Saving model to disk\n",
    "    pickle.dump(xg_reg, open(f'crypto_models/{coin}-USD_model_{today}.pkl','wb'))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[6.32712603e+00, 6.57379007e+00, 6.28331423e+00, 6.39219093e+00,\n",
       "        1.58842638e+08],\n",
       "       [6.39105606e+00, 6.49421787e+00, 5.58881712e+00, 6.08269978e+00,\n",
       "        2.32265574e+08],\n",
       "       [6.07912111e+00, 6.81902122e+00, 5.89397192e+00, 6.77089024e+00,\n",
       "        2.41234606e+08],\n",
       "       [6.76920319e+00, 6.94835711e+00, 6.50927591e+00, 6.81211996e+00,\n",
       "        1.84516560e+08],\n",
       "       [6.81038523e+00, 7.16367388e+00, 6.68894100e+00, 6.92895412e+00,\n",
       "        1.88461410e+08],\n",
       "       [6.93405008e+00, 7.56142378e+00, 6.60241795e+00, 7.07468414e+00,\n",
       "        3.71903028e+08],\n",
       "       [7.07436419e+00, 8.15135956e+00, 7.07332420e+00, 8.14293957e+00,\n",
       "        4.43262069e+08],\n",
       "       [8.13779354e+00, 8.50174332e+00, 7.98842001e+00, 8.27886677e+00,\n",
       "        3.49099080e+08],\n",
       "       [8.27885246e+00, 8.68225193e+00, 8.03966618e+00, 8.65573883e+00,\n",
       "        2.70454488e+08],\n",
       "       [8.65433121e+00, 8.73576546e+00, 8.04172802e+00, 8.04457092e+00,\n",
       "        2.63021151e+08],\n",
       "       [8.04585075e+00, 8.55943871e+00, 7.82096291e+00, 7.82732201e+00,\n",
       "        2.42546152e+08],\n",
       "       [7.82532501e+00, 7.99339390e+00, 7.29903793e+00, 7.33291292e+00,\n",
       "        3.33187655e+08],\n",
       "       [7.33576298e+00, 7.48466396e+00, 7.07386303e+00, 7.36802101e+00,\n",
       "        2.87098029e+08],\n",
       "       [7.37062407e+00, 7.59779501e+00, 6.93830395e+00, 7.52667713e+00,\n",
       "        3.23687511e+08],\n",
       "       [7.53615379e+00, 8.32941055e+00, 7.21201086e+00, 8.08587646e+00,\n",
       "        5.39936619e+08],\n",
       "       [8.08607864e+00, 8.30012226e+00, 7.96259689e+00, 8.06583595e+00,\n",
       "        4.47948197e+08],\n",
       "       [8.06585407e+00, 8.28046894e+00, 7.80399323e+00, 8.09722233e+00,\n",
       "        3.33735291e+08],\n",
       "       [8.09720135e+00, 8.88777447e+00, 7.88079500e+00, 8.76491356e+00,\n",
       "        4.14283803e+08],\n",
       "       [8.76243496e+00, 9.26767635e+00, 8.42290974e+00, 8.97449875e+00,\n",
       "        6.80888288e+08],\n",
       "       [8.97400379e+00, 9.33720779e+00, 8.79000568e+00, 8.90892506e+00,\n",
       "        6.69464067e+08],\n",
       "       [8.90778637e+00, 9.54809475e+00, 8.71459579e+00, 9.37381554e+00,\n",
       "        4.85663669e+08],\n",
       "       [9.37366104e+00, 9.65395641e+00, 8.93406582e+00, 9.03252983e+00,\n",
       "        5.48847164e+08],\n",
       "       [9.02877426e+00, 9.34024906e+00, 8.98468208e+00, 8.99660397e+00,\n",
       "        4.34227865e+08],\n",
       "       [8.99618721e+00, 8.99618721e+00, 8.53213787e+00, 8.79794693e+00,\n",
       "        4.13668882e+08],\n",
       "       [8.79133320e+00, 9.07610989e+00, 8.19339085e+00, 8.19339085e+00,\n",
       "        2.67451885e+08],\n",
       "       [8.19492340e+00, 8.38456917e+00, 7.74573183e+00, 7.80407810e+00,\n",
       "        2.03896723e+08],\n",
       "       [7.80616093e+00, 8.20875072e+00, 7.44418478e+00, 8.20875072e+00,\n",
       "        2.34574531e+08],\n",
       "       [8.20488453e+00, 9.02435398e+00, 8.11120701e+00, 8.97495747e+00,\n",
       "        3.12197850e+08],\n",
       "       [8.97510719e+00, 9.45924664e+00, 8.89474297e+00, 9.05434799e+00,\n",
       "        3.38316025e+08],\n",
       "       [9.05292797e+00, 9.34044933e+00, 8.81297970e+00, 9.21837234e+00,\n",
       "        2.40149001e+08]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set1 = yf.download(['ETH-USD'], start=\"2013-09-17\", end=today)\n",
    "set2 = coin_set.copy().dropna()\n",
    "\n",
    "\n",
    "projection = 30\n",
    "set2['Close_Predict']=coin_set2[['Close']].shift(-projection)\n",
    "set2['Open_Predict']=coin_set2[['Open']].shift(-projection)\n",
    "set2['High_Predict']=coin_set2[['High']].shift(-projection)\n",
    "set2['Low_Predict']=coin_set2[['Low']].shift(-projection)\n",
    "set2['Volume_Predict']=coin_set2[['Volume']].shift(-projection)\n",
    "\n",
    "set3 = set2.tail(projection)\n",
    "set3 = np.array(set3[['Open','High','Low','Close','Volume']])\n",
    "set3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-03-14</th>\n",
       "      <td>6.439715</td>\n",
       "      <td>6.639943</td>\n",
       "      <td>6.353963</td>\n",
       "      <td>6.526642</td>\n",
       "      <td>7318172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-15</th>\n",
       "      <td>6.633174</td>\n",
       "      <td>7.715249</td>\n",
       "      <td>6.432468</td>\n",
       "      <td>7.504351</td>\n",
       "      <td>6057301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-16</th>\n",
       "      <td>7.507990</td>\n",
       "      <td>8.305615</td>\n",
       "      <td>6.694531</td>\n",
       "      <td>7.383882</td>\n",
       "      <td>3477393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-17</th>\n",
       "      <td>7.357443</td>\n",
       "      <td>7.357443</td>\n",
       "      <td>4.727895</td>\n",
       "      <td>4.776164</td>\n",
       "      <td>2653565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-18</th>\n",
       "      <td>4.828242</td>\n",
       "      <td>5.229982</td>\n",
       "      <td>4.828242</td>\n",
       "      <td>5.110341</td>\n",
       "      <td>2567201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-12</th>\n",
       "      <td>8.194923</td>\n",
       "      <td>8.384569</td>\n",
       "      <td>7.745732</td>\n",
       "      <td>7.804078</td>\n",
       "      <td>203896723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-13</th>\n",
       "      <td>7.806161</td>\n",
       "      <td>8.208751</td>\n",
       "      <td>7.444185</td>\n",
       "      <td>8.208751</td>\n",
       "      <td>234574531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-14</th>\n",
       "      <td>8.204885</td>\n",
       "      <td>9.024354</td>\n",
       "      <td>8.111207</td>\n",
       "      <td>8.974957</td>\n",
       "      <td>312197850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-15</th>\n",
       "      <td>8.975107</td>\n",
       "      <td>9.459247</td>\n",
       "      <td>8.894743</td>\n",
       "      <td>9.054348</td>\n",
       "      <td>338316025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-16</th>\n",
       "      <td>9.052928</td>\n",
       "      <td>9.340449</td>\n",
       "      <td>8.812980</td>\n",
       "      <td>9.218372</td>\n",
       "      <td>240149001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1221 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Open      High       Low     Close     Volume\n",
       "Date                                                         \n",
       "2019-03-14  6.439715  6.639943  6.353963  6.526642    7318172\n",
       "2019-03-15  6.633174  7.715249  6.432468  7.504351    6057301\n",
       "2019-03-16  7.507990  8.305615  6.694531  7.383882    3477393\n",
       "2019-03-17  7.357443  7.357443  4.727895  4.776164    2653565\n",
       "2019-03-18  4.828242  5.229982  4.828242  5.110341    2567201\n",
       "...              ...       ...       ...       ...        ...\n",
       "2022-07-12  8.194923  8.384569  7.745732  7.804078  203896723\n",
       "2022-07-13  7.806161  8.208751  7.444185  8.208751  234574531\n",
       "2022-07-14  8.204885  9.024354  8.111207  8.974957  312197850\n",
       "2022-07-15  8.975107  9.459247  8.894743  9.054348  338316025\n",
       "2022-07-16  9.052928  9.340449  8.812980  9.218372  240149001\n",
       "\n",
       "[1221 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coin_set2\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2860 entries, 2014-09-17 to 2022-07-16\n",
      "Freq: D\n",
      "Data columns (total 18 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   (Adj Close, BTC-USD)  2860 non-null   float64\n",
      " 1   (Adj Close, ETH-USD)  1711 non-null   float64\n",
      " 2   (Adj Close, LTC-USD)  2860 non-null   float64\n",
      " 3   (Close, BTC-USD)      2860 non-null   float64\n",
      " 4   (Close, ETH-USD)      1711 non-null   float64\n",
      " 5   (Close, LTC-USD)      2860 non-null   float64\n",
      " 6   (High, BTC-USD)       2860 non-null   float64\n",
      " 7   (High, ETH-USD)       1711 non-null   float64\n",
      " 8   (High, LTC-USD)       2860 non-null   float64\n",
      " 9   (Low, BTC-USD)        2860 non-null   float64\n",
      " 10  (Low, ETH-USD)        1711 non-null   float64\n",
      " 11  (Low, LTC-USD)        2860 non-null   float64\n",
      " 12  (Open, BTC-USD)       2860 non-null   float64\n",
      " 13  (Open, ETH-USD)       1711 non-null   float64\n",
      " 14  (Open, LTC-USD)       2860 non-null   float64\n",
      " 15  (Volume, BTC-USD)     2860 non-null   int64  \n",
      " 16  (Volume, ETH-USD)     1711 non-null   float64\n",
      " 17  (Volume, LTC-USD)     2860 non-null   int64  \n",
      "dtypes: float64(16), int64(2)\n",
      "memory usage: 424.5 KB\n"
     ]
    }
   ],
   "source": [
    "Crypto_Port.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the cryptocurrency data in the Crypto_Port variable as as CSV (Comma Seperate Value) file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Crypto_Port.to_csv(\"Crypto_Port.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Crypto_Port = pd.read_csv(\"Crypto_Port.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Adj Close.1</th>\n",
       "      <th>Adj Close.2</th>\n",
       "      <th>Close</th>\n",
       "      <th>Close.1</th>\n",
       "      <th>Close.2</th>\n",
       "      <th>High</th>\n",
       "      <th>High.1</th>\n",
       "      <th>High.2</th>\n",
       "      <th>Low</th>\n",
       "      <th>Low.1</th>\n",
       "      <th>Low.2</th>\n",
       "      <th>Open</th>\n",
       "      <th>Open.1</th>\n",
       "      <th>Open.2</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Volume.1</th>\n",
       "      <th>Volume.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>BTC-USD</td>\n",
       "      <td>ETH-USD</td>\n",
       "      <td>LTC-USD</td>\n",
       "      <td>BTC-USD</td>\n",
       "      <td>ETH-USD</td>\n",
       "      <td>LTC-USD</td>\n",
       "      <td>BTC-USD</td>\n",
       "      <td>ETH-USD</td>\n",
       "      <td>LTC-USD</td>\n",
       "      <td>BTC-USD</td>\n",
       "      <td>ETH-USD</td>\n",
       "      <td>LTC-USD</td>\n",
       "      <td>BTC-USD</td>\n",
       "      <td>ETH-USD</td>\n",
       "      <td>LTC-USD</td>\n",
       "      <td>BTC-USD</td>\n",
       "      <td>ETH-USD</td>\n",
       "      <td>LTC-USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Date</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-09-17</td>\n",
       "      <td>457.3340148925781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.058549880981445</td>\n",
       "      <td>457.3340148925781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.058549880981445</td>\n",
       "      <td>468.17401123046875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.170770168304443</td>\n",
       "      <td>452.4219970703125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.965950012207031</td>\n",
       "      <td>465.864013671875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.08588981628418</td>\n",
       "      <td>21056800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3071840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-09-18</td>\n",
       "      <td>424.44000244140625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.685229778289795</td>\n",
       "      <td>424.44000244140625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.685229778289795</td>\n",
       "      <td>456.8599853515625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.065430164337158</td>\n",
       "      <td>413.10400390625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.579959869384766</td>\n",
       "      <td>456.8599853515625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.065430164337158</td>\n",
       "      <td>34483200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4569260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-09-19</td>\n",
       "      <td>394.7959899902344</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.327770233154297</td>\n",
       "      <td>394.7959899902344</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.327770233154297</td>\n",
       "      <td>427.8349914550781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.755819797515869</td>\n",
       "      <td>384.5320129394531</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.254350185394287</td>\n",
       "      <td>424.1029968261719</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.687290191650391</td>\n",
       "      <td>37919700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3917450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2841</th>\n",
       "      <td>2022-06-26</td>\n",
       "      <td>21027.294921875</td>\n",
       "      <td>1199.8316650390625</td>\n",
       "      <td>56.87614440917969</td>\n",
       "      <td>21027.294921875</td>\n",
       "      <td>1199.8316650390625</td>\n",
       "      <td>56.87614440917969</td>\n",
       "      <td>21783.724609375</td>\n",
       "      <td>1272.1312255859375</td>\n",
       "      <td>60.300819396972656</td>\n",
       "      <td>21016.26953125</td>\n",
       "      <td>1199.4063720703125</td>\n",
       "      <td>56.87559509277344</td>\n",
       "      <td>21496.494140625</td>\n",
       "      <td>1242.987548828125</td>\n",
       "      <td>58.955406188964844</td>\n",
       "      <td>18027170497</td>\n",
       "      <td>12096607824.0</td>\n",
       "      <td>486759815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2842</th>\n",
       "      <td>2022-06-27</td>\n",
       "      <td>20735.478515625</td>\n",
       "      <td>1193.6806640625</td>\n",
       "      <td>55.92555618286133</td>\n",
       "      <td>20735.478515625</td>\n",
       "      <td>1193.6806640625</td>\n",
       "      <td>55.92555618286133</td>\n",
       "      <td>21478.08984375</td>\n",
       "      <td>1234.1807861328125</td>\n",
       "      <td>58.51468276977539</td>\n",
       "      <td>20620.19921875</td>\n",
       "      <td>1179.79248046875</td>\n",
       "      <td>55.249855041503906</td>\n",
       "      <td>21028.23828125</td>\n",
       "      <td>1199.713134765625</td>\n",
       "      <td>56.86295700073242</td>\n",
       "      <td>20965695707</td>\n",
       "      <td>12492225250.0</td>\n",
       "      <td>456437012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2843</th>\n",
       "      <td>2022-06-28</td>\n",
       "      <td>20280.634765625</td>\n",
       "      <td>1144.5792236328125</td>\n",
       "      <td>52.81161117553711</td>\n",
       "      <td>20280.634765625</td>\n",
       "      <td>1144.5792236328125</td>\n",
       "      <td>52.81161117553711</td>\n",
       "      <td>21164.423828125</td>\n",
       "      <td>1229.739013671875</td>\n",
       "      <td>56.72005081176758</td>\n",
       "      <td>20228.8125</td>\n",
       "      <td>1141.15966796875</td>\n",
       "      <td>52.752288818359375</td>\n",
       "      <td>20731.544921875</td>\n",
       "      <td>1193.2540283203125</td>\n",
       "      <td>55.91389083862305</td>\n",
       "      <td>21381535161</td>\n",
       "      <td>14023205651.0</td>\n",
       "      <td>519374670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2844</th>\n",
       "      <td>2022-06-29</td>\n",
       "      <td>20104.0234375</td>\n",
       "      <td>1098.94384765625</td>\n",
       "      <td>53.42253875732422</td>\n",
       "      <td>20104.0234375</td>\n",
       "      <td>1098.94384765625</td>\n",
       "      <td>53.42253875732422</td>\n",
       "      <td>20364.15625</td>\n",
       "      <td>1152.684814453125</td>\n",
       "      <td>54.23308181762695</td>\n",
       "      <td>19937.791015625</td>\n",
       "      <td>1092.09912109375</td>\n",
       "      <td>51.790496826171875</td>\n",
       "      <td>20281.169921875</td>\n",
       "      <td>1144.5244140625</td>\n",
       "      <td>52.80720138549805</td>\n",
       "      <td>23552740328</td>\n",
       "      <td>15386286815.0</td>\n",
       "      <td>557459009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2845</th>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>19784.7265625</td>\n",
       "      <td>1067.298828125</td>\n",
       "      <td>53.64842987060547</td>\n",
       "      <td>19784.7265625</td>\n",
       "      <td>1067.298828125</td>\n",
       "      <td>53.64842987060547</td>\n",
       "      <td>20141.16015625</td>\n",
       "      <td>1103.6904296875</td>\n",
       "      <td>53.736392974853516</td>\n",
       "      <td>18729.65625</td>\n",
       "      <td>1009.0948486328125</td>\n",
       "      <td>50.4050178527832</td>\n",
       "      <td>20108.3125</td>\n",
       "      <td>1099.3531494140625</td>\n",
       "      <td>53.447410583496094</td>\n",
       "      <td>26267239923</td>\n",
       "      <td>16350755497.0</td>\n",
       "      <td>632075268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2846 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0           Adj Close         Adj Close.1        Adj Close.2  \\\n",
       "0            NaN             BTC-USD             ETH-USD            LTC-USD   \n",
       "1           Date                 NaN                 NaN                NaN   \n",
       "2     2014-09-17   457.3340148925781                 NaN  5.058549880981445   \n",
       "3     2014-09-18  424.44000244140625                 NaN  4.685229778289795   \n",
       "4     2014-09-19   394.7959899902344                 NaN  4.327770233154297   \n",
       "...          ...                 ...                 ...                ...   \n",
       "2841  2022-06-26     21027.294921875  1199.8316650390625  56.87614440917969   \n",
       "2842  2022-06-27     20735.478515625     1193.6806640625  55.92555618286133   \n",
       "2843  2022-06-28     20280.634765625  1144.5792236328125  52.81161117553711   \n",
       "2844  2022-06-29       20104.0234375    1098.94384765625  53.42253875732422   \n",
       "2845  2022-06-30       19784.7265625      1067.298828125  53.64842987060547   \n",
       "\n",
       "                   Close             Close.1            Close.2  \\\n",
       "0                BTC-USD             ETH-USD            LTC-USD   \n",
       "1                    NaN                 NaN                NaN   \n",
       "2      457.3340148925781                 NaN  5.058549880981445   \n",
       "3     424.44000244140625                 NaN  4.685229778289795   \n",
       "4      394.7959899902344                 NaN  4.327770233154297   \n",
       "...                  ...                 ...                ...   \n",
       "2841     21027.294921875  1199.8316650390625  56.87614440917969   \n",
       "2842     20735.478515625     1193.6806640625  55.92555618286133   \n",
       "2843     20280.634765625  1144.5792236328125  52.81161117553711   \n",
       "2844       20104.0234375    1098.94384765625  53.42253875732422   \n",
       "2845       19784.7265625      1067.298828125  53.64842987060547   \n",
       "\n",
       "                    High              High.1              High.2  \\\n",
       "0                BTC-USD             ETH-USD             LTC-USD   \n",
       "1                    NaN                 NaN                 NaN   \n",
       "2     468.17401123046875                 NaN   5.170770168304443   \n",
       "3      456.8599853515625                 NaN   5.065430164337158   \n",
       "4      427.8349914550781                 NaN   4.755819797515869   \n",
       "...                  ...                 ...                 ...   \n",
       "2841     21783.724609375  1272.1312255859375  60.300819396972656   \n",
       "2842      21478.08984375  1234.1807861328125   58.51468276977539   \n",
       "2843     21164.423828125   1229.739013671875   56.72005081176758   \n",
       "2844         20364.15625   1152.684814453125   54.23308181762695   \n",
       "2845      20141.16015625     1103.6904296875  53.736392974853516   \n",
       "\n",
       "                    Low               Low.1               Low.2  \\\n",
       "0               BTC-USD             ETH-USD             LTC-USD   \n",
       "1                   NaN                 NaN                 NaN   \n",
       "2     452.4219970703125                 NaN   4.965950012207031   \n",
       "3       413.10400390625                 NaN   4.579959869384766   \n",
       "4     384.5320129394531                 NaN   4.254350185394287   \n",
       "...                 ...                 ...                 ...   \n",
       "2841     21016.26953125  1199.4063720703125   56.87559509277344   \n",
       "2842     20620.19921875    1179.79248046875  55.249855041503906   \n",
       "2843         20228.8125    1141.15966796875  52.752288818359375   \n",
       "2844    19937.791015625    1092.09912109375  51.790496826171875   \n",
       "2845        18729.65625  1009.0948486328125    50.4050178527832   \n",
       "\n",
       "                   Open              Open.1              Open.2       Volume  \\\n",
       "0               BTC-USD             ETH-USD             LTC-USD      BTC-USD   \n",
       "1                   NaN                 NaN                 NaN          NaN   \n",
       "2      465.864013671875                 NaN    5.08588981628418     21056800   \n",
       "3     456.8599853515625                 NaN   5.065430164337158     34483200   \n",
       "4     424.1029968261719                 NaN   4.687290191650391     37919700   \n",
       "...                 ...                 ...                 ...          ...   \n",
       "2841    21496.494140625   1242.987548828125  58.955406188964844  18027170497   \n",
       "2842     21028.23828125   1199.713134765625   56.86295700073242  20965695707   \n",
       "2843    20731.544921875  1193.2540283203125   55.91389083862305  21381535161   \n",
       "2844    20281.169921875     1144.5244140625   52.80720138549805  23552740328   \n",
       "2845         20108.3125  1099.3531494140625  53.447410583496094  26267239923   \n",
       "\n",
       "           Volume.1   Volume.2  \n",
       "0           ETH-USD    LTC-USD  \n",
       "1               NaN        NaN  \n",
       "2               NaN    3071840  \n",
       "3               NaN    4569260  \n",
       "4               NaN    3917450  \n",
       "...             ...        ...  \n",
       "2841  12096607824.0  486759815  \n",
       "2842  12492225250.0  456437012  \n",
       "2843  14023205651.0  519374670  \n",
       "2844  15386286815.0  557459009  \n",
       "2845  16350755497.0  632075268  \n",
       "\n",
       "[2846 rows x 19 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Crypto_Port"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the data from the Crypto_Port.csv file back into Crypto_Port variable with dates being the index column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\oriyomi\\Desktop\\AI_Workspace\\COM724\\Data Preprocessing.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/oriyomi/Desktop/AI_Workspace/COM724/Data%20Preprocessing.ipynb#ch0000000?line=0'>1</a>\u001b[0m Crypto_Port2 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mCrypto_Port.csv\u001b[39m\u001b[39m\"\u001b[39m, header \u001b[39m=\u001b[39m [\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m], index_col\u001b[39m=\u001b[39m[\u001b[39m0\u001b[39m], parse_dates \u001b[39m=\u001b[39m [\u001b[39m0\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "Crypto_Port2 = pd.read_csv(\"Crypto_Port.csv\", header = [0,1], index_col=[0], parse_dates = [0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pulling out more information using the describe() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">Adj Close</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Close</th>\n",
       "      <th colspan=\"3\" halign=\"left\">High</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Low</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Open</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>BTC-USD</th>\n",
       "      <th>ETH-USD</th>\n",
       "      <th>LTC-USD</th>\n",
       "      <th>BTC-USD</th>\n",
       "      <th>ETH-USD</th>\n",
       "      <th>LTC-USD</th>\n",
       "      <th>BTC-USD</th>\n",
       "      <th>ETH-USD</th>\n",
       "      <th>LTC-USD</th>\n",
       "      <th>BTC-USD</th>\n",
       "      <th>ETH-USD</th>\n",
       "      <th>LTC-USD</th>\n",
       "      <th>BTC-USD</th>\n",
       "      <th>ETH-USD</th>\n",
       "      <th>LTC-USD</th>\n",
       "      <th>BTC-USD</th>\n",
       "      <th>ETH-USD</th>\n",
       "      <th>LTC-USD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2844.000000</td>\n",
       "      <td>1695.000000</td>\n",
       "      <td>2844.000000</td>\n",
       "      <td>2844.000000</td>\n",
       "      <td>1695.000000</td>\n",
       "      <td>2844.000000</td>\n",
       "      <td>2844.000000</td>\n",
       "      <td>1695.000000</td>\n",
       "      <td>2844.000000</td>\n",
       "      <td>2844.000000</td>\n",
       "      <td>1695.000000</td>\n",
       "      <td>2844.000000</td>\n",
       "      <td>2844.000000</td>\n",
       "      <td>1695.000000</td>\n",
       "      <td>2844.000000</td>\n",
       "      <td>2.844000e+03</td>\n",
       "      <td>1.695000e+03</td>\n",
       "      <td>2.844000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12422.233886</td>\n",
       "      <td>1099.738397</td>\n",
       "      <td>67.401271</td>\n",
       "      <td>12422.233886</td>\n",
       "      <td>1099.738397</td>\n",
       "      <td>67.401271</td>\n",
       "      <td>12740.147621</td>\n",
       "      <td>1135.732180</td>\n",
       "      <td>70.097566</td>\n",
       "      <td>12053.700606</td>\n",
       "      <td>1057.752523</td>\n",
       "      <td>64.442875</td>\n",
       "      <td>12417.091835</td>\n",
       "      <td>1099.552493</td>\n",
       "      <td>67.404216</td>\n",
       "      <td>1.540798e+10</td>\n",
       "      <td>1.279550e+10</td>\n",
       "      <td>1.547561e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16595.044603</td>\n",
       "      <td>1245.069868</td>\n",
       "      <td>69.570497</td>\n",
       "      <td>16595.044603</td>\n",
       "      <td>1245.069868</td>\n",
       "      <td>69.570497</td>\n",
       "      <td>17028.421279</td>\n",
       "      <td>1283.913847</td>\n",
       "      <td>73.079538</td>\n",
       "      <td>16101.873540</td>\n",
       "      <td>1201.267838</td>\n",
       "      <td>65.778696</td>\n",
       "      <td>16599.725375</td>\n",
       "      <td>1245.731378</td>\n",
       "      <td>69.616900</td>\n",
       "      <td>1.993426e+10</td>\n",
       "      <td>1.112210e+10</td>\n",
       "      <td>2.262441e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>178.102997</td>\n",
       "      <td>84.308296</td>\n",
       "      <td>1.157010</td>\n",
       "      <td>178.102997</td>\n",
       "      <td>84.308296</td>\n",
       "      <td>1.157010</td>\n",
       "      <td>211.731003</td>\n",
       "      <td>85.342743</td>\n",
       "      <td>1.344810</td>\n",
       "      <td>171.509995</td>\n",
       "      <td>82.829887</td>\n",
       "      <td>1.113740</td>\n",
       "      <td>176.897003</td>\n",
       "      <td>84.279694</td>\n",
       "      <td>1.153240</td>\n",
       "      <td>5.914570e+06</td>\n",
       "      <td>6.217330e+08</td>\n",
       "      <td>4.817140e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>632.335251</td>\n",
       "      <td>201.911812</td>\n",
       "      <td>3.942395</td>\n",
       "      <td>632.335251</td>\n",
       "      <td>201.911812</td>\n",
       "      <td>3.942395</td>\n",
       "      <td>641.147736</td>\n",
       "      <td>206.291725</td>\n",
       "      <td>4.015915</td>\n",
       "      <td>621.927261</td>\n",
       "      <td>196.447502</td>\n",
       "      <td>3.877715</td>\n",
       "      <td>630.784515</td>\n",
       "      <td>201.867546</td>\n",
       "      <td>3.944493</td>\n",
       "      <td>8.610942e+07</td>\n",
       "      <td>3.711635e+09</td>\n",
       "      <td>4.127570e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6547.295166</td>\n",
       "      <td>423.669312</td>\n",
       "      <td>49.604229</td>\n",
       "      <td>6547.295166</td>\n",
       "      <td>423.669312</td>\n",
       "      <td>49.604229</td>\n",
       "      <td>6643.439941</td>\n",
       "      <td>435.457001</td>\n",
       "      <td>51.326406</td>\n",
       "      <td>6449.304932</td>\n",
       "      <td>407.851715</td>\n",
       "      <td>47.784416</td>\n",
       "      <td>6548.199951</td>\n",
       "      <td>422.587006</td>\n",
       "      <td>49.570601</td>\n",
       "      <td>5.782325e+09</td>\n",
       "      <td>1.030311e+10</td>\n",
       "      <td>4.854375e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11489.900146</td>\n",
       "      <td>1871.499451</td>\n",
       "      <td>104.968313</td>\n",
       "      <td>11489.900146</td>\n",
       "      <td>1871.499451</td>\n",
       "      <td>104.968313</td>\n",
       "      <td>11791.881592</td>\n",
       "      <td>1948.870605</td>\n",
       "      <td>108.129725</td>\n",
       "      <td>11225.209473</td>\n",
       "      <td>1794.161377</td>\n",
       "      <td>100.633686</td>\n",
       "      <td>11487.965820</td>\n",
       "      <td>1872.685181</td>\n",
       "      <td>104.954123</td>\n",
       "      <td>2.625181e+10</td>\n",
       "      <td>1.818402e+10</td>\n",
       "      <td>2.508535e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>67566.828125</td>\n",
       "      <td>4812.087402</td>\n",
       "      <td>386.450775</td>\n",
       "      <td>67566.828125</td>\n",
       "      <td>4812.087402</td>\n",
       "      <td>386.450775</td>\n",
       "      <td>68789.625000</td>\n",
       "      <td>4891.704590</td>\n",
       "      <td>412.960144</td>\n",
       "      <td>66382.062500</td>\n",
       "      <td>4718.039062</td>\n",
       "      <td>345.298828</td>\n",
       "      <td>67549.734375</td>\n",
       "      <td>4810.071289</td>\n",
       "      <td>387.869171</td>\n",
       "      <td>3.509679e+11</td>\n",
       "      <td>8.448291e+10</td>\n",
       "      <td>1.799426e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Adj Close                                   Close               \\\n",
       "            BTC-USD      ETH-USD      LTC-USD       BTC-USD      ETH-USD   \n",
       "count   2844.000000  1695.000000  2844.000000   2844.000000  1695.000000   \n",
       "mean   12422.233886  1099.738397    67.401271  12422.233886  1099.738397   \n",
       "std    16595.044603  1245.069868    69.570497  16595.044603  1245.069868   \n",
       "min      178.102997    84.308296     1.157010    178.102997    84.308296   \n",
       "25%      632.335251   201.911812     3.942395    632.335251   201.911812   \n",
       "50%     6547.295166   423.669312    49.604229   6547.295166   423.669312   \n",
       "75%    11489.900146  1871.499451   104.968313  11489.900146  1871.499451   \n",
       "max    67566.828125  4812.087402   386.450775  67566.828125  4812.087402   \n",
       "\n",
       "                            High                                     Low  \\\n",
       "           LTC-USD       BTC-USD      ETH-USD      LTC-USD       BTC-USD   \n",
       "count  2844.000000   2844.000000  1695.000000  2844.000000   2844.000000   \n",
       "mean     67.401271  12740.147621  1135.732180    70.097566  12053.700606   \n",
       "std      69.570497  17028.421279  1283.913847    73.079538  16101.873540   \n",
       "min       1.157010    211.731003    85.342743     1.344810    171.509995   \n",
       "25%       3.942395    641.147736   206.291725     4.015915    621.927261   \n",
       "50%      49.604229   6643.439941   435.457001    51.326406   6449.304932   \n",
       "75%     104.968313  11791.881592  1948.870605   108.129725  11225.209473   \n",
       "max     386.450775  68789.625000  4891.704590   412.960144  66382.062500   \n",
       "\n",
       "                                         Open                            \\\n",
       "           ETH-USD      LTC-USD       BTC-USD      ETH-USD      LTC-USD   \n",
       "count  1695.000000  2844.000000   2844.000000  1695.000000  2844.000000   \n",
       "mean   1057.752523    64.442875  12417.091835  1099.552493    67.404216   \n",
       "std    1201.267838    65.778696  16599.725375  1245.731378    69.616900   \n",
       "min      82.829887     1.113740    176.897003    84.279694     1.153240   \n",
       "25%     196.447502     3.877715    630.784515   201.867546     3.944493   \n",
       "50%     407.851715    47.784416   6548.199951   422.587006    49.570601   \n",
       "75%    1794.161377   100.633686  11487.965820  1872.685181   104.954123   \n",
       "max    4718.039062   345.298828  67549.734375  4810.071289   387.869171   \n",
       "\n",
       "             Volume                              \n",
       "            BTC-USD       ETH-USD       LTC-USD  \n",
       "count  2.844000e+03  1.695000e+03  2.844000e+03  \n",
       "mean   1.540798e+10  1.279550e+10  1.547561e+09  \n",
       "std    1.993426e+10  1.112210e+10  2.262441e+09  \n",
       "min    5.914570e+06  6.217330e+08  4.817140e+05  \n",
       "25%    8.610942e+07  3.711635e+09  4.127570e+06  \n",
       "50%    5.782325e+09  1.030311e+10  4.854375e+08  \n",
       "75%    2.625181e+10  1.818402e+10  2.508535e+09  \n",
       "max    3.509679e+11  8.448291e+10  1.799426e+10  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Crypto_Port2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping the \"NAN\" (Not A Number) values from the \"Close\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "CryptoClose = Crypto_Port2.loc[:,\"Close\"].copy().dropna()CryptoClose.to_csv(\"CryptoClose.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BTC-USD</th>\n",
       "      <th>ETH-USD</th>\n",
       "      <th>LTC-USD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-09</th>\n",
       "      <td>7143.580078</td>\n",
       "      <td>320.884003</td>\n",
       "      <td>64.269699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-10</th>\n",
       "      <td>6618.140137</td>\n",
       "      <td>299.252991</td>\n",
       "      <td>59.260101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11</th>\n",
       "      <td>6357.600098</td>\n",
       "      <td>314.681000</td>\n",
       "      <td>62.303299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-12</th>\n",
       "      <td>5950.069824</td>\n",
       "      <td>307.907990</td>\n",
       "      <td>59.005402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-13</th>\n",
       "      <td>6559.490234</td>\n",
       "      <td>316.716003</td>\n",
       "      <td>61.396500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-26</th>\n",
       "      <td>21027.294922</td>\n",
       "      <td>1199.831665</td>\n",
       "      <td>56.876144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-27</th>\n",
       "      <td>20735.478516</td>\n",
       "      <td>1193.680664</td>\n",
       "      <td>55.925556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-28</th>\n",
       "      <td>20280.634766</td>\n",
       "      <td>1144.579224</td>\n",
       "      <td>52.811611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-29</th>\n",
       "      <td>20104.023438</td>\n",
       "      <td>1098.943848</td>\n",
       "      <td>53.422539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-30</th>\n",
       "      <td>19784.726562</td>\n",
       "      <td>1067.298828</td>\n",
       "      <td>53.648430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1695 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 BTC-USD      ETH-USD    LTC-USD\n",
       "Date                                            \n",
       "2017-11-09   7143.580078   320.884003  64.269699\n",
       "2017-11-10   6618.140137   299.252991  59.260101\n",
       "2017-11-11   6357.600098   314.681000  62.303299\n",
       "2017-11-12   5950.069824   307.907990  59.005402\n",
       "2017-11-13   6559.490234   316.716003  61.396500\n",
       "...                  ...          ...        ...\n",
       "2022-06-26  21027.294922  1199.831665  56.876144\n",
       "2022-06-27  20735.478516  1193.680664  55.925556\n",
       "2022-06-28  20280.634766  1144.579224  52.811611\n",
       "2022-06-29  20104.023438  1098.943848  53.422539\n",
       "2022-06-30  19784.726562  1067.298828  53.648430\n",
       "\n",
       "[1695 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CryptoClose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the data inside the CryptoClose Variable in a new csv file naming it CryptoClose.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "CryptoClose.to_csv(\"CryptoClose.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the data stored in CryptoClose variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "CryptoClose.plot(figsize = (15,8) , fontsize = 13)\n",
    "plt.legend(fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "CryptoClose = pd.read_csv(\"CryptoClose.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the CrptoClose CSV file and storing it to the close variable with dates as the index column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "close = pd.read_csv(\"CryptoClose.csv\", index_col=[0],parse_dates=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "selecting the BTC-USD column (column index = 0), converting it into a dataframe and putting it equal to btc variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "btc =  close.iloc[:,0].copy().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BTC-USD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-09</th>\n",
       "      <td>7143.580078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-10</th>\n",
       "      <td>6618.140137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11</th>\n",
       "      <td>6357.600098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-12</th>\n",
       "      <td>5950.069824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-13</th>\n",
       "      <td>6559.490234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-26</th>\n",
       "      <td>21027.294922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-27</th>\n",
       "      <td>20735.478516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-28</th>\n",
       "      <td>20280.634766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-29</th>\n",
       "      <td>20104.023438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-30</th>\n",
       "      <td>19784.726562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1695 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 BTC-USD\n",
       "Date                    \n",
       "2017-11-09   7143.580078\n",
       "2017-11-10   6618.140137\n",
       "2017-11-11   6357.600098\n",
       "2017-11-12   5950.069824\n",
       "2017-11-13   6559.490234\n",
       "...                  ...\n",
       "2022-06-26  21027.294922\n",
       "2022-06-27  20735.478516\n",
       "2022-06-28  20280.634766\n",
       "2022-06-29  20104.023438\n",
       "2022-06-30  19784.726562\n",
       "\n",
       "[1695 rows x 1 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the percent change and dropping the NAN (Not A Number) values simultaneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BTC-USD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-10</th>\n",
       "      <td>-0.073554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11</th>\n",
       "      <td>-0.039368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-12</th>\n",
       "      <td>-0.064101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-13</th>\n",
       "      <td>0.102422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-14</th>\n",
       "      <td>0.011626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-26</th>\n",
       "      <td>-0.022093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-27</th>\n",
       "      <td>-0.013878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-28</th>\n",
       "      <td>-0.021936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-29</th>\n",
       "      <td>-0.008708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-30</th>\n",
       "      <td>-0.015882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1694 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             BTC-USD\n",
       "Date                \n",
       "2017-11-10 -0.073554\n",
       "2017-11-11 -0.039368\n",
       "2017-11-12 -0.064101\n",
       "2017-11-13  0.102422\n",
       "2017-11-14  0.011626\n",
       "...              ...\n",
       "2022-06-26 -0.022093\n",
       "2022-06-27 -0.013878\n",
       "2022-06-28 -0.021936\n",
       "2022-06-29 -0.008708\n",
       "2022-06-30 -0.015882\n",
       "\n",
       "[1694 rows x 1 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btc.pct_change().dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the return variable holding the returns from bitcoin usd crypto pair and reading the first five rows stored in the ret variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BTC-USD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-10</th>\n",
       "      <td>-0.073554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11</th>\n",
       "      <td>-0.039368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-12</th>\n",
       "      <td>-0.064101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-13</th>\n",
       "      <td>0.102422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-14</th>\n",
       "      <td>0.011626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             BTC-USD\n",
       "Date                \n",
       "2017-11-10 -0.073554\n",
       "2017-11-11 -0.039368\n",
       "2017-11-12 -0.064101\n",
       "2017-11-13  0.102422\n",
       "2017-11-14  0.011626"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret = btc.pct_change().dropna()\n",
    "ret.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the return data (in the ret variable) as a histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ret.plot(kind=\"hist\", figsize = (12,8), bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTC-USD    0.001447\n",
      "dtype: float64 daily mean return\n",
      "BTC-USD    0.001673\n",
      "dtype: float64 return variance\n",
      "BTC-USD    0.528225\n",
      "dtype: float64 annual mean return\n"
     ]
    }
   ],
   "source": [
    "daily_mean_ret = ret.mean()\n",
    "print(daily_mean_ret, 'daily mean return')\n",
    "\n",
    "## Finding out the variance of daily returns\n",
    "var_daily_ret =ret.var()\n",
    "print(var_daily_ret, 'return variance')\n",
    "\n",
    "## Finding out the Standard Deviation\n",
    "ret.std()\n",
    "\n",
    "# Finding the annal mean return\n",
    "ann_mean_ret = ret.mean() * 365\n",
    "print(ann_mean_ret, 'annual mean return')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BTC-USD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-09</th>\n",
       "      <td>7143.580078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-10</th>\n",
       "      <td>6618.140137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11</th>\n",
       "      <td>6357.600098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-12</th>\n",
       "      <td>5950.069824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-13</th>\n",
       "      <td>6559.490234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-26</th>\n",
       "      <td>21027.294922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-27</th>\n",
       "      <td>20735.478516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-28</th>\n",
       "      <td>20280.634766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-29</th>\n",
       "      <td>20104.023438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-30</th>\n",
       "      <td>19784.726562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1695 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 BTC-USD\n",
       "Date                    \n",
       "2017-11-09   7143.580078\n",
       "2017-11-10   6618.140137\n",
       "2017-11-11   6357.600098\n",
       "2017-11-12   5950.069824\n",
       "2017-11-13   6559.490234\n",
       "...                  ...\n",
       "2022-06-26  21027.294922\n",
       "2022-06-27  20735.478516\n",
       "2022-06-28  20280.634766\n",
       "2022-06-29  20104.023438\n",
       "2022-06-30  19784.726562\n",
       "\n",
       "[1695 rows x 1 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BTC-USD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-09</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-10</th>\n",
       "      <td>7143.580078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11</th>\n",
       "      <td>6618.140137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-12</th>\n",
       "      <td>6357.600098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-13</th>\n",
       "      <td>5950.069824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-26</th>\n",
       "      <td>21502.337891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-27</th>\n",
       "      <td>21027.294922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-28</th>\n",
       "      <td>20735.478516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-29</th>\n",
       "      <td>20280.634766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-30</th>\n",
       "      <td>20104.023438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1695 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 BTC-USD\n",
       "Date                    \n",
       "2017-11-09           NaN\n",
       "2017-11-10   7143.580078\n",
       "2017-11-11   6618.140137\n",
       "2017-11-12   6357.600098\n",
       "2017-11-13   5950.069824\n",
       "...                  ...\n",
       "2022-06-26  21502.337891\n",
       "2022-06-27  21027.294922\n",
       "2022-06-28  20735.478516\n",
       "2022-06-29  20280.634766\n",
       "2022-06-30  20104.023438\n",
       "\n",
       "[1695 rows x 1 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btc.shift(periods=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "btc[\"lag1\"] = btc.shift(periods = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BTC-USD</th>\n",
       "      <th>lag1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-09</th>\n",
       "      <td>7143.580078</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-10</th>\n",
       "      <td>6618.140137</td>\n",
       "      <td>7143.580078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11</th>\n",
       "      <td>6357.600098</td>\n",
       "      <td>6618.140137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-12</th>\n",
       "      <td>5950.069824</td>\n",
       "      <td>6357.600098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-13</th>\n",
       "      <td>6559.490234</td>\n",
       "      <td>5950.069824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-26</th>\n",
       "      <td>21027.294922</td>\n",
       "      <td>21502.337891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-27</th>\n",
       "      <td>20735.478516</td>\n",
       "      <td>21027.294922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-28</th>\n",
       "      <td>20280.634766</td>\n",
       "      <td>20735.478516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-29</th>\n",
       "      <td>20104.023438</td>\n",
       "      <td>20280.634766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-30</th>\n",
       "      <td>19784.726562</td>\n",
       "      <td>20104.023438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1695 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 BTC-USD          lag1\n",
       "Date                                  \n",
       "2017-11-09   7143.580078           NaN\n",
       "2017-11-10   6618.140137   7143.580078\n",
       "2017-11-11   6357.600098   6618.140137\n",
       "2017-11-12   5950.069824   6357.600098\n",
       "2017-11-13   6559.490234   5950.069824\n",
       "...                  ...           ...\n",
       "2022-06-26  21027.294922  21502.337891\n",
       "2022-06-27  20735.478516  21027.294922\n",
       "2022-06-28  20280.634766  20735.478516\n",
       "2022-06-29  20104.023438  20280.634766\n",
       "2022-06-30  19784.726562  20104.023438\n",
       "\n",
       "[1695 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "btc[\"Diff\"] = btc.iloc[:,0].sub(btc.lag1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BTC-USD</th>\n",
       "      <th>lag1</th>\n",
       "      <th>Diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-09</th>\n",
       "      <td>7143.580078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-10</th>\n",
       "      <td>6618.140137</td>\n",
       "      <td>7143.580078</td>\n",
       "      <td>-525.439941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11</th>\n",
       "      <td>6357.600098</td>\n",
       "      <td>6618.140137</td>\n",
       "      <td>-260.540039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-12</th>\n",
       "      <td>5950.069824</td>\n",
       "      <td>6357.600098</td>\n",
       "      <td>-407.530273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-13</th>\n",
       "      <td>6559.490234</td>\n",
       "      <td>5950.069824</td>\n",
       "      <td>609.420410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-26</th>\n",
       "      <td>21027.294922</td>\n",
       "      <td>21502.337891</td>\n",
       "      <td>-475.042969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-27</th>\n",
       "      <td>20735.478516</td>\n",
       "      <td>21027.294922</td>\n",
       "      <td>-291.816406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-28</th>\n",
       "      <td>20280.634766</td>\n",
       "      <td>20735.478516</td>\n",
       "      <td>-454.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-29</th>\n",
       "      <td>20104.023438</td>\n",
       "      <td>20280.634766</td>\n",
       "      <td>-176.611328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-30</th>\n",
       "      <td>19784.726562</td>\n",
       "      <td>20104.023438</td>\n",
       "      <td>-319.296875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1695 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 BTC-USD          lag1        Diff\n",
       "Date                                              \n",
       "2017-11-09   7143.580078           NaN         NaN\n",
       "2017-11-10   6618.140137   7143.580078 -525.439941\n",
       "2017-11-11   6357.600098   6618.140137 -260.540039\n",
       "2017-11-12   5950.069824   6357.600098 -407.530273\n",
       "2017-11-13   6559.490234   5950.069824  609.420410\n",
       "...                  ...           ...         ...\n",
       "2022-06-26  21027.294922  21502.337891 -475.042969\n",
       "2022-06-27  20735.478516  21027.294922 -291.816406\n",
       "2022-06-28  20280.634766  20735.478516 -454.843750\n",
       "2022-06-29  20104.023438  20280.634766 -176.611328\n",
       "2022-06-30  19784.726562  20104.023438 -319.296875\n",
       "\n",
       "[1695 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The daily percent changes or returns given in the following\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BTC-USD</th>\n",
       "      <th>lag1</th>\n",
       "      <th>Diff</th>\n",
       "      <th>pct_change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-09</th>\n",
       "      <td>7143.580078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-10</th>\n",
       "      <td>6618.140137</td>\n",
       "      <td>7143.580078</td>\n",
       "      <td>-525.439941</td>\n",
       "      <td>-7.355415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11</th>\n",
       "      <td>6357.600098</td>\n",
       "      <td>6618.140137</td>\n",
       "      <td>-260.540039</td>\n",
       "      <td>-3.936756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-12</th>\n",
       "      <td>5950.069824</td>\n",
       "      <td>6357.600098</td>\n",
       "      <td>-407.530273</td>\n",
       "      <td>-6.410128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-13</th>\n",
       "      <td>6559.490234</td>\n",
       "      <td>5950.069824</td>\n",
       "      <td>609.420410</td>\n",
       "      <td>10.242240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-26</th>\n",
       "      <td>21027.294922</td>\n",
       "      <td>21502.337891</td>\n",
       "      <td>-475.042969</td>\n",
       "      <td>-2.209262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-27</th>\n",
       "      <td>20735.478516</td>\n",
       "      <td>21027.294922</td>\n",
       "      <td>-291.816406</td>\n",
       "      <td>-1.387798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-28</th>\n",
       "      <td>20280.634766</td>\n",
       "      <td>20735.478516</td>\n",
       "      <td>-454.843750</td>\n",
       "      <td>-2.193553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-29</th>\n",
       "      <td>20104.023438</td>\n",
       "      <td>20280.634766</td>\n",
       "      <td>-176.611328</td>\n",
       "      <td>-0.870837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-30</th>\n",
       "      <td>19784.726562</td>\n",
       "      <td>20104.023438</td>\n",
       "      <td>-319.296875</td>\n",
       "      <td>-1.588224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1695 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 BTC-USD          lag1        Diff  pct_change\n",
       "Date                                                          \n",
       "2017-11-09   7143.580078           NaN         NaN         NaN\n",
       "2017-11-10   6618.140137   7143.580078 -525.439941   -7.355415\n",
       "2017-11-11   6357.600098   6618.140137 -260.540039   -3.936756\n",
       "2017-11-12   5950.069824   6357.600098 -407.530273   -6.410128\n",
       "2017-11-13   6559.490234   5950.069824  609.420410   10.242240\n",
       "...                  ...           ...         ...         ...\n",
       "2022-06-26  21027.294922  21502.337891 -475.042969   -2.209262\n",
       "2022-06-27  20735.478516  21027.294922 -291.816406   -1.387798\n",
       "2022-06-28  20280.634766  20735.478516 -454.843750   -2.193553\n",
       "2022-06-29  20104.023438  20280.634766 -176.611328   -0.870837\n",
       "2022-06-30  19784.726562  20104.023438 -319.296875   -1.588224\n",
       "\n",
       "[1695 rows x 4 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btc[\"pct_change\"] = btc.iloc[:,0].div(btc.lag1).sub(1).mul(100) \n",
    "btc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BTC-USD</th>\n",
       "      <th>lag1</th>\n",
       "      <th>Diff</th>\n",
       "      <th>pct_change</th>\n",
       "      <th>Diff2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-09</th>\n",
       "      <td>7143.580078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-10</th>\n",
       "      <td>6618.140137</td>\n",
       "      <td>7143.580078</td>\n",
       "      <td>-525.439941</td>\n",
       "      <td>-7.355415</td>\n",
       "      <td>-525.439941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11</th>\n",
       "      <td>6357.600098</td>\n",
       "      <td>6618.140137</td>\n",
       "      <td>-260.540039</td>\n",
       "      <td>-3.936756</td>\n",
       "      <td>-260.540039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-12</th>\n",
       "      <td>5950.069824</td>\n",
       "      <td>6357.600098</td>\n",
       "      <td>-407.530273</td>\n",
       "      <td>-6.410128</td>\n",
       "      <td>-407.530273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-13</th>\n",
       "      <td>6559.490234</td>\n",
       "      <td>5950.069824</td>\n",
       "      <td>609.420410</td>\n",
       "      <td>10.242240</td>\n",
       "      <td>609.420410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-26</th>\n",
       "      <td>21027.294922</td>\n",
       "      <td>21502.337891</td>\n",
       "      <td>-475.042969</td>\n",
       "      <td>-2.209262</td>\n",
       "      <td>-475.042969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-27</th>\n",
       "      <td>20735.478516</td>\n",
       "      <td>21027.294922</td>\n",
       "      <td>-291.816406</td>\n",
       "      <td>-1.387798</td>\n",
       "      <td>-291.816406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-28</th>\n",
       "      <td>20280.634766</td>\n",
       "      <td>20735.478516</td>\n",
       "      <td>-454.843750</td>\n",
       "      <td>-2.193553</td>\n",
       "      <td>-454.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-29</th>\n",
       "      <td>20104.023438</td>\n",
       "      <td>20280.634766</td>\n",
       "      <td>-176.611328</td>\n",
       "      <td>-0.870837</td>\n",
       "      <td>-176.611328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-30</th>\n",
       "      <td>19784.726562</td>\n",
       "      <td>20104.023438</td>\n",
       "      <td>-319.296875</td>\n",
       "      <td>-1.588224</td>\n",
       "      <td>-319.296875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1695 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 BTC-USD          lag1        Diff  pct_change       Diff2\n",
       "Date                                                                      \n",
       "2017-11-09   7143.580078           NaN         NaN         NaN         NaN\n",
       "2017-11-10   6618.140137   7143.580078 -525.439941   -7.355415 -525.439941\n",
       "2017-11-11   6357.600098   6618.140137 -260.540039   -3.936756 -260.540039\n",
       "2017-11-12   5950.069824   6357.600098 -407.530273   -6.410128 -407.530273\n",
       "2017-11-13   6559.490234   5950.069824  609.420410   10.242240  609.420410\n",
       "...                  ...           ...         ...         ...         ...\n",
       "2022-06-26  21027.294922  21502.337891 -475.042969   -2.209262 -475.042969\n",
       "2022-06-27  20735.478516  21027.294922 -291.816406   -1.387798 -291.816406\n",
       "2022-06-28  20280.634766  20735.478516 -454.843750   -2.193553 -454.843750\n",
       "2022-06-29  20104.023438  20280.634766 -176.611328   -0.870837 -176.611328\n",
       "2022-06-30  19784.726562  20104.023438 -319.296875   -1.588224 -319.296875\n",
       "\n",
       "[1695 rows x 5 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btc[\"Diff2\"] = btc.iloc[:,0].diff(periods=1)\n",
    "btc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BTC-USD</th>\n",
       "      <th>lag1</th>\n",
       "      <th>Diff</th>\n",
       "      <th>pct_change</th>\n",
       "      <th>Diff2</th>\n",
       "      <th>pct_change2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-09</th>\n",
       "      <td>7143.580078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-10</th>\n",
       "      <td>6618.140137</td>\n",
       "      <td>7143.580078</td>\n",
       "      <td>-525.439941</td>\n",
       "      <td>-7.355415</td>\n",
       "      <td>-525.439941</td>\n",
       "      <td>-7.355415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11</th>\n",
       "      <td>6357.600098</td>\n",
       "      <td>6618.140137</td>\n",
       "      <td>-260.540039</td>\n",
       "      <td>-3.936756</td>\n",
       "      <td>-260.540039</td>\n",
       "      <td>-3.936756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-12</th>\n",
       "      <td>5950.069824</td>\n",
       "      <td>6357.600098</td>\n",
       "      <td>-407.530273</td>\n",
       "      <td>-6.410128</td>\n",
       "      <td>-407.530273</td>\n",
       "      <td>-6.410128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-13</th>\n",
       "      <td>6559.490234</td>\n",
       "      <td>5950.069824</td>\n",
       "      <td>609.420410</td>\n",
       "      <td>10.242240</td>\n",
       "      <td>609.420410</td>\n",
       "      <td>10.242240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-26</th>\n",
       "      <td>21027.294922</td>\n",
       "      <td>21502.337891</td>\n",
       "      <td>-475.042969</td>\n",
       "      <td>-2.209262</td>\n",
       "      <td>-475.042969</td>\n",
       "      <td>-2.209262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-27</th>\n",
       "      <td>20735.478516</td>\n",
       "      <td>21027.294922</td>\n",
       "      <td>-291.816406</td>\n",
       "      <td>-1.387798</td>\n",
       "      <td>-291.816406</td>\n",
       "      <td>-1.387798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-28</th>\n",
       "      <td>20280.634766</td>\n",
       "      <td>20735.478516</td>\n",
       "      <td>-454.843750</td>\n",
       "      <td>-2.193553</td>\n",
       "      <td>-454.843750</td>\n",
       "      <td>-2.193553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-29</th>\n",
       "      <td>20104.023438</td>\n",
       "      <td>20280.634766</td>\n",
       "      <td>-176.611328</td>\n",
       "      <td>-0.870837</td>\n",
       "      <td>-176.611328</td>\n",
       "      <td>-0.870837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-30</th>\n",
       "      <td>19784.726562</td>\n",
       "      <td>20104.023438</td>\n",
       "      <td>-319.296875</td>\n",
       "      <td>-1.588224</td>\n",
       "      <td>-319.296875</td>\n",
       "      <td>-1.588224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1695 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 BTC-USD          lag1        Diff  pct_change       Diff2  \\\n",
       "Date                                                                         \n",
       "2017-11-09   7143.580078           NaN         NaN         NaN         NaN   \n",
       "2017-11-10   6618.140137   7143.580078 -525.439941   -7.355415 -525.439941   \n",
       "2017-11-11   6357.600098   6618.140137 -260.540039   -3.936756 -260.540039   \n",
       "2017-11-12   5950.069824   6357.600098 -407.530273   -6.410128 -407.530273   \n",
       "2017-11-13   6559.490234   5950.069824  609.420410   10.242240  609.420410   \n",
       "...                  ...           ...         ...         ...         ...   \n",
       "2022-06-26  21027.294922  21502.337891 -475.042969   -2.209262 -475.042969   \n",
       "2022-06-27  20735.478516  21027.294922 -291.816406   -1.387798 -291.816406   \n",
       "2022-06-28  20280.634766  20735.478516 -454.843750   -2.193553 -454.843750   \n",
       "2022-06-29  20104.023438  20280.634766 -176.611328   -0.870837 -176.611328   \n",
       "2022-06-30  19784.726562  20104.023438 -319.296875   -1.588224 -319.296875   \n",
       "\n",
       "            pct_change2  \n",
       "Date                     \n",
       "2017-11-09          NaN  \n",
       "2017-11-10    -7.355415  \n",
       "2017-11-11    -3.936756  \n",
       "2017-11-12    -6.410128  \n",
       "2017-11-13    10.242240  \n",
       "...                 ...  \n",
       "2022-06-26    -2.209262  \n",
       "2022-06-27    -1.387798  \n",
       "2022-06-28    -2.193553  \n",
       "2022-06-29    -0.870837  \n",
       "2022-06-30    -1.588224  \n",
       "\n",
       "[1695 rows x 6 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btc[\"pct_change2\"] = btc.iloc[:,0].pct_change(periods=1).mul(100)\n",
    "btc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating Monthly change or return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2017-11-30          NaN\n",
       "2017-12-31    38.332561\n",
       "2018-01-31   -27.798739\n",
       "2018-02-28     1.729763\n",
       "2018-03-31   -32.933289\n",
       "2018-04-30    32.508931\n",
       "2018-05-31   -18.899091\n",
       "2018-06-30   -14.546907\n",
       "2018-07-31    21.493441\n",
       "2018-08-31    -9.547787\n",
       "2018-09-30    -5.854570\n",
       "2018-10-31    -4.647912\n",
       "2018-11-30   -36.411576\n",
       "2018-12-31    -6.834697\n",
       "2019-01-31    -7.612357\n",
       "2019-02-28    11.481101\n",
       "2019-03-31     6.501501\n",
       "2019-04-30    30.333730\n",
       "2019-05-31    60.249302\n",
       "2019-06-30    26.154911\n",
       "2019-07-31    -6.762659\n",
       "2019-08-31    -4.511012\n",
       "2019-09-30   -13.880620\n",
       "2019-10-31    10.920318\n",
       "2019-11-30   -17.717702\n",
       "2019-12-31    -4.967624\n",
       "2020-01-31    29.984020\n",
       "2020-02-29    -8.031850\n",
       "2020-03-31   -25.127764\n",
       "2020-04-30    34.477896\n",
       "2020-05-31     9.268348\n",
       "2020-06-30    -3.414686\n",
       "2020-07-31    23.916341\n",
       "2020-08-31     3.155867\n",
       "2020-09-30    -7.673512\n",
       "2020-10-31    27.785306\n",
       "2020-11-30    42.412328\n",
       "2020-12-31    47.773174\n",
       "2021-01-31    14.180671\n",
       "2021-02-28    36.308751\n",
       "2021-03-31    30.531111\n",
       "2021-04-30    -1.983502\n",
       "2021-05-31   -35.354560\n",
       "2021-06-30    -6.139417\n",
       "2021-07-31    18.793385\n",
       "2021-08-31    13.310110\n",
       "2021-09-30    -7.157155\n",
       "2021-10-31    40.026729\n",
       "2021-11-30    -7.034580\n",
       "2021-12-31   -18.768355\n",
       "2022-01-31   -16.894668\n",
       "2022-02-28    12.239415\n",
       "2022-03-31     5.430113\n",
       "2022-04-30   -17.180563\n",
       "2022-05-31   -15.703524\n",
       "2022-06-30   -37.768831\n",
       "Freq: M, Name: BTC-USD, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btc.iloc[:,0].resample(\"M\").last().pct_change(periods=1).mul(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BTC-USD    7143.580078\n",
       "ETH-USD     320.884003\n",
       "LTC-USD      64.269699\n",
       "Name: 2017-11-09 00:00:00, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "close.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = close.div(close.iloc[0]).mul(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BTC-USD</th>\n",
       "      <th>ETH-USD</th>\n",
       "      <th>LTC-USD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-09</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-10</th>\n",
       "      <td>92.644585</td>\n",
       "      <td>93.258931</td>\n",
       "      <td>92.205351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11</th>\n",
       "      <td>88.997394</td>\n",
       "      <td>98.066902</td>\n",
       "      <td>96.940393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-12</th>\n",
       "      <td>83.292547</td>\n",
       "      <td>95.956167</td>\n",
       "      <td>91.809052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-13</th>\n",
       "      <td>91.823570</td>\n",
       "      <td>98.701088</td>\n",
       "      <td>95.529465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-26</th>\n",
       "      <td>294.352337</td>\n",
       "      <td>373.914454</td>\n",
       "      <td>88.496049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-27</th>\n",
       "      <td>290.267321</td>\n",
       "      <td>371.997561</td>\n",
       "      <td>87.016988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-28</th>\n",
       "      <td>283.900153</td>\n",
       "      <td>356.695633</td>\n",
       "      <td>82.171866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-29</th>\n",
       "      <td>281.427845</td>\n",
       "      <td>342.473865</td>\n",
       "      <td>83.122435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-30</th>\n",
       "      <td>276.958141</td>\n",
       "      <td>332.612040</td>\n",
       "      <td>83.473909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1695 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               BTC-USD     ETH-USD     LTC-USD\n",
       "Date                                          \n",
       "2017-11-09  100.000000  100.000000  100.000000\n",
       "2017-11-10   92.644585   93.258931   92.205351\n",
       "2017-11-11   88.997394   98.066902   96.940393\n",
       "2017-11-12   83.292547   95.956167   91.809052\n",
       "2017-11-13   91.823570   98.701088   95.529465\n",
       "...                ...         ...         ...\n",
       "2022-06-26  294.352337  373.914454   88.496049\n",
       "2022-06-27  290.267321  371.997561   87.016988\n",
       "2022-06-28  283.900153  356.695633   82.171866\n",
       "2022-06-29  281.427845  342.473865   83.122435\n",
       "2022-06-30  276.958141  332.612040   83.473909\n",
       "\n",
       "[1695 rows x 3 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "norm.plot(figsize=(15,8), fontsize=13)\n",
    "plt.legend(fontsize=13)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             BTC-USD   ETH-USD   LTC-USD\n",
      "Date                                    \n",
      "2017-11-10 -0.073554 -0.067411 -0.077946\n",
      "2017-11-11 -0.039368  0.051555  0.051353\n",
      "2017-11-12 -0.064101 -0.021523 -0.052933\n",
      "2017-11-13  0.102422  0.028606  0.040523\n",
      "2017-11-14  0.011626  0.066037  0.020899\n",
      "...              ...       ...       ...\n",
      "2022-06-26 -0.022093 -0.035076 -0.035506\n",
      "2022-06-27 -0.013878 -0.005127 -0.016713\n",
      "2022-06-28 -0.021936 -0.041134 -0.055680\n",
      "2022-06-29 -0.008708 -0.039871  0.011568\n",
      "2022-06-30 -0.015882 -0.028796  0.004228\n",
      "\n",
      "[1694 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Return\n",
    "ret = close.pct_change().dropna()\n",
    "print(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BTC-USD</th>\n",
       "      <th>ETH-USD</th>\n",
       "      <th>LTC-USD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BTC-USD</th>\n",
       "      <td>0.001673</td>\n",
       "      <td>0.001605</td>\n",
       "      <td>0.001718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ETH-USD</th>\n",
       "      <td>0.001605</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.002363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LTC-USD</th>\n",
       "      <td>0.001718</td>\n",
       "      <td>0.002363</td>\n",
       "      <td>0.003252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          BTC-USD   ETH-USD   LTC-USD\n",
       "BTC-USD  0.001673  0.001605  0.001718\n",
       "ETH-USD  0.001605  0.002625  0.002363\n",
       "LTC-USD  0.001718  0.002363  0.003252"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret.cov()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BTC-USD</th>\n",
       "      <th>ETH-USD</th>\n",
       "      <th>LTC-USD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BTC-USD</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.765910</td>\n",
       "      <td>0.736703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ETH-USD</th>\n",
       "      <td>0.765910</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.808672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LTC-USD</th>\n",
       "      <td>0.736703</td>\n",
       "      <td>0.808672</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          BTC-USD   ETH-USD   LTC-USD\n",
       "BTC-USD  1.000000  0.765910  0.736703\n",
       "ETH-USD  0.765910  1.000000  0.808672\n",
       "LTC-USD  0.736703  0.808672  1.000000"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqYAAAHjCAYAAADxBt3dAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABURklEQVR4nO3deVyVZfrH8e8BRRAERBQVFLdcwn3BJVSmLLVmKnNa1NzXXFocS8ls0hZTm0FLM3clrcwlS0fNEUvb1LTSmUpzQUFxR0VQBA7n94c/z3g6cHhSHjjC5/16ndfE/dzPzXXOnOzyupfHYrPZbAIAAACKmEdRBwAAAABIJKYAAABwEySmAAAAcAskpgAAAHALJKYAAABwCySmAAAAcAskpgAAACXcr7/+qoiICJ08edJlv/T0dE2cOFF33XWXmjVrpsGDB+vIkSMOfbKzszV9+nR17NhRTZo0Uc+ePbV3715DcZCYAgAAlGCHDh3S0KFDlZ2dnW/f5557Ths3btSYMWM0ZcoUnTp1Sn369NGlS5fsfV5//XUtXrxYgwcPVmxsrDw9PdWvXz8lJSXlOz6JKQAAQAmUnZ2tZcuW6dFHH9XVq1fz7b9r1y5t3bpVU6ZMUbdu3XTfffdp8eLFunTpkj788ENJ0rFjx7R8+XKNHTtWTz75pO6++24tWLBAAQEBmj9/fr6/g8QUAACgBNq9e7feeustDRgwQGPGjMm3/zfffCNfX1/ddddd9ragoCC1atVK27ZtkyRt375dVqtVnTt3tvfx8vJSdHS0vY8rJKYAAAAlUO3atbV582aNHDlSnp6e+fY/fPiwwsPDnfpWr15dCQkJ9j4BAQEKCgpy6BMeHq7k5GRlZGS4/B2l/uB7AAAAgJtITU1VamqqU7u/v7/8/f1d3hscHPyHfldaWpr8/Pyc2n19fZWWlpZvH+na5ilvb+88f4dbJabDLK4/QOB2MTtpR1GHANwyS1DVog4BKBhlA4o6AtNynIi3X9fMmTOd2keOHKlRo0YV6O+y2Wx5XvPw8Mi3jyRZLBaX190qMQUAAIBxffv2Vbdu3Zza86uW3gw/Pz8dO3bMqT09Pd1eJfXz81N6erpTn+sV1dyqqTciMQUAADCZWZt6jEzZF5SaNWvqu+++k81mc6h8Hj16VDVr1pQk1apVSxcuXNDFixcVEBDg0CcsLExeXl4ufwebnwAAAEzmYbGY8ipMUVFRSk1N1bfffmtvS0lJ0a5du9SuXTtJsv/v559/bu+TmZmpL7/80n7NFSqmAAAAcJKSkqLExETVqVNHfn5+atWqlSIjIzV69GiNGTNGgYGBeuedd1SuXDn16NFDkhQaGqpu3brptdde0+XLlxUeHq5FixYpNTVVgwYNyvd3kpgCAACY7Hacov7yyy8VExOjuLg4tW7dWpI0c+ZMvfnmm5o6dapycnLUokULTZ8+3WHaftKkSfL399fcuXN1+fJlRUREaNGiRQoPD8/3d1ps+W2fKkTsykdxwa58FAfsykex4Qa78p/2MCeGt3MumjJuUaFiCgAAYDKPwl0OetsiMQUAADDZ7TiVXxT4nAAAAOAWqJgCAACYrLCPdrpdUTEFAACAW6BiCgAAYDIqgcbwOQEAAMAtUDEFAAAwGcdFGUNiCgAAYDKmqI3hcwIAAIBboGIKAABgMgvHRRlCxRQAAABugYopAACAyagEGkNiCgAAYDJ25RtDAg8AAAC3QMUUAADAZFQCjeFzAgAAgFugYgoAAGAyD46LMoTEFAAAwGRMURvD5wQAAAC3QMUUAADAZBwXZQwVUwAAALgFKqYAAAAmoxJoDIkpAACAyTzEXL4RJPAAAABwC1RMAQAATMbmJ2OomAIAAMAtUDEFAAAwGZVAY/icAAAA4BaomAIAAJiMNabGkJgCAACYjOOijGEqHwAAAG7BUMXUZrNpx44d2r17t86ePStJCgkJUcuWLdWyZUtTAwQAALjdMZVvTL6J6U8//aSYmBgdOXJENpvN4ZrFYlGdOnX05ptvKiIiwrQgAQAAUPy5TEx/++039e3bV5UrV9akSZPUrl07BQcHS5JOnTql7777TgsWLFCfPn20evVqhYeHF0rQAAAAtxPWThrjMjF99913Vb16dS1fvlxly5Z1uFa9enVVr15df/7zn9WjRw/NmTNHb7zxhqnBAgAA3I6YyjfGZQK/a9cuDRgwwCkpvZGvr6969+6t7du3F3hwAAAAKDlcVkwvXLig0NDQfAepUaOGTp8+XWBBAQAAFCccF2WMy4ppdna2vL298x3Ey8tLVqu1wIICAABAycMB+wAAACZjjakx+SamX3/9tY4ePeqyT2JiYoEFBAAAUNyQlxqTb2L69ttvGxrIYuEjBwAAwM1zmZjGx8cXVhwAAADFFlP5xrhMTI3syAcAAAAKgqHNT//973/l7++v6tWrS5IuXryoBQsW6ODBg6pXr5769u2rwMBAM+MEAAC4bXFclDEuj4vKysrSyJEj9eijj2rjxo2SpMzMTPXq1Uvz5s1TcnKyli9frkcffVTnz58vlIABAABQPLlMTJcuXapt27Zp7Nix+utf/ypJWrZsmQ4ePKhnnnlGa9as0b///W+VLVtWs2fPLpSAAQAAbjceFnNexY3LxHTt2rXq37+/+vXrp6CgIEnShg0b5OPjo/79+0v63yNJt2zZYn60AAAAtyEPk17Fjcv3dOTIEbVq1cr+c3p6un7++Wc1a9ZMZcqUsbfXqFFDp06dMi9KAAAAFHsuNz/ZbDZ5enraf/7xxx9ltVrVunVrh36XLl2Sj4+PORECAADc5orhrLspXFZMa9asqZ9//tn+8xdffCGLxaKoqCiHflu3blWNGjVMCRAAAAAlg8uK6YMPPqh3331XwcHBslqtWrVqlRo0aKCIiAh7nw0bNmjVqlV69tlnzY4VAADgtuTBEzINcZmYPvnkk/r55581btw4SVJISIimTJliv961a1cdOXJEzZs3V+/evc2NFAAA4DZFWmqMy8S0VKlSmjZtmp577jmdO3dO9erVk5eXl/16dHS0atSooW7dujm0AwAAAH+UoSc/Va1aVVWrVnVqHzt2bIEHBAAAUNxQMTXGZWKanJyca7vFYpGPj48CAgJkYc0EAAAACoDLxPTuu+92mXh6eXmpZcuWGj16tMOGKAAAAPwPZTxjXCamU6dOzfNaVlaWTp48qfj4eD355JNavny56tatW+ABAgAA3O6YYTbGYrPZbLcygM1mU69evVS5cmX985//vKVghln8b+l+wF3MTtpR1CEAt8wS5Ly3ALgtlQ0o6gi0KqiyKeN2TzlpyrhFxdDmJ1csFosef/xx/eMf/yiIeFAIes6OlUepUlo6eFRRhwJIkqxWq6Yv+kBrPt+i9MtXFNWqmV5+eqiCgwKd+vYePV7f7/nZeRBJ78e+rqTkk3px2ju5Xn+kyz1643m+9zCP1WrV9Fnv6ZO165Seflnt27XVyzHPK7hCBae+vQcN087dP+Q6ztL576lVi+YObRv/Ha9nXohR/L/WKCyXDclwb9RLjbnlxFSSqlSpovPnzxfEUDDZXyaOV4dhA/X1/CVFHQpgNzPuI63ZtEVvjn1Ggf7lNOntOXp64hR9MGOyU993XhmnrOxs+885OTY9Nf41+fr6qFlEfTWqV0ftIx3/g75qw2bN+WCl+j7yF9PfC0q2d96bp0/W/ktTXn1FgQEBmjh5qkaNGacPF81z7vuPKcrKyrL/nJNj07BnRsvP11fNmjR26Hv6zFn9/XXnfx+A4qZAEtNz584pMDCwIIaCSYJr1lDvBTNVteGdOnc0sajDAewys7IUt3qdxo8YpLtaNpUk/eOlv6lTr6H64ed9ah5R36F/oH85h5/nfbhaSSdOav3iWSrl6alSnp7yLlPGfj0p+aTmfLBSY4f1V73aNcx+OyjBMrOyFPfhcr30wt90V5vWkqR/vvma7nngYf3w0141b+qYbAYGOE4vz120REnHjmvDJx+rVCnH/zy/+MqrqnvHHdq5a7e5bwKmcfkMeNjd8udks9n04YcfqlmzZgURD0xSq11rnU86rlcbtdG5hKNFHQ5gt+9QgtIvX1Fk04b2trDKIQqtXEm79/7i8t4zKec1e9nHem7gk6oYVD7XPtPmLlHdmuF67IH7CjRu4Pf27f9N6enpimz5v4p9WNWqCq1aRbt+/NHlvWfOntXs+Yv03Kjhqhgc7HBt2ccrdebsWQ0fPMCUuAF34rJiunbt2jyvZWZm6vTp09q0aZMOHz6sDz74oMCDQ8HZuWy5di5bXtRhAE5OnjknSQoJdlyDV6lCkE6cOevy3vkfrVaFwAA9/ufOuV7fdyhBm776TovfelUeHtQrYK6Tp05LkkIqVnJor1Sxov1aXuYtjlOFoPJ6ons3h/aEo0c1feZsvT//PaWlpxdswChUbMo3xmVi+vzzz7u82cvLSy1atNCSJUs4xxTATcnIuCoPDw+V/t3UpVfp0srMzMzzvrTLV7RqY7zGDO4rT0/PXPssWbVWTRrUU5tmjQo0ZiA3VzIyrn2XS//uu+xVWlevXs3zvrT0dK36dK2ef2aUw3c5OztbL7z0igb17a36de/Qrh9/Mit0FAIL258McZmYxsfH59p+45OfqEIAuBVlyngpJydH2VarSt3wH+XMrCz5eHvned+Wb3bIarXqwU4dc71+NTNTn2/7VuNHDi7wmIHceJcpc+27nJ3tsEY0MzNLPj4+ed4X/+U2WbOtevCBrg7t7y1YJA+LRYP69TYtZsDduExMQ0ND87yWnJyscuXKkZgCuCVVKl1bT3fmXIqqVKpobz99LkUhwUF53hf/7U5Ft2mpsj65J6/f/bBXWdnZujeqdcEGDOShSuUQSdKZs+fs/yxJp8+cUUilDnneF//lVkV3iFLZ3yWvqz9bp9Nnzqpl+7slSTm2HEnSn7s/oWGD+mvYwP4F/RZgIuqlxtxUVmm1WnXPPfdo//79BR0PgBKmfq2a8i3r43A26bGTp3T85Gm1bJz3EqHd//lFrX+3y/n31++sU1v+fn4FGi+Ql/p175Cvr6/D2aTHkpN1PPmEWjXPe4Pw7h9/UptWLZ3a35/3nv618iOt+Wip1ny0VJNfeVmSNPed6Xrir48U/BsA3MBNHxd1iw+MAgBJ19bf9Xywq6bOWazyAf4KCgzQpLfnqFWTCDW9s54ys7J08VKaAsr5yat0aUnXqqlnz19Q3VrheY77y8HDqluremG9DUBeXl7q+Wh3TY2dofKBgaoQVF4TJ09VZIvmatq40bXv8sWLCggI+N93+cxZnT2Xorp16jiNF1q1isPPZ85d2yhYtWplp6Om4P6omBrDPDyAIvfMgF768z0d9PzkWPUdM0FVQyrq7b+PlST9+PM+tX+0v378eZ+9/5lz1x7oEVgu72romXPnFViuXJ7XATM8O2KY/tK1i55/6WX1GfKUqlaprBnT3pQk/bhnr6LuvV8/7tlr73/m7LWTJwICeCR3cedhMedV3FhsN1H6tFqtioiI0KpVqwp0N/4wC/9ioniYnbSjqEMAbpkliMdeopgoW/QV5vXBVfLvdBPuP3vilu5ft26dZs+eraSkJIWGhmro0KF6+OGH8+y/b98+TZs2Tbt371aZMmXUsWNH/e1vf1NIyP/WVe/atUu9evVyujc6Olpz5sxxGc9NTeV7enpq8uTJCgsLu5nbAQAAShR3PC5q/fr1GjNmjPr27auoqCht3rxZY8eOlbe3t7p06eLUPzExUb169VJwcLAmTZqkgIAALV68WD169NCaNWvk73+twLh//36VLVtWixYtcrj/+nVXDCemaWlp8rthE0G3bt20Y8cORUZGysKpsQAAALeV2NhYde3aVTExMZKk9u3b6+LFi5oxY0auiWlcXJyys7O1aNEiVa16bUalTZs26tKli+bPn6/Ro0dLulZVveOOO9S0adM/HFO+a0z37Nmjrl27OmW958+fV79+/dSpUyf9/PPPedwNAAAAi0mvm5WUlKTExETdd5/j45o7d+6sw4cPKykpyemehIQE1a1b156USlKZMmXUqFEjbd261d7266+/ql69ejcVl8vENCEhQQMGDJDNZlPjxo7Hsvj6+mry5MkqVaqUevfunesbAAAAwLVHkprxulmHDx+WJNWsWdOhPTz82mknCQkJTvdUqVJFp06dUnZ2tkP7sWPH7Hmg1WrVgQMHdPLkSXXr1k0NGzZUdHS0Fi5caOhEJ5eJ6XvvvafQ0FCtWrVKHTs6Pl3Fy8tLDz/8sFasWKGKFStq9uzZ+f4yAAAAFJzU1FQdO3bM6ZWamuryvkuXLkmSwzJN6VrhUbq2hPP3Hn74YZ0+fVrjx49XcnKyzp07p9jYWB04cEBXrlyRJB05ckQZGRlKSEjQ4MGDNW/ePHXq1ElTp07VO++8k+/7cbnG9Pvvv9fTTz9tDzI3/v7+6tevnxYuXJjvLwMAACiJzNqNs2TJEs2cOdOpfeTIkRo1alSe9+VXvcztyZ4tW7bUG2+8ocmTJ2vNmjWyWCy699571aNHD61YsUKSFBISonnz5qlBgwaqWPHa0/zatm2rjIwMzZs3TwMGDHBKhm/kMjE9d+6cy8eSXlerVi2dPn06334AAAAoOH379lW3bt2c2vPbAV/u/895Tk9Pd2i/Xiktl8c50I888ogeeughJSYmqly5cgoODlZMTIwCAwMlXavAdujg/Aje6OhorVixQgkJCWrUqFGecblMTIODg3X8+HG1atXKVTedOnVKQUF5P9MaAACgJPMwqWbq7+9v6Bim37u+tjQxMdFho9LRo0cdrt/o0KFD+u9//6uHHnrI4fovv/yiO++8U9K1o6J2796tRx99VKX//wlnkpSRkSFJKl++vMu4XK4xbdeunT766COXA9hsNi1fvtxl9gsAAAD3ER4errCwMG3cuNGhfdOmTapRo4bDzvvrfvvtN73wwgsOG963b9+uffv2qVOnTpKuJbYTJ07Utm3bHO5dv369wsLC8p2Jd1kx7devn7p3767Ro0frpZdecqqKpqSk6PXXX9dPP/2kuLg4l78IAACgpHLHE99HjBihmJgYBQQEKDo6WvHx8dqwYYNiY2MlXcvzEhMTVadOHfn5+aljx44KCwvT6NGjNWrUKKWkpGjy5Mlq0qSJHnzwQUnXpuwjIiI0YcIEpaSkqHLlylq7dq22bNmid955J9+z7/N9JOmGDRv04osvKjs7WxEREQoNDZXValVycrJ++eUXeXp6asKECfrrX/96yx8QjyRFccEjSVEc8EhSFBtu8EjSLZXy37NzM+4+ffyW7v/oo4+0cOFCnThxQtWqVdOQIUPsjyRdvXq1YmJiFBcXp9atW0u6dozU66+/rh9//FE+Pj6699579dxzzzksJ0hJSdH06dO1detWpaSk6I477tDw4cPtVVVX8k1MpWvrD95//319/fXXOnnypDw9PVW1alVFRUWpZ8+eBfZoUhJTFBckpigOSExRbJCY3jYMPZK0evXqGj9+vNmxAAAAFEvuOJXvjlxufurTp48OHTpUWLEAAACgBHNZMd25c6fT+VYAAAD4YyzUTA0xNJUPAACAm+dBXmqIy6l8AAAAoLDkWzF97bXXXD7T9DqLxaIFCxYUSFAAAADFCQVTY/JNTLOzs5WVlVUYsQAAAKAEyzcxfeWVV9S4cePCiAUAAKBYomJqDJufAAAATMaufGPY/AQAAAC34DIx7datm8qXL5/rNZvNpnPnzsnAE00BAABKNIvFnFdx4zIxnTx5sjIzMzVt2jS99dZbOnLkiCRp6dKlioyMVFRUlNq0aaO5c+cWRqwAAAAoxlyuMf3+++81cOBAeXp6ysfHR8uWLdOoUaM0depUtWvXTg0aNNDevXsVGxsrPz8/9ezZs7DiBgAAuG2wdtIYl4npzJkz1aZNG73zzjsqU6aM/vnPf2ratGnq3r27Xn/9dXu/8ePHa+XKlSSmAAAAuGkuE/hffvlFjz/+uMqUKSNJ6tu3r2w2m7p06eLQ78EHH1RCQoJ5UQIAANzGLCa9ihuXFdNLly4pKCjI/nNAQIAkKTAw0KGft7e3MjIyCj46AACAYsBSHHcqmSDfJQ+enp72f77+oXp4sFICAAAABeumDtgn6wcAADCOzMmYfBPT1157TX5+fpJkP7N04sSJ8vX1tfdJS0szKTwAAACUFC4T01atWkmSsrKyXLaVKVNGLVu2NCM+AACA2x4VU2NcJqbvv/9+YcUBAABQbLEM0hh2MQEAAMAt3NTmJwAAABjnQcHUECqmAAAAcAtUTAEAAExmoWRqCIkpAACAydj7ZAxT+QAAAHALVEwBAABMRsXUGCqmAAAAcAtUTAEAAEzGAfvGUDEFAACAW6BiCgAAYDIKpsaQmAIAAJiMqXxjmMoHAACAW6BiCgAAYDIKpsZQMQUAAIBboGIKAABgMg9KpoaQmAIAAJiMvNQYpvIBAADgFqiYAgAAmIzjooyhYgoAAAC3QMUUAADAZBZKgYaQmAIAAJiMqXxjyN8BAADgFqiYAgAAmIyCqTFUTAEAAOAWqJgCAACYjDWmxlAxBQAAgFugYgoAAGAyCqbGkJgCAACYzIPM1BCm8gEAAOAWqJgCAACYjIKpMVRMAQAA4BaomAIAAJiM46KMITEFAAAwGXmpMW6VmM5O2lHUIQAF4qlqrYs6BOCWzVr3VlGHABQIzweGFHUIMMitElMAAIDiiIqpMWx+AgAAgFugYgoAAGAyiwclUyNITAEAAEzGVL4xTOUDAADALVAxBQAAMJkHJVNDqJgCAADALVAxBQAAMBkFU2OomAIAAMAtUDEFAAAwmYWSqSEkpgAAACYjLzWGqXwAAAC4BSqmAAAAJmMq3xgqpgAAACXUunXr9MADD6hx48bq2rWr1qxZ47L/vn37NHDgQDVt2lStW7fWCy+8oFOnTjn0yc7O1vTp09WxY0c1adJEPXv21N69ew3FQ2IKAABgMovFnNetWL9+vcaMGaOoqCjNmjVLkZGRGjt2rDZu3Jhr/8TERPXq1UvHjh3TpEmTNHXqVJ05c0Y9evRQamqqvd/rr7+uxYsXa/DgwYqNjZWnp6f69eunpKSkfGNiKh8AAMBk7jiVHxsbq65duyomJkaS1L59e128eFEzZsxQly5dnPrHxcUpOztbixYtUtWqVSVJbdq0UZcuXTR//nyNHj1ax44d0/LlyzVhwgT16NFDkhQVFaXOnTtr/vz5mjhxosuYqJgCAACUMElJSUpMTNR9993n0N65c2cdPnw41+pmQkKC6tata09KJalMmTJq1KiRtm7dKknavn27rFarOnfubO/j5eWl6Ohobdu2Ld+4SEwBAABMZvEw53WzDh8+LEmqWbOmQ3t4eLika0no71WpUkWnTp1Sdna2Q/uxY8fsiezhw4cVEBCgoKAgp3GTk5OVkZHhMi4SUwAAgNtUamqqjh075vS6cc1nbi5duiRJ8vPzc2j39fWVJKWlpTnd8/DDD+v06dMaP368kpOTde7cOcXGxurAgQO6cuWK/b7fj3njuOnp6S7jYo0pAACAycxaY7pkyRLNnDnTqX3kyJEaNWpUnvfZbDaX43p4ONcuW7ZsqTfeeEOTJ0/WmjVrZLFYdO+996pHjx5asWKFoXHz+xxITAEAAMzmYU5i2rdvX3Xr1s2p3d/f3+V95cqVk+RcwbxeKb1+/fceeeQRPfTQQ0pMTFS5cuUUHBysmJgYBQYGSrpWgc2tKnp93NyqqTciMQUAALhN+fv755uE5ub62tLExETVq1fP3n706FGH6zc6dOiQ/vvf/+qhhx5yuP7LL7/ozjvvlCTVqlVLFy5c0MWLFxUQEOAwblhYmLy8vFzGxRpTAAAAs7nZQabh4eEKCwtzOrN006ZNqlGjhsPO++t+++03vfDCCw479rdv3659+/apU6dOkqR27dpJkj7//HN7n8zMTH355Zf2a65QMQUAACiBRowYoZiYGAUEBCg6Olrx8fHasGGDYmNjJUkpKSlKTExUnTp15Ofnp44dOyosLEyjR4/WqFGjlJKSosmTJ6tJkyZ68MEHJUmhoaHq1q2bXnvtNV2+fFnh4eFatGiRUlNTNWjQoHxjIjEFAAAwmTsesP/II48oMzNTCxcu1IoVK1StWjVNmTJF999/vyTpyy+/VExMjOLi4tS6dWuVLVtW8+fP1+uvv67nnntOPj4+uv/++/Xcc8/J09PTPu6kSZPk7++vuXPn6vLly4qIiNCiRYvsR1G5YrHlt32qENmO/VrUIQAF4qlqrYs6BOCWzVr3VlGHABQIzweGFHUISu3U3JRx/Tf/YMq4RYU1pgAAAHALTOUDAACYzQ2n8t0RFVMAAAC4BSqmAAAAJrOYdMB+cUPFFAAAAG6BiikAAIDZWGNqCIkpAACAyZjKN4apfAAAALgFKqYAAABmYyrfECqmAAAAcAtUTAEAAMzGGlNDSEwBAABMZmEq3xDDiWlSUpJ2796ts2fPSpJCQkLUokULVa1a1bTgAAAAUHLkm5gmJibq73//u7Zv3y6bzeZwzcPDQx06dNCECRMUGhpqWpAAAAC3NabyDXGZmCYnJ+vxxx+XzWbT0KFD1a5dO1WoUEGSdPr0aX333Xdavny5evToodWrVys4OLhQggYAAEDx4zIxnTlzpsqUKaPly5crJCTE4Vrt2rXVtm1b9erVSz169NCcOXM0fvx4U4MFAAC4LbHG1BCXx0V9++23Gjp0qFNSeqOQkBD1799fW7duLfDgAAAAigOLhzmv4sblWzp37pxq1aqV7yB169bViRMnCiwoAAAAlDwup/KzsrLk4+OT7yDe3t7Kzs4usKAAAACKFabyDSmGRWAAAADcjvI9Lmr//v35VkMPHjxYYAEBAAAUNxaOizIk38T05ZdfzncQm83GEw0AAABwS1wmpnFxcYUVBwAAQPFFAc8Ql4lpZGRkYcUBAABQfDGVb0i+U/nStWOjLBaLgoKCJEmZmZn65JNPdPDgQdWrV08PPvigvLy8TA0UAAAAxVu+ienkyZO1bNkyPffccxo4cKBycnI0cOBA7dq1S/7+/kpPT9fy5csVFxdn6GgpAACAkoa9OMa4PC5q5cqViouLU48ePdSpUydJ0qpVq/T999+rZ8+e2r59uzZv3qzz589r3rx5hRIwAAAAiqd8E9NevXpp/PjxCg8PlyR99tlnKl26tJ599llZLBZVrlxZ/fv318aNGwslYAAAgNuOh8WcVzHjMjE9ePCg2rdvb//56tWr+umnn9S4cWOVK1fO3l6vXj0dP37cvCgBAABuZxaLOa9ixmVimpWVJW9vb/vPe/fuVVZWltNu/StXrqh06dLmRAgAAIASwWViGhYW5vBUp23btsliseiuu+5y6Ldjxw6FhoaaEyEAAMBtzmKxmPIqblzuyu/SpYvmzp2runXrymq16uOPP1a1atXUsmVLe5+9e/fqgw8+UN++fU0PFgAAAMWXy8R00KBB2rFjh3r37i2LxSJvb2+98cYb9uv9+/fXjh07VLNmTQ0cOND0YAEAAG5LxXCjkhlcJqY+Pj5aunSpdu3apbNnz6pVq1aqUKGC/XpgYKAGDRqkgQMHys/Pz/RgAQAAbkfFcdrdDIae/HTj1P2NYmNjCzQYAAAAlFyGElMAAADcAqbyDXGZmNavXz/P0rOPj48qVqyo1q1ba9iwYapataopAQIAAKBkcJmYPv3003kmpllZWTp58qS++OILxcfHa8WKFSSnAAAAuWGNqSEuE9Phw4fnO8CVK1f02GOPafbs2Xr11VcLLDAAAACULLe8xtTHx0d9+vTR7NmzCyIe/AFWq1XTF32gNZ9vUfrlK4pq1UwvPz1UwUGBTn17jx6v7/f8nOs478e+rqTkk3px2ju5Xn+kyz164/lRBRk6cMt6zo6VR6lSWjqY7ybchzUnRzPWf6M13/+s9KuZal+/hl7qfo+Cy/nm2n/7gUTFrvtKB0+dVXA5Xz3WtrEG/KmV02ylzWbT0Hmr1bxmqIbd26Yw3goKmIU1poYUyOan6tWr6+zZswUxFP6AmXEfac2mLXpz7DMK9C+nSW/P0dMTp+iDGZOd+r7zyjhlZWfbf87Jsemp8a/J19dHzSLqq1G9Omof2dzhnlUbNmvOByvV95G/mP5egD/iLxPHq8Owgfp6/pKiDgVwMOvz7/Tprp/1Zs8uCvT10aSV8Xp28WdaOqqHU9+jZ85r+PxPNOjuSL3V5wH9cuy0Xvxwg3y8SqtnVDN7v8xsqyat3Kyv9x1R85o8ZfG2xVS+IQWSmKalpXGOaSHLzMpS3Op1Gj9ikO5q2VSS9I+X/qZOvYbqh5/3qXlEfYf+gf7lHH6e9+FqJZ04qfWLZ6mUp6dKeXrKu0wZ+/Wk5JOa88FKjR3WX/Vq1zD77QCGBNesod4LZqpqwzt17mhiUYcDOMjMtur9bT/oxW5/Urt6NSRJ/+jzgO59bb5+TDiuZr9LKr/ed0RlSpfS8M5tJUnVKgRq40/79c3+I/bE9Jdjp/TS8s+VdiVT/j5lBBR3HgUxyJo1a9SwYcOCGAoG7TuUoPTLVxTZ9H+fe1jlEIVWrqTde39xee+ZlPOavexjPTfwSVUMKp9rn2lzl6huzXA99sB9BRo3cCtqtWut80nH9WqjNjqXcLSowwEc7Dt+WulXMxVZp5q9LTQoQKFB/tp9+LhT/yA/H128nKF//fCrcnJsOnDirHYdPqaIsMr2Pt/uP6qWtcK0ekxv+XmTmN7WPCzmvIoZlxXTH374Ic9rmZmZOn36tDZs2KCtW7dqwYIFBR4c8nbyzDlJUkhwBYf2ShWCdOKM62UV8z9arQqBAXr8z51zvb7vUII2ffWdFr/1qjw8CuTvLkCB2LlsuXYuW17UYQC5OnUxTZJUKcBxBrGSv59OXrjk1P/exnXVvfVRvbBsvcZ9sEHWHJu6NK3rsIZ00D2R5gYNuBmXiWnPnj3zPC7KZrNJura+NDY2Vm3bti346JCnjIyr8vDwUOlSjv8XepUurczMzDzvS7t8Ras2xmvM4L7y9PTMtc+SVWvVpEE9tWnWqEBjBoDi7EpmljwsFpX+3Z+tXqU8dfWGNf7XXbqSoeMpqRr4p1bq0rSeDpw4q8lrvtSsTd9qVJe7CitsFBIeSWqMy8Q0Li4u13aLxWI/YD8kJMSUwOBamTJeysnJUbbVqlI3/CGYmZUlH2/vPO/b8s0OWa1WPdipY67Xr2Zm6vNt32r8yMEFHjMAFGfepUspx2ZTtjVHpTz/N9uUmW2Vj1dpp/7/WPeVSnl4aPSfO0iS7gwLUXZOjiau3Kze7Zsr0Nen0GJHISiG0+5mcJmYRkYyheCuqlQKliSdOZeiKpUq2ttPn0tRSHBQnvfFf7tT0W1aqqxP7snrdz/sVVZ2tu6Nal2wAQNAMVc58Nom0zOpaapS3t/efjo1TXcH1Hbqv+foCXVqVMehrXF4FWVbc5R8PpXEFCXSTS0gtFqtatCggX7+OfdzMWG++rVqyresj8PZpMdOntLxk6fVsnFEnvft/s8vat20scvrd9apLX9OWQCAP6R+aEX5lvHS94eO2duOp1zU8ZRUtawV5tS/cqCffjtxxqHt4Imz8rBYVD040OxwUdgsFnNexcxNHxd1fY0pioaXV2n1fLCrps5ZrPIB/goKDNCkt+eoVZMINb2znjKzsnTxUpoCyvnJq/S1KaTT51J09vwF1a0Vnue4vxw8rLq1qhfW2wCAYsOrVCn1uKuJpq3dqvK+PqpQrqwmrYxXq9phalKjqjKzrbp4OUMBZb3lVcpTT7ZvruELPtF7/96uB5rX16GT5zTl06164q4m7MBHiVUg55iiaDwzoJeysrP1/ORYZVutav//T36SpB9/3qe+f5ugJf94Va2bXtvEdObceUlSYLm8q6Fnzp3XnXVqmR88ABRDT3eNUpY1R2M/WK9sa46i6tfQhEfukST9dCRZ/d79WIuHP6bIOtXU8c5amtHvQc359w7Ni99pf/LT4E4soyuWimF10wwW202UPq1WqyIiIrRq1SpFROQ9bfxH2Y79WmBjAUXpqWqs0cXtb9a6t4o6BKBAeD4wpKhDUPYzD5kybqkZn5oyblG5qTWmHh4eGjlypCpVqlTQ8QAAAKCEuqmpfIvFopEjRxZ0LAAAAMUTD6wxxGViOmHCBMMDWSwWTZo06ZYDAgAAQMnkMjH95ptvnNpOnDih4OBglS7teFgwTzQAAADIA3mSIS4T0y1btjj8nJ2drYYNG+q9994r0E1PAAAAwB9aY0pVFAAA4CaQQxnCOaYAAABmIzE1hC1iAAAAcAtUTAEAAMzGcVGG3NSnxFpTAAAAFDSXFdP77rsv1yR0xIgR8vLycmr//PPPCy4yAACA4oKiniEuE9PmzZs7JabNmzc3NSAAAIBih8TUEJeJ6ZtvvllYcQAAAKCEc7nGNCYmRklJSYUVCwAAQPFksZjzKmZcJqaffPKJzp8/X1ixAAAAoATjuCgAAACzcVyUISSmAAAAZiuG0+5myDcxnTNnjoKCgvIdyGKxaNKkSQUSFAAAAEqefBPTPXv25Hpm6e9x6D4AAEAeyJMMyTcxfffdd9W4cePCiAUAAACFaN26dZo9e7aSkpIUGhqqoUOH6uGHH86zf0pKiqZNm6avvvpKmZmZatasmWJiYlSjRg17n127dqlXr15O90ZHR2vOnDku42GNKQAAgNncsGK6fv16jRkzRn379lVUVJQ2b96ssWPHytvbW126dHHqb7PZNGLECCUmJur5559XYGCg3n77bfXp00dr165VQECAJGn//v0qW7asFi1a5HC/v79/vjGRmAIAAJRAsbGx6tq1q2JiYiRJ7du318WLFzVjxoxcE9MjR47ohx9+0JQpU+xV1dq1a6tTp07asmWLunXrJknat2+f7rjjDjVt2vQPx+Ty7IJWrVrJ19f3Dw8KAACA/7F4eJjyullJSUlKTEzUfffd59DeuXNnHT58ONcHLF29elWSHHLD61XSCxcu2Nt+/fVX1atX76bicvmOvL295fG7N/31118rPT3doW3v3r1q2LDhTQUAAABQ7LnZk58OHz4sSapZs6ZDe3h4uCQpISHB6Z769eurdevWmjVrlg4dOqSUlBS99tprKlu2rDp16iRJslqtOnDggE6ePKlu3bqpYcOGio6O1sKFC2Wz2fKNy+VU/tdff61Lly7Zf7ZarRo8eLBWrlypiIgIe7vNZpPVas33lwEAAKDgpKamKjU11and39/f5ZrO6/mdn5+fQ/v1amhaWlqu973yyisaNGiQ7r//fkmSl5eXZs2apWrVqkm6Nt2fkZGhhIQEjR49WuXLl1d8fLymTp2qtLQ0Pf300y7fj8vENLfM1ki2CwAAgBuYtPlpyZIlmjlzplP7yJEjNWrUqDzvyy+f+/2MuSQdOnRITzzxhKpXr64XX3xR3t7e+vjjj/X0009r/vz5atmypUJCQjRv3jw1aNBAFStWlCS1bdtWGRkZmjdvngYMGOCUDN+IzU8AAAC3qb59+9o3Hd0ovx3w5cqVkySn5ZnXK6XXr99o8eLFkqSFCxfa15bedddd6tmzp9544w2tXr1afn5+6tChg9O90dHRWrFihRISEtSoUaM84yIxBQAAMJtJFdP8puzzcn1taWJiosNGpaNHjzpcv1FycrJq165tT0qlaw9YatGiheLi4iRdOypq9+7devTRR1W6dGl7v4yMDElS+fLlXcZ189u5AAAAYIyHhzmvmxQeHq6wsDBt3LjRoX3Tpk2qUaOGqlat6nRPzZo1deDAAac1rXv27FFoaKika4ntxIkTtW3bNoc+69evV1hYmL1fXm6qYsrjRwEAAG5vI0aMUExMjAICAhQdHa34+Hht2LBBsbGxkq495SkxMVF16tSRn5+f+vXrp88++0wDBgzQkCFD5O3trU8//VQ7d+603xMdHa2IiAhNmDBBKSkpqly5stauXastW7bonXfeyTeHzDcxfe211+yLVK8vlJ04caLDGVZ57dwCAACA3PLJT4888ogyMzO1cOFCrVixQtWqVdOUKVPsO+6//PJLxcTEKC4uTq1bt1ZYWJg+/PBDvfXWW4qJiZHFYlHdunW1aNEitWvXTtK1Xfrz58/X9OnTNXPmTKWkpOiOO+7QzJkz7UdKuWKxudiW1bt37z/0Bt9///0/1P/3bMd+vaX7AXfxVLXWRR0CcMtmrXurqEMACoTnA0OKOgRZ3zAnBs8X55oyblFxWTG91UQTAAAAcsuKqTtiVz4AAIDZSEwNYVc+AAAA3AIVUwAAALPdwtFOJQmfEgAAANwCFVMAAACzscbUECqmAAAAcAtUTAEAAMxGxdQQElMAAACzsfnJED4lAAAAuAUqpgAAAGZjKt8QKqYAAABwC1RMAQAAzEbF1BASUwAAALORmBrCVD4AAADcAhVTAAAAs3FclCF8SgAAAHALVEwBAADMxhpTQ0hMAQAAzEZiaghT+QAAAHALVEwBAADMZqEWaASfEgAAANwCFVMAAACzebDG1AgqpgAAAHALVEwBAADMxhpTQ0hMAQAAzMZxUYaQvgMAAMAtUDEFAAAwmwe1QCP4lAAAAOAWqJgCAACYjTWmhpCYAgAAmI1d+YbwKQEAAMAtUDEFAAAwG1P5hlAxBQAAgFugYgoAAGA2josyxK0SU0tQ1aIOASgQs9a9VdQhALdsxJ/HFHUIQIF4zzakqENgKt8g0ncAAAC4BbeqmAIAABRLHBdlCJ8SAAAA3AIVUwAAALN5sMbUCCqmAAAAcAtUTAEAAMzGGlNDSEwBAADMxnFRhpC+AwAAwC1QMQUAADAbU/mG8CkBAADALVAxBQAAMBvHRRlCYgoAAGA2Nj8ZwlQ+AAAA3AIVUwAAALOx+ckQPiUAAAC4BSqmAAAAZmPzkyEkpgAAAGZjKt8QPiUAAAC4BSqmAAAAZuO4KEOomAIAAMAtUDEFAAAwG2tMDSExBQAAMBu78g0hfQcAAIBboGIKAABgNqbyDeFTAgAAgFugYgoAAGA2josyhIopAAAA3AIVUwAAALN5UAs0gsQUAADAbEzlG0L6DgAAALdAxRQAAMBsHBdlCJ8SAAAA3AIVUwAAALOxxtQQElMAAACzsSvfED4lAACAEmrdunV64IEH1LhxY3Xt2lVr1qxx2T8lJUUxMTGKiopSZGSkhg4dqiNHjjj0yc7O1vTp09WxY0c1adJEPXv21N69ew3FQ2IKAABgNovFnNctWL9+vcaMGaOoqCjNmjVLkZGRGjt2rDZu3Jhrf5vNphEjRmjbtm0aM2aMpk6dqjNnzqhPnz66ePGivd/rr7+uxYsXa/DgwYqNjZWnp6f69eunpKSkfGNiKh8AAKAEio2NVdeuXRUTEyNJat++vS5evKgZM2aoS5cuTv2PHDmiH374QVOmTNHDDz8sSapdu7Y6deqkLVu2qFu3bjp27JiWL1+uCRMmqEePHpKkqKgode7cWfPnz9fEiRNdxkTFFAAAwGwWD3NeNykpKUmJiYm67777HNo7d+6sw4cP51rdvHr1qiTJ19fX3hYQECBJunDhgiRp+/btslqt6ty5s72Pl5eXoqOjtW3btnzjomIKAABgNpN25aempio1NdWp3d/fX/7+/nned/jwYUlSzZo1HdrDw8MlSQkJCapWrZrDtfr166t169aaNWuWatWqpfLly+vNN99U2bJl1alTJ/u4AQEBCgoKcho3OTlZGRkZ8vb2zjMuElMAAIDb1JIlSzRz5kyn9pEjR2rUqFF53nfp0iVJkp+fn0P79WpoWlparve98sorGjRokO6//35J16qhs2bNsiexaWlpTmPeOG56enrBJKZJSUnavXu3zp49K0kKCQlRixYtVLVqVaNDAAAAlEwmPfmpb9++6tatm1O7q2qpdG0jkyseuRxvdejQIT3xxBOqXr26XnzxRXl7e+vjjz/W008/rfnz56tly5b5jmvJp3Kcb2KamJiov//979q+fbvTL/Pw8FCHDh00YcIEhYaG5jcUAAAAClB+U/Z5KVeunKRrFcwbXa+UXr9+o8WLF0uSFi5caF9betddd6lnz5564403tHr1avn5+TmNeeO4uVVTb+QyMU1OTtbjjz8um82moUOHql27dqpQoYIk6fTp0/ruu++0fPly9ejRQ6tXr1ZwcLDLXwYAAFAiebjXk5+ury1NTExUvXr17O1Hjx51uH6j5ORk1a5d256UStcqoC1atFBcXJwkqVatWrpw4YIuXrzo0O/o0aMKCwuTl5eXy7hc1pVnzpypMmXK6NNPP9Wzzz6ryMhI1a5dW7Vr11bbtm01evRoffbZZypVqpTmzJmT32cAAAAANxAeHq6wsDCnM0s3bdqkGjVq5LpUs2bNmjpw4IDTZqs9e/bYZ87btWsnSfr888/t1zMzM/Xll1/ar7nismL67bffaujQoQoJCcmzT0hIiPr376/3339f48ePz/cXAgAAlDgmrTG9FSNGjFBMTIwCAgIUHR2t+Ph4bdiwQbGxsZKuPeUpMTFRderUkZ+fn/r166fPPvtMAwYM0JAhQ+Tt7a1PP/1UO3futN8TGhqqbt266bXXXtPly5cVHh6uRYsWKTU1VYMGDco3JpeJ6blz51SrVq18B6lbt65OnDhh5DMAAAAoeUw6LupWPPLII8rMzNTChQu1YsUKVatWTVOmTLHvuP/yyy8VExOjuLg4tW7dWmFhYfrwww/11ltvKSYmRhaLRXXr1tWiRYscqqGTJk2Sv7+/5s6dq8uXLysiIkKLFi2yH0XlisXmYvtU/fr19fHHH6tx48YuB9mzZ4+eeOIJ/frrr0Y/i9xdvph/H+A2YP1ieVGHANyyEX8eU9QhAAXiPZvzOZ+Fzfr1SlPG9Yz6qynjFhXOMQUAADCbG07lu6N8E9P9+/crOzvbZZ+DBw8WWEAAAAAomfJNTF9++eV8B7HZbPkemAoAAFBSkScZ4zIxvX4mFQAAAG4BU/mGuExMIyMjCysOAAAAlHCGNj+dO3dOFotFQUFBkq4dlPrJJ5/o4MGDqlevnh588MF8T/IHAAAosaiYGpJvYjp58mQtW7ZMzz33nAYOHKicnBwNHDhQu3btkr+/v9LT07V8+XLFxcXJx8enMGIGAABAMeQyfV+5cqXi4uLUo0cPderUSZK0atUqff/99+rZs6e2b9+uzZs36/z585o3b16hBAwAAHDb8bCY8ypm8k1Me/XqpfHjx9tP6//ss89UunRpPfvss7JYLKpcubL69+/v9KxVAAAA/D+LhzmvYsblOzp48KDat29v//nq1av66aef1LhxY5UrV87eXq9ePR0/fty8KAEAAFDsuVxjmpWVJW9vb/vPe/fuVVZWltNu/StXrqh06dLmRAgAAHC74xxTQ1xWTMPCwhye6rRt2zZZLBbdddddDv127Nih0NBQcyIEAABAieCyYtqlSxfNnTtXdevWldVq1ccff6xq1aqpZcuW9j579+7VBx98oL59+5oeLAAAwG2pGK4HNYPLxHTQoEHasWOHevfuLYvFIm9vb73xxhv26/3799eOHTtUs2ZNDRw40PRgAQAAUHy5TEx9fHy0dOlS7dq1S2fPnlWrVq1UoUIF+/XAwEANGjRIAwcOlJ+fn+nBAgAA3JZYY2qIoSc/3Th1f6PY2NgCDQYAAKBYYirfED4lAAAAuAWXFdP69evLkkfp2cfHRxUrVlTr1q01bNgwVa1a1ZQAAQAAbnvF8ClNZnCZmD799NN5JqZZWVk6efKkvvjiC8XHx2vFihUkp4XMarVq+qz39MnadUpPv6z27drq5ZjnFXzDOuDreg8app27f8h1nKXz31OrFs0d2jb+O17PvBCj+H+tURj/v8Jk1pwczVj/jdZ8/7PSr2aqff0aeqn7PQou55tr/+0HEhW77isdPHVWweV89Vjbxhrwp1ZOf17ZbDYNnbdazWuGati9bQrjrQB/WM/ZsfIoVUpLB48q6lCAIucyMR0+fHi+A1y5ckWPPfaYZs+erVdffbXAAkP+3nlvnj5Z+y9NefUVBQYEaOLkqRo1Zpw+XDTPue8/pigrK8v+c06OTcOeGS0/X181a9LYoe/pM2f199cnmx4/cN2sz7/Tp7t+1ps9uyjQ10eTVsbr2cWfaemoHk59j545r+HzP9GguyP1Vp8H9Mux03rxww3y8SqtnlHN7P0ys62atHKzvt53RM1rcs4y3NNfJo5Xh2ED9fX8JUUdCszGGlNDbvlT8vHxUZ8+ffTNN98URDwwKDMrS3EfLtfoUcN1V5vWimhQX/988zX98NMe/fDTXqf+gQEBqhgcbH99+q/1Sjp2XP988zWVKuX495MXX3lVde+4o7DeCkq4zGyr3t/2g569P0rt6tXQnWEh+kefB/RDQrJ+THB+1PHX+46oTOlSGt65rapVCFTnJnXVoUEtfbP/iL3PL8dO6YkZy7TzYJL8fcoU4rsBjAmuWUPPbVmnDk8N1LmjiUUdDgqDxWLOq5gpkPS9evXqOnv2bEEMBYP27f9N6enpimz5vyn4sKpVFVq1inb9+KPLe8+cPavZ8xfpuVHDVTE42OHaso9X6szZsxo+eIApcQO/t+/4aaVfzVRknWr2ttCgAIUG+Wv3YefENMjPRxcvZ+hfP/yqnBybDpw4q12HjykirLK9z7f7j6plrTCtHtNbft4kpnA/tdq11vmk43q1URudSzha1OEAbsPQcVH5SUtL4xzTQnby1GlJUkjFSg7tlSpWtF/Ly7zFcaoQVF5PdO/m0J5w9Kimz5yt9+e/p7T09IINGMjDqYtpkqRKAY5/hlTy99PJC5ec+t/buK66tz6qF5at17gPNsiaY1OXpnUd1pAOuifS3KCBW7Rz2XLtXLa8qMNAYWIq35AC+ZTWrFmjhg0bFsRQMOhKRoY8PDxUurTj3y28vErr6tWred6Xlp6uVZ+u1aC+veXp6Wlvz87O1gsvvaJBfXurfl2m8VF4rmRmycNiUekbvo+S5FXKU1ezs536X7qSoeMpqRr4p1Za/mwvTe7RRd/uT9SsTd8WVsgAAJO4rJj+8EPuu7glKTMzU6dPn9aGDRu0detWLViwoMCDQ968y5RRTk6OsrOzHdaIZmZmycfHJ8/74r/cJmu2VQ8+0NWh/b0Fi+RhsWhQv96mxQzkxrt0KeXYbMq25qiU5//+rpyZbZWPV2mn/v9Y95VKeXho9J87SJLuDAtRdk6OJq7crN7tmyvQN+/vPwAUmWK4HtQMLhPTnj175nlclM1mk3RtfWlsbKzatm1b8NEhT1Uqh0iSzpw9Z/9nSTp95oxCKnXI8774L7cqukOUyv4ueV392TqdPnNWLdvfLUnKseVIkv7c/QkNG9Rfwwb2L+i3AEiSKgeWkySdSU1TlfL+9vbTqWm6O6C2U/89R0+oU6M6Dm2Nw6so25qj5POpJKYA3BNT+Ya4TEzj4uJybbdYLPYD9kNCQnLtA3PVr3uHfH19tXP3D3ro/6ufx5KTdTz5hFo1b5bnfbt//Emjhg1xan9/3nvKvmHa9Odf9+m5ceM1953pqnuHc3IAFJT6oRXlW8ZL3x86pgdb3ilJOp5yUcdTUtWyVphT/8qBfvrtxBmHtoMnzsrDYlH14MDCCBkAYBKXiWlkJBsI3JWXl5d6PtpdU2NnqHxgoCoEldfEyVMV2aK5mjZupMysLF28eFEBAQHyKn1tOvT0mbM6ey5FdevUcRovtGoVh5/PnDsnSapatbICAwLMf0MosbxKlVKPu5po2tqtKu/rowrlymrSyni1qh2mJjWqKjPbqouXMxRQ1ltepTz1ZPvmGr7gE7337+16oHl9HTp5TlM+3aon7mrCDnwA7suDiqkRN7Ur32q1qmHDhlq5cqUiIiIKOiYY9OyIYcrOztbzL72s7Ozsa09+GveCJOnHPXvVZ/BTips3W61btpB07ZgoSQoI8M9zTKAoPN01SlnWHI39YL2yrTmKql9DEx65R5L005Fk9Xv3Yy0e/pgi61RTxztraUa/BzXn3zs0L36n/clPgzvxF2kAuN1ZbNcXi/4BVqtVERERWrVqVcEmppcvFtxYQBGyfsExMLj9jfjzmKIOASgQ79lSizoE2fZvN2VcS73i9bhl6soAAABwCwVywD4AAABcYFe+ITeVmHp4eGjkyJGqVKlS/p0BAABKOs4xNcRw+p6Tk2P/Z4vFopEjRyojI8OUoAAAAFDy5JuYJiYmasCAAZo/f75De1pamrp06aJevXopOTnZtAABAABuexYPc17FjMt3dOrUKfXq1Uu//vprrgfpP/XUU0pISNDjjz+us/9/FBEAAABwM1wmpnPnzpWXl5fWrFmjhx56yOGan5+fRo4cqZUrV8pms2nu3LmmBgoAAHDbsljMeRUzLhPTr776SoMHD3b52NGqVatq4MCB2rZtW4EHBwAAUCx4eJjzKmbyncqvXTv/56Q3aNBAJ0+eLLCgAAAAUPK4PC6qfPnyOnPmTL6DXLhwQf7+POYSAAAgV8Vw2t0MLiumLVq00Jo1a/IdZM2aNapXr15BxQQAAIASyGVi2qdPH33zzTeaNm2aMjMzna5nZmbqrbfe0tatW9WrVy/TggQAALitcVyUIS6n8ps0aaIXXnhBU6ZM0Zo1a9SmTRuFhobKarUqOTlZO3bs0Pnz5zVixAhFR0cXUsgAAAC3GabyDcn3kaR9+/ZVw4YNtWDBAm3evFlXr16VJPn6+ioqKkr9+/dX06ZNzY4TAAAAxVy+ial0ba1pixYtJEkpKSkqVaoUm50AAAAMo2JqhMvFCTExMUpKSnJoCwoKIikFAABAgXOZmH7yySc6f/58YcUCAABQPPHkJ0OK33YuAAAA3JYMrTEFAADALSiG1U0z5JuYzpkzR0FBQfkOZLFYNGnSpAIJCgAAoHghMTUi38R0z5498vLyyncgC38TAAAAwC3INzF999131bhx48KIBQAAoHiigGcIm58AAADgFgokMf3+++81efLkghgKAACg+LGY9CpmXCamrVq1kq+vb76D/PLLL4qLiyuwoAAAAIoXMlMjXK4xff/99wsrDgAAAJRwnGMKAABgNjY/GcLmJwAAALgFKqYAAABmo2JqiMvEdMCAAYYGSU5OLpBgAAAAiicSUyNcJqZZWVmGBqlYsaIqVqxYIAEBAACgZGJXPgAAgNmYyjeEzU8AAABwC2x+AgAAMB0VUyOomAIAAMAtUDEFAAAwG2tMDSExBQAAMBuJqSFM5QMAAMAtUDEFAAAwHRVTI0hMAQAASqh169Zp9uzZSkpKUmhoqIYOHaqHH344177jxo3TJ598kudY+/fvlyTt2rVLvXr1croeHR2tOXPmuIyHxBQAAMBkFjdcY7p+/XqNGTNGffv2VVRUlDZv3qyxY8fK29tbXbp0ceo/fPhwPfHEEw5tR48e1bhx4/TYY4/Z2/bv36+yZctq0aJFDn39/f3zjYnEFAAAwGxumJjGxsaqa9euiomJkSS1b99eFy9e1IwZM3JNTKtXr67q1avbf7ZarXr11VdVv359jR8/3t6+b98+3XHHHWratOkfjonNTwAAACVMUlKSEhMTdd999zm0d+7cWYcPH1ZSUlK+Y3z00Uf65ZdfNHHiRHl5ednbf/31V9WrV++m4iIxBQAAMJ3FpNfNOXz4sCSpZs2aDu3h4eGSpISEBJf3p6en6+2339ZDDz2kxo0b29utVqsOHDigkydPqlu3bmrYsKGio6O1cOFC2Wy2fONiKh8AAOA2lZqaqtTUVKd2f39/l2s6L126JEny8/NzaPf19ZUkpaWlufy9q1atUmpqqoYOHerQfuTIEWVkZCghIUGjR49W+fLlFR8fr6lTpyotLU1PP/20y3FJTAEAAMxm0hrTJUuWaObMmU7tI0eO1KhRo/K8L7/qpYeH60n1ZcuW6Z577nGquIaEhGjevHlq0KCBKlasKElq27atMjIyNG/ePA0YMMApGb4RiSkAAIDZTEpM+/btq27dujm157cDvly5cpKuTcnf6Hql9Pr13Ozbt09HjhzRmDFjnK75+fmpQ4cOTu3R0dFasWKFEhIS1KhRozzHJjEFAAC4TeU3ZZ+X65XOxMREh41KR48edbiemy+//FJly5ZVx44dna7t379fu3fv1qOPPqrSpUvb2zMyMiRJ5cuXdxkXm58AAABM516bn8LDwxUWFqaNGzc6tG/atEk1atRQ1apV87z3p59+UsOGDR124l939OhRTZw4Udu2bXNoX79+vcLCwhQaGuoyLiqmAAAAJdCIESMUExOjgIAARUdHKz4+Xhs2bFBsbKwkKSUlRYmJiapTp47DutDffvst12qpdG3KPiIiQhMmTFBKSooqV66stWvXasuWLXrnnXfyfdAAiSkAAIDZ3PCA/UceeUSZmZlauHChVqxYoWrVqmnKlCm6//77JV2bso+JiVFcXJxat25tv+/cuXN5Lh/w8vLS/PnzNX36dM2cOVMpKSm64447NHPmTHXq1CnfmCw2I4dKFZbLF4s6AqBAWL9YXtQhALdsxJ+dNzYAt6P3bM7HKRW6C6fMGTcwxJxxiwgVUwAAALO5X8HULZGYAgAAmI7M1Ah25QMAAMAtUDEFAAAwmxtufnJHVEwBAADgFqiYAgAAmI2KqSEkpgAAAKYjMTWCqXwAAAC4BSqmAAAAZmMq3xAqpgAAAHALVEwBAADMRsXUEBJTAAAA05GYGsFUPgAAANwCFVMAAACzMZVvCBVTAAAAuAWLzWazFXUQAAAAABVTAAAAuAUSUwAAALgFElMAAAC4BRJTAAAAuAUSUwAAALgFElMAAAC4BRJTAAAAuAUSUwAAALgFElMAAAC4BRJTAAAAuAUSUwAAALgFElMAAAC4hVJFHUBJ0Lt3b+3cudOhrVy5crrzzjs1cuRIRUZGaty4cfrkk09cjhMZGan333/f/vOhQ4e0ePFiffPNNzp79qyCg4PVsmVLDRs2TLVq1XI51rFjx3TPPfdo6tSpeuihh5yuf/rpp3rhhRcUHx+vsLAwSVJWVpaWLVumTz/9VAkJCbJYLKpRo4b+8pe/6Mknn5SXl5fD2DcqXbq0AgMD1aJFCw0fPlz16tVzGR/cU27f5RtFRUUpMzPTZR9J6tatm958802NGzdOu3fv1r///e9c+919991q27atXn/99TzH2rFjh/r06aNly5apZcuWTtffffddzZgxQ/v377e3Xb58WQsWLNCGDRt07NgxlS5dWnfccYe6d++uv/71r7JYLA5j36h06dKqUKGC2rVrp5EjRyo0NNTle4X76t27tzw9PbV48WKndqPf4ev27NmjuLg47dq1S+fPn1dISIjat2+voUOHKiQkxOVYfIeB/yExLSSNGjXSSy+9JEmyWq06f/68li9froEDB2r16tUaPny4nnjiCXv/iRMnytPT036PJPn5+dn/ecOGDRo3bpzq169v/4MlOTlZCxcu1F//+lctWLBAzZo1K9D38OKLL+qLL77QkCFDFBERIavVql27dik2Nla7d+/WrFmzHPqPGjVKUVFRkqSMjAwdP35cCxcu1KOPPqrFixerefPmBRofCseN3+XfK1eunGw2m9LS0uxtI0eOVKNGjTR06FB7W1BQkOlx5sVms2nIkCE6evSohgwZojp16igjI0NfffWVJkyYoAMHDujFF190uGfSpEn2v0xduXJFhw8f1ty5c/XFF1/oo48+Uo0aNYrgncAsf//73//Qd3jJkiWaMmWK2rVrp+eff14VK1bUoUOHNH/+fG3atElLly4t0O8I32EUZySmhcTPz09NmzZ1aIuKilLbtm21evVqjR07VtWrV3fo7+np6XSPJB09elQxMTGKjo5WbGysPDz+tyLj3nvvVffu3TVu3Dht2LDB4dqtOH78uD777DO98cYb6t69u729Q4cOCgoK0uTJk7V37141btzYfq1atWpO8Xfu3Fndu3dXTEyM1q9fL09PzwKJD4Unt++yK15eXgoKCvpD95hp165d+v7777VkyRK1adPG3v6nP/1JHh4eWrp0qQYPHqyKFSvar9WuXdsh/rZt2+qee+7RQw89pL///e9asmRJYb4FmKxOnToOP7v6Du/evVtvvvmm+vXrp7Fjx9rbW7dubf+OvPLKK05V2VvBdxjFGYlpESpTpoy8vb3tUy5GLV26VNnZ2XrppZecEk8/Pz/FxMRoz549SktLk7+/f4HEeu7cOUlSTk6O07UHH3xQV69eNfS7/Pz8NGjQIL300kvauXOn2rZtWyDxAUadPXtW0rWq0+89+eSTCgkJMfTvZOXKlfXEE0/ovffeU2JiosNfLFFyLFiwQIGBgXr22WedroWEhGjcuHE6deqUsrOzVapUwfwnl+8wijM2PxUSm82m7OxsZWdnKysrS2fPnlVsbKyuXLniUIE04quvvlJERITD34ZvFB0drWeeeabAklJJql+/vkJCQvTaa69p0qRJ+uqrr+xTXUFBQRo6dKjhqaDryeju3bsLLD4Unhu/y79/5fYfSiPyGs8MrVq1UtmyZfXss8/qrbfe0s6dO5WRkSFJqlGjhgYPHqzg4GBDY7Vr104S3+WSymaz6euvv1bbtm1VpkyZXPs8/PDDGjp0aIElpRLfYRRvVEwLyfbt2xUREeHU/vzzz6t27dp/aKyTJ0+qQYMGBRWaIV5eXpo3b57Gjh2rZcuWadmyZfL09FRERIS6du2qXr165fkH8+9d/wPzzJkzZoYMk+T1XZakefPmqUOHDn9ovMTExDzHM0NwcLDmzJmjF198UfPmzdO8efNUunRpNWvWTH/5y1/UvXt3w0tM+C6XbOfPn9fVq1dVtWrVQv29fIdRnJGYFpLGjRvr5ZdflnTtb9nnz5/Xxo0bNW3aNHl5eTntmnTF09NTVqvVUF+bzebUt1SpUoaXD9zYr169elqzZo3+85//6Ouvv9aOHTv0448/au/evVq1apWWLl2q8uXLG34fuD3d+F3+vZo1a/7h8SpXrqyZM2fmeu2pp56y/3NOTo7TUpI/8l2+UWRkpDZt2qTdu3fr66+/1s6dO/Xjjz9q586d+uyzz7RgwQLDf9FCyXU9+TP65zHfYSB/JKaFxNfXV40aNXJo69ixo06ePKkZM2aoV69ehv+GW7VqVSUnJ+d5/erVq0pPT1dQUJA++eQTxcTEOFyPj49X2bJlJUmZmZm5jpGVlSVJ8vHxcbrWqFEjNWrUSE899ZSuXLmiRYsWacaMGVqwYIHGjBmTb/ynTp2SpHyPUIF7yu27fCu8vLzyHO/6EWSSNGvWLKcEdv/+/fbv6PXv7O9lZWXZv+838vDwUKtWrdSqVStJ0sWLFzV9+nR98MEHWr16tXr06JFv7HyXS7aAgAD5+vq6/PP4+pInPz8/vsOAASSmRaxBgwb69ttvlZKSkuea0d+LiorSkiVL7GeX/t71o6QWLVqkP/3pT1q5cqXD9UqVKsnT01NeXl46ffp0rr/j5MmT8vLyUkBAgCRpypQp+uKLL7Rx40aHfj4+Pho+fLg+//xzHTx40FD827dvl6Rcz+sD8vLYY48pOjraqf36vzfX/wP7eydPnnT49+TZZ5/VhQsXnHZJBwQEaMKECfrXv/6lQ4cOGYpp+/btslgsatGihbE3gWInKipKO3bs0NWrV3OtUC5evFjvvvuuNmzYwHcYMIDNT0XsP//5jwICAv7QuY49e/ZUqVKl9MYbbzhNC6Wmpmr27NmqUqWKIiMjVb58eXuF8/rLy8tLnp6eatGihTZt2uQ0DZWTk6P4+Hi1bNnSXsUNDw9XQkKC1q9f7xRPenq6Tp8+bejQ/PT0dC1YsEB16tSx/y0fMCIkJMTpuyxdWwpQvXp1p780SdfOa/zqq6/UunVre1u1atW0fft2/fTTT079T58+rcuXL6tu3br5xnPq1CktX75c7du3tz+EAiVP//79deHCBc2YMcPpWnJyspYtW6bGjRsrPDyc7zBgABXTQpKWlubwh0hGRobWrl2rnTt36rnnnvtD53lWq1ZNEyZM0Msvv6yTJ0/q8ccfV0hIiBISErRo0SKdOXNGS5YsyXfMZ555Rn369FG/fv3Uo0cPVahQQSdOnNDy5cuVkJCguLg4e99HHnlEn332mV544QXt2LFDHTt2lL+/v44cOaK4uDj5+Piob9++DuMnJSXZ33NmZqaOHj2quLg4e3w3s64KRe/33+UbWSwWNWnSpHADkvS3v/1Nzz77rEaOHKmHH35Yfn5+SkpKUlxcnKxWq4YNG2bvO3DgQG3evFn9+/dXz5491bp1a/n4+Oi3337TwoULVbduXaenoR06dMi+qzojI0MHDhzQokWLVLp06TzX2+L2cOLEiVzPGL3zzjsVGRmZ7/3NmjXTiBEjNHPmTB0+fFgPPfSQAgMDtW/fPi1YsEAeHh6aNm1avuPwHQausdhu9nwXGJbb4+18fHxUs2ZNde/eXU8++WSu9+T2qLwb7dq1S0uWLNHevXuVkpKiSpUqqVWrVnrqqacUHh5uKLb//Oc/mjt3rn788UdduHBBgYGB9sea1q9f36Hv1atXFRcXp88//1xHjhxRRkaGKlWqpLvvvlvDhw+3V31zeyRpqVKlVLFiRbVp00ZDhw69qU0yKHr5ParR09NTv/zyi0Obq8eKFsQjSa/79ttvtXDhQv33v/9VWlqagoOD1a5dOw0fPtypGnTp0iXNnz9fW7Zs0fHjx5WVlaXQ0FB17txZQ4YMka+vr6S8H+dYuXJldezYUUOHDlWlSpXyjQ3uydX3uU+fPho/frwkY9/DLVu2aNmyZdq/f79SU1NVpUoVtW/fXkOGDDH8HeE7DJCYAgAAwE2wxhQAAABugcQUAAAAboHEFAAAAG6BxBQAAABugcQUAAAAboHEFAAAAG6BxBQAAABugcQUAAAAboHEFAAAAG7h/wCUGeUI1EMynwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.set(font_scale=1.5)\n",
    "sns.heatmap(ret.corr(), cmap = \"Reds\", annot = True, annot_kws={\"size\":15}, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 20\n",
      "21.5 21\n",
      "19 21.5\n",
      "22 19\n",
      "1.15\n"
     ]
    }
   ],
   "source": [
    "prices = [20, 21,21.5,19,22]\n",
    "amount = 10\n",
    "profit = 0\n",
    "\n",
    "i = 0\n",
    "\n",
    "while i < len(prices) - 1:\n",
    "    print(prices[i+1], prices[i] )\n",
    "    diff = (prices[i+1] - prices[i] ) / prices[i]\n",
    "    profit += diff * amount\n",
    "    # amount += profit\n",
    "    i += 1\n",
    "\n",
    "print(round(profit, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperopt\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "space={'max_depth': hp.quniform(\"max_depth\", 3, 18, 1),\n",
    "        'gamma': hp.uniform ('gamma', 1,9),\n",
    "        'reg_alpha' : hp.quniform('reg_alpha', 40,180,1),\n",
    "        'reg_lambda' : hp.uniform('reg_lambda', 0,1),\n",
    "        'colsample_bytree' : hp.uniform('colsample_bytree', 0.5,1),\n",
    "        'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n",
    "        'n_estimators': 180\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "SCORE:                                                 \n",
      "16158256.24811321                                      \n",
      "  1%|          | 1/100 [00:01<03:01,  1.83s/trial, best loss: 16158256.24811321]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                          \n",
      "15082236.026611777                                                              \n",
      "  2%|▏         | 2/100 [00:02<01:34,  1.04trial/s, best loss: 15082236.026611777]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                           \n",
      "14670673.519137887                                                               \n",
      "SCORE:                                                                           \n",
      "13444026.907472283                                                               \n",
      "  4%|▍         | 4/100 [00:02<00:45,  2.13trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                           \n",
      "15737909.055172356                                                               \n",
      "SCORE:                                                                           \n",
      "15802399.580183184                                                               \n",
      "  6%|▌         | 6/100 [00:04<01:25,  1.10trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                           \n",
      "14474169.52631391                                                                \n",
      "  7%|▋         | 7/100 [00:05<01:28,  1.05trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                           \n",
      "15825911.590097236                                                               \n",
      "  8%|▊         | 8/100 [00:06<01:13,  1.25trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                           \n",
      "15873355.47217847                                                                \n",
      "SCORE:                                                                           \n",
      "15300735.313293654                                                               \n",
      " 10%|█         | 10/100 [00:11<02:19,  1.55s/trial, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "14870627.114470545                                                                \n",
      "SCORE:                                                                            \n",
      "15573453.911671652                                                                \n",
      " 11%|█         | 11/100 [00:12<02:04,  1.40s/trial, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "16966601.65949994                                                                 \n",
      " 13%|█▎        | 13/100 [00:13<01:09,  1.25trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "16243284.399231534                                                                \n",
      " 14%|█▍        | 14/100 [00:13<00:56,  1.53trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "15459176.486378405                                                                \n",
      " 15%|█▌        | 15/100 [00:13<00:49,  1.71trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "14675236.354582656                                                                \n",
      " 16%|█▌        | 16/100 [00:14<00:48,  1.75trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "16111584.156845713                                                                \n",
      " 17%|█▋        | 17/100 [00:14<00:46,  1.80trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "14996825.24071382                                                                 \n",
      "SCORE:                                                                            \n",
      "15160868.414870612                                                                \n",
      " 19%|█▉        | 19/100 [00:15<00:33,  2.41trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "14727012.008235857                                                                \n",
      " 20%|██        | 20/100 [00:15<00:28,  2.76trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "15995721.360353705                                                                \n",
      " 21%|██        | 21/100 [00:16<00:28,  2.82trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "15331105.679619057                                                                \n",
      " 22%|██▏       | 22/100 [00:16<00:35,  2.23trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "14160168.261372922                                                                \n",
      "SCORE:                                                                            \n",
      "15624150.95095523                                                                 \n",
      " 24%|██▍       | 24/100 [00:17<00:30,  2.49trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "14562808.940570762                                                                \n",
      "SCORE:                                                                            \n",
      "15240728.48429341                                                                 \n",
      " 26%|██▌       | 26/100 [00:18<00:26,  2.81trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "15882919.10579431                                                                 \n",
      " 27%|██▋       | 27/100 [00:19<00:36,  1.99trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "14131377.509139983                                                                \n",
      "SCORE:                                                                            \n",
      "16164665.53791449                                                                 \n",
      " 29%|██▉       | 29/100 [00:19<00:28,  2.47trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "15228982.519086076                                                                \n",
      "SCORE:                                                                            \n",
      "15653154.265792873                                                                \n",
      " 31%|███       | 31/100 [00:20<00:23,  2.92trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "14743374.367594989                                                                \n",
      " 32%|███▏      | 32/100 [00:20<00:21,  3.14trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "15814632.430434706                                                                \n",
      "SCORE:                                                                            \n",
      "15010309.609183405                                                                \n",
      " 34%|███▍      | 34/100 [00:21<00:20,  3.23trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "14844261.215742283                                                                \n",
      " 35%|███▌      | 35/100 [00:21<00:17,  3.76trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "15588764.779208282                                                                \n",
      "SCORE:                                                                            \n",
      "15498243.975075506                                                                \n",
      " 37%|███▋      | 37/100 [00:21<00:14,  4.21trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "15362700.46825825                                                                 \n",
      "SCORE:                                                                            \n",
      "15902430.596526502                                                                \n",
      " 39%|███▉      | 39/100 [00:22<00:13,  4.49trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "13890833.057345882                                                                \n",
      "SCORE:                                                                            \n",
      "15333470.496427745                                                                \n",
      " 41%|████      | 41/100 [00:22<00:14,  4.10trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "14571685.778251957                                                                \n",
      " 42%|████▏     | 42/100 [00:22<00:13,  4.38trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "14860811.71023106                                                                 \n",
      " 43%|████▎     | 43/100 [00:23<00:14,  3.96trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "15840211.791430399                                                                \n",
      " 44%|████▍     | 44/100 [00:23<00:16,  3.41trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "15306657.773780966                                                                \n",
      "SCORE:                                                                            \n",
      "14893424.51666762                                                                 \n",
      " 46%|████▌     | 46/100 [00:24<00:17,  3.08trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "15833177.998855697                                                                \n",
      "SCORE:                                                                            \n",
      "14739101.76590077                                                                 \n",
      " 48%|████▊     | 48/100 [00:24<00:16,  3.23trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "16295571.635147706                                                                \n",
      " 49%|████▉     | 49/100 [00:25<00:16,  3.08trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "15105507.53344857                                                                 \n",
      "SCORE:                                                                            \n",
      "15374782.025681134                                                                \n",
      " 51%|█████     | 51/100 [00:26<00:16,  3.03trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "14493652.977378968                                                                \n",
      " 52%|█████▏    | 52/100 [00:26<00:20,  2.32trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "14124108.305577943                                                                \n",
      " 53%|█████▎    | 53/100 [00:27<00:26,  1.78trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "15383057.56584787                                                                 \n",
      " 54%|█████▍    | 54/100 [00:28<00:32,  1.43trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "14630557.043983892                                                                \n",
      " 55%|█████▌    | 55/100 [00:29<00:31,  1.45trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "14599185.261353528                                                                \n",
      " 56%|█████▌    | 56/100 [00:29<00:28,  1.53trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "14620984.885270806                                                                \n",
      "SCORE:                                                                            \n",
      "15026187.41334055                                                                 \n",
      " 58%|█████▊    | 58/100 [00:30<00:22,  1.90trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "15859029.702088807                                                                \n",
      "SCORE:                                                                            \n",
      "14688800.31755713                                                                 \n",
      " 60%|██████    | 60/100 [00:31<00:16,  2.39trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "14731534.504356096                                                                \n",
      " 61%|██████    | 61/100 [00:31<00:17,  2.29trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "14676056.790235765                                                                \n",
      " 62%|██████▏   | 62/100 [00:32<00:17,  2.23trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "15072989.172743624                                                                \n",
      "SCORE:                                                                            \n",
      "15701882.482737562                                                                \n",
      " 64%|██████▍   | 64/100 [00:33<00:15,  2.33trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "15222609.870742546                                                                \n",
      "SCORE:                                                                            \n",
      "14124082.744356785                                                                \n",
      " 66%|██████▌   | 66/100 [00:33<00:12,  2.76trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "13890834.5373035                                                                  \n",
      " 67%|██████▋   | 67/100 [00:34<00:13,  2.42trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "15151104.862146007                                                                \n",
      "SCORE:                                                                            \n",
      "14571077.73074379                                                                 \n",
      " 69%|██████▉   | 69/100 [00:35<00:14,  2.19trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "14478255.399738178                                                                \n",
      " 70%|███████   | 70/100 [00:35<00:11,  2.57trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "15642569.955826001                                                                \n",
      " 70%|███████   | 70/100 [00:35<00:11,  2.57trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "15952898.826988403                                                                \n",
      " 72%|███████▏  | 72/100 [00:36<00:08,  3.17trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "13771687.908532834                                                                \n",
      " 73%|███████▎  | 73/100 [00:36<00:08,  3.19trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "14571038.53192498                                                                 \n",
      " 74%|███████▍  | 74/100 [00:36<00:08,  3.21trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "15538044.173902992                                                                \n",
      "SCORE:                                                                            \n",
      "14723895.436068056                                                                \n",
      " 76%|███████▌  | 76/100 [00:37<00:07,  3.22trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "15173821.273074174                                                                \n",
      "SCORE:                                                                            \n",
      "14560865.00783403                                                                 \n",
      " 78%|███████▊  | 78/100 [00:38<00:06,  3.23trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "16011653.096727852                                                                \n",
      " 79%|███████▉  | 79/100 [00:39<00:15,  1.35trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "16030445.707731234                                                                \n",
      " 80%|████████  | 80/100 [00:40<00:12,  1.56trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "14477683.803635567                                                                \n",
      "SCORE:                                                                            \n",
      "15147579.684093403                                                                \n",
      " 82%|████████▏ | 82/100 [00:40<00:08,  2.09trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "14540584.174595831                                                                \n",
      " 83%|████████▎ | 83/100 [00:41<00:09,  1.84trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "14687124.763813928                                                                \n",
      "SCORE:                                                                            \n",
      "15206057.017695077                                                                \n",
      " 85%|████████▌ | 85/100 [00:42<00:06,  2.26trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      " 85%|████████▌ | 85/100 [00:42<00:06,  2.26trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15705349.270694682                                                                \n",
      "SCORE:                                                                            \n",
      "14555071.096147558                                                                \n",
      " 87%|████████▋ | 87/100 [00:42<00:04,  2.89trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "15962101.234992232                                                                \n",
      " 88%|████████▊ | 88/100 [00:43<00:04,  2.89trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "14816699.730533686                                                                \n",
      " 89%|████████▉ | 89/100 [00:43<00:03,  2.98trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "16261540.270717477                                                                \n",
      "SCORE:                                                                            \n",
      "14212277.75784652                                                                 \n",
      " 91%|█████████ | 91/100 [00:44<00:02,  3.05trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "15833091.940580064                                                                \n",
      "SCORE:                                                                            \n",
      "15619301.029787654                                                                \n",
      " 93%|█████████▎| 93/100 [00:44<00:02,  2.95trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:\n",
      "16080469.069324067                                                                \n",
      "SCORE:                                                                            \n",
      "14323810.041555576                                                                \n",
      " 95%|█████████▌| 95/100 [00:45<00:01,  3.25trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "16898928.797740992                                                                \n",
      "SCORE:                                                                            \n",
      "15207476.640155498                                                                \n",
      " 97%|█████████▋| 97/100 [00:46<00:00,  3.15trial/s, best loss: 13444026.907472283]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "15268067.434257774                                                                \n",
      "                                                                                  \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:\n",
      "13375522.435594222                                                                \n",
      " 99%|█████████▉| 99/100 [00:46<00:00,  3.03trial/s, best loss: 13375522.435594222]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "c:\\Users\\oriyomi\\Anaconda3\\envs\\my_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "14886783.448707845                                                                \n",
      "100%|██████████| 100/100 [00:47<00:00,  2.11trial/s, best loss: 13375522.435594222]\n",
      "{'colsample_bytree': 0.7877187154112623, 'gamma': 4.751686814941894, 'max_depth': 5.0, 'min_child_weight': 5.0, 'reg_alpha': 47.0, 'reg_lambda': 0.20312582098075171}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import hyperopt\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "import xgboost as xgb\n",
    "from datetime import date\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "today = date.today()\n",
    "\n",
    "# dd/mm/YY\n",
    "d1 = today.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "coin_set = yf.download(['BTC-USD'], start=\"2013-09-17\", end=d1)\n",
    "coin_set2 = coin_set.copy().dropna()\n",
    "\n",
    "coin_set2['Close_Predict']=coin_set2[['Close']].shift(-30)\n",
    "\n",
    "X = np.array(coin_set2[['Open','High','Low','Close','Volume']])\n",
    "X = X[:-30]\n",
    "\n",
    "y = np.array(coin_set2['Close_Predict'])\n",
    "y = y[:-30]\n",
    "\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25)\n",
    "\n",
    "space={'max_depth': hp.quniform(\"max_depth\", 3, 18, 1),\n",
    "        'gamma': hp.uniform ('gamma', 1,9),\n",
    "        'reg_alpha' : hp.quniform('reg_alpha', 40,180,1),\n",
    "        'reg_lambda' : hp.uniform('reg_lambda', 0,1),\n",
    "        'colsample_bytree' : hp.uniform('colsample_bytree', 0.5,1),\n",
    "        'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n",
    "        'n_estimators': 180\n",
    "    }\n",
    "\n",
    "\n",
    "def hyperparameter_tuning(space):\n",
    "    model=xgb.XGBRegressor(n_estimators =space['n_estimators'], max_depth = int(space['max_depth']), \n",
    "                        gamma = space['gamma'],\n",
    "                         reg_alpha = int(space['reg_alpha']), \n",
    "                         min_child_weight=space['min_child_weight'],\n",
    "                          colsample_bytree=space['colsample_bytree'])\n",
    "    evaluation = [( X_train, y_train), ( X_test, y_test)]\n",
    "   \n",
    "    model.fit(X_train, y_train,\n",
    "            eval_set=evaluation, eval_metric=\"rmse\",\n",
    "            early_stopping_rounds=10,verbose=False)\n",
    "\n",
    "    pred = model.predict(X_test)\n",
    "    mse= mean_squared_error(y_test, pred)\n",
    "    print (\"SCORE:\", mse)\n",
    "    #change the metric if you like\n",
    "    return {'loss':mse, 'status': STATUS_OK, 'model': model}\n",
    "\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn=hyperparameter_tuning,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=100,\n",
    "            trials=trials)\n",
    "\n",
    "print (best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('my_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "2b27d762439fa3f7a8f8a04f42616e6ae8d932ddd0123537274b18465b5ddfe6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
